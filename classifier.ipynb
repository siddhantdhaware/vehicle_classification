{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Colors_1 classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, utils\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 90\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import train, test, and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7267 files belonging to 15 classes.\n",
      "Found 1550 files belonging to 15 classes.\n",
      "Found 1556 files belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "colors_1_train = utils.image_dataset_from_directory(\"datasets/data/split/colors_1/train/\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "colors_1_val = utils.image_dataset_from_directory(\"datasets/data/split/colors_1/val\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "colors_1_test = utils.image_dataset_from_directory(\"datasets/data/split/colors_1/test\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_1_data_augmentation = keras.Sequential(\n",
    "[\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(height_factor=0.2,width_factor=0.3)\n",
    "] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 90, 90, 3)]       0         \n",
      "                                                                 \n",
      " rescaling_11 (Rescaling)    (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 88, 88, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 44, 44, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 42, 42, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 9, 9, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 15)                188175    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 576,591\n",
      "Trainable params: 576,591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "colors_1_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "x = colors_1_data_augmentation(colors_1_inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(colors_1_inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x) \n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "colors_1_outputs = layers.Dense(15, activation=\"softmax\")(x)\n",
    "\n",
    "colors_1_model = keras.Model(inputs=colors_1_inputs, outputs=colors_1_outputs)\n",
    "\n",
    "colors_1_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "colors_1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_1_callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=5\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"2_firstAugmentation_colors_1_checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 06:38:29.839116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - ETA: 0s - loss: 1.5784 - accuracy: 0.4770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 06:38:38.899058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 10s 43ms/step - loss: 1.5784 - accuracy: 0.4770 - val_loss: 1.3032 - val_accuracy: 0.5594\n",
      "Epoch 2/30\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.9624 - accuracy: 0.6640 - val_loss: 0.9135 - val_accuracy: 0.6606\n",
      "Epoch 3/30\n",
      "228/228 [==============================] - 9s 38ms/step - loss: 0.7781 - accuracy: 0.7275 - val_loss: 0.9508 - val_accuracy: 0.6703\n",
      "Epoch 4/30\n",
      "228/228 [==============================] - 9s 38ms/step - loss: 0.6702 - accuracy: 0.7680 - val_loss: 0.8391 - val_accuracy: 0.7097\n",
      "Epoch 5/30\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.5959 - accuracy: 0.7980 - val_loss: 0.7753 - val_accuracy: 0.7471\n",
      "Epoch 6/30\n",
      "228/228 [==============================] - 9s 40ms/step - loss: 0.5212 - accuracy: 0.8237 - val_loss: 0.6954 - val_accuracy: 0.7613\n",
      "Epoch 7/30\n",
      "228/228 [==============================] - 9s 40ms/step - loss: 0.4605 - accuracy: 0.8462 - val_loss: 0.6076 - val_accuracy: 0.7806\n",
      "Epoch 8/30\n",
      "228/228 [==============================] - 9s 40ms/step - loss: 0.4057 - accuracy: 0.8667 - val_loss: 0.6028 - val_accuracy: 0.7929\n",
      "Epoch 9/30\n",
      "228/228 [==============================] - 10s 45ms/step - loss: 0.3536 - accuracy: 0.8869 - val_loss: 0.5936 - val_accuracy: 0.8039\n",
      "Epoch 10/30\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.3054 - accuracy: 0.9041 - val_loss: 0.6816 - val_accuracy: 0.7910\n",
      "Epoch 11/30\n",
      "228/228 [==============================] - 9s 40ms/step - loss: 0.2651 - accuracy: 0.9183 - val_loss: 0.9583 - val_accuracy: 0.7761\n",
      "Epoch 12/30\n",
      "228/228 [==============================] - 10s 44ms/step - loss: 0.2265 - accuracy: 0.9284 - val_loss: 1.0841 - val_accuracy: 0.7903\n",
      "Epoch 13/30\n",
      "228/228 [==============================] - 10s 43ms/step - loss: 0.2007 - accuracy: 0.9422 - val_loss: 1.0260 - val_accuracy: 0.7729\n",
      "Epoch 14/30\n",
      "228/228 [==============================] - 10s 44ms/step - loss: 0.1870 - accuracy: 0.9437 - val_loss: 1.3822 - val_accuracy: 0.7697\n"
     ]
    }
   ],
   "source": [
    "history = colors_1_model.fit(\n",
    "  colors_1_train.cache(),\n",
    "  epochs=30,\n",
    "  callbacks=colors_1_callbacks_list,\n",
    "  validation_data=colors_1_val.cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 06:40:57.645939: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 1s 19ms/step - loss: 0.6778 - accuracy: 0.7783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6777648329734802, 0.7782776355743408]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colors_1_model.evaluate(colors_1_test)\n",
    "\n",
    "colors_1_model_test = keras.models.load_model(\"1_base_colors_1_checkpoint_path.keras\")\n",
    "colors_1_model_test.evaluate(colors_1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Vehicle Type classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import train, test, and val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 840 files belonging to 3 classes.\n",
      "Found 180 files belonging to 3 classes.\n",
      "Found 180 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "vehicle_type_train = utils.image_dataset_from_directory(\"datasets/data/split/vehicle_type/train/\", image_size=(224, 224), batch_size=16)\n",
    "vehicle_type_val = utils.image_dataset_from_directory(\"datasets/data/split/vehicle_type/val\", image_size=(224, 224), batch_size=16)\n",
    "vehicle_type_test = utils.image_dataset_from_directory(\"datasets/data/split/vehicle_type/test\", image_size=(224, 224), batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_type_data_augmentation = keras.Sequential(\n",
    "[\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(height_factor=0.2,width_factor=0.3)\n",
    "] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_14 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_13 (Rescaling)    (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 111, 111, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 54, 54, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 26, 26, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 24, 24, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 12, 12, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 10, 10, 512)       1180160   \n",
      "                                                                 \n",
      " global_average_pooling2d_9   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,570,115\n",
      "Trainable params: 1,570,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vehicle_type_inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = vehicle_type_data_augmentation(vehicle_type_inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(vehicle_type_inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=512, kernel_size=3, activation=\"relu\")(x)\n",
    "\n",
    "# x = layers.Flatten()(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "vehicle_type_outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "vehicle_type_model = keras.Model(inputs=vehicle_type_inputs, outputs=vehicle_type_outputs)\n",
    "\n",
    "vehicle_type_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "vehicle_type_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=5\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"3_secondAugmentation_vehicle_type_checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 06:42:14.729922: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - ETA: 0s - loss: 1.1868 - accuracy: 0.3607"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 06:42:21.876071: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 8s 139ms/step - loss: 1.1868 - accuracy: 0.3607 - val_loss: 1.1102 - val_accuracy: 0.3833\n",
      "Epoch 2/30\n",
      "53/53 [==============================] - 7s 128ms/step - loss: 1.1007 - accuracy: 0.4214 - val_loss: 1.0603 - val_accuracy: 0.4278\n",
      "Epoch 3/30\n",
      "53/53 [==============================] - 7s 126ms/step - loss: 1.0410 - accuracy: 0.5512 - val_loss: 0.9326 - val_accuracy: 0.5333\n",
      "Epoch 4/30\n",
      "53/53 [==============================] - 7s 126ms/step - loss: 0.9341 - accuracy: 0.6167 - val_loss: 0.9115 - val_accuracy: 0.5056\n",
      "Epoch 5/30\n",
      "53/53 [==============================] - 7s 126ms/step - loss: 0.8524 - accuracy: 0.6476 - val_loss: 0.8673 - val_accuracy: 0.5667\n",
      "Epoch 6/30\n",
      "53/53 [==============================] - 7s 126ms/step - loss: 0.7628 - accuracy: 0.6952 - val_loss: 0.7332 - val_accuracy: 0.6611\n",
      "Epoch 7/30\n",
      "53/53 [==============================] - 7s 131ms/step - loss: 0.6713 - accuracy: 0.7488 - val_loss: 0.5906 - val_accuracy: 0.7500\n",
      "Epoch 8/30\n",
      "53/53 [==============================] - 7s 137ms/step - loss: 0.6634 - accuracy: 0.7571 - val_loss: 0.5262 - val_accuracy: 0.7778\n",
      "Epoch 9/30\n",
      "53/53 [==============================] - 7s 132ms/step - loss: 0.5766 - accuracy: 0.8012 - val_loss: 0.5843 - val_accuracy: 0.7722\n",
      "Epoch 10/30\n",
      "53/53 [==============================] - 7s 139ms/step - loss: 0.5134 - accuracy: 0.8202 - val_loss: 0.6051 - val_accuracy: 0.7611\n",
      "Epoch 11/30\n",
      "53/53 [==============================] - 7s 131ms/step - loss: 0.4774 - accuracy: 0.8179 - val_loss: 0.5560 - val_accuracy: 0.7889\n",
      "Epoch 12/30\n",
      "53/53 [==============================] - 7s 132ms/step - loss: 0.4273 - accuracy: 0.8417 - val_loss: 0.5294 - val_accuracy: 0.7889\n",
      "Epoch 13/30\n",
      "53/53 [==============================] - 7s 136ms/step - loss: 0.4276 - accuracy: 0.8405 - val_loss: 0.5134 - val_accuracy: 0.8278\n",
      "Epoch 14/30\n",
      "53/53 [==============================] - 7s 134ms/step - loss: 0.3657 - accuracy: 0.8619 - val_loss: 0.5606 - val_accuracy: 0.8111\n",
      "Epoch 15/30\n",
      "53/53 [==============================] - 7s 136ms/step - loss: 0.3310 - accuracy: 0.8726 - val_loss: 0.8104 - val_accuracy: 0.7500\n",
      "Epoch 16/30\n",
      "53/53 [==============================] - 7s 138ms/step - loss: 0.3638 - accuracy: 0.8798 - val_loss: 0.4984 - val_accuracy: 0.8222\n",
      "Epoch 17/30\n",
      "53/53 [==============================] - 7s 137ms/step - loss: 0.3082 - accuracy: 0.8929 - val_loss: 0.4062 - val_accuracy: 0.8611\n",
      "Epoch 18/30\n",
      "53/53 [==============================] - 7s 135ms/step - loss: 0.2820 - accuracy: 0.9036 - val_loss: 0.3983 - val_accuracy: 0.8833\n",
      "Epoch 19/30\n",
      "53/53 [==============================] - 7s 134ms/step - loss: 0.2852 - accuracy: 0.9036 - val_loss: 0.5137 - val_accuracy: 0.8333\n",
      "Epoch 20/30\n",
      "53/53 [==============================] - 8s 143ms/step - loss: 0.2370 - accuracy: 0.9131 - val_loss: 0.3809 - val_accuracy: 0.8833\n",
      "Epoch 21/30\n",
      "53/53 [==============================] - 7s 139ms/step - loss: 0.3234 - accuracy: 0.9036 - val_loss: 0.3836 - val_accuracy: 0.8722\n",
      "Epoch 22/30\n",
      "53/53 [==============================] - 7s 139ms/step - loss: 0.1903 - accuracy: 0.9417 - val_loss: 0.4643 - val_accuracy: 0.8833\n",
      "Epoch 23/30\n",
      "53/53 [==============================] - 8s 143ms/step - loss: 0.2579 - accuracy: 0.9119 - val_loss: 0.4205 - val_accuracy: 0.8722\n"
     ]
    }
   ],
   "source": [
    "history = vehicle_type_model.fit(\n",
    "  vehicle_type_train.cache(),\n",
    "  epochs=30,\n",
    "  callbacks=callbacks_list,\n",
    "  validation_data=vehicle_type_val.cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 06:45:09.027585: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 46ms/step - loss: 0.3933 - accuracy: 0.8833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3933464288711548, 0.8833333253860474]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_types_test = keras.models.load_model(\"2_firstAugmentation_vehicle_type_checkpoint_path.keras\")\n",
    "vehicle_types_test.evaluate(vehicle_type_test)\n",
    "# vehicle_type_model.evaluate(vehicle_type_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
