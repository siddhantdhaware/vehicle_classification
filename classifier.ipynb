{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Colors_1 classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, utils\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 90\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import train, test, and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7267 files belonging to 15 classes.\n",
      "Found 1550 files belonging to 15 classes.\n",
      "Found 1556 files belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "colors_1_train = utils.image_dataset_from_directory(\"datasets/data/split/colors_1/train/\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "colors_1_val = utils.image_dataset_from_directory(\"datasets/data/split/colors_1/val\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "colors_1_test = utils.image_dataset_from_directory(\"datasets/data/split/colors_1/test\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_1_data_augmentation = keras.Sequential(\n",
    "[\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(height_factor=0.2,width_factor=0.3)\n",
    "] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_27 (InputLayer)       [(None, 90, 90, 3)]       0         \n",
      "                                                                 \n",
      " rescaling_26 (Rescaling)    (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " conv2d_115 (Conv2D)         (None, 88, 88, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_89 (MaxPoolin  (None, 44, 44, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_116 (Conv2D)         (None, 42, 42, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_90 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_91 (MaxPoolin  (None, 9, 9, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_118 (Conv2D)         (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 15)                188175    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 576,591\n",
      "Trainable params: 576,591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "colors_1_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "x = colors_1_data_augmentation(colors_1_inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(colors_1_inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x) \n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "colors_1_outputs = layers.Dense(15, activation=\"softmax\")(x)\n",
    "\n",
    "colors_1_model = keras.Model(inputs=colors_1_inputs, outputs=colors_1_outputs)\n",
    "\n",
    "colors_1_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "colors_1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_1_callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=5\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/colors_1_3_secondAug_checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:38:44.498122: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - ETA: 0s - loss: 1.6081 - accuracy: 0.4581"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:38:54.309405: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 11s 46ms/step - loss: 1.6081 - accuracy: 0.4581 - val_loss: 5.4079 - val_accuracy: 0.3084\n",
      "Epoch 2/30\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.9798 - accuracy: 0.6770 - val_loss: 1.0841 - val_accuracy: 0.6432\n",
      "Epoch 3/30\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.7772 - accuracy: 0.7407 - val_loss: 0.8226 - val_accuracy: 0.7355\n",
      "Epoch 4/30\n",
      "228/228 [==============================] - 9s 40ms/step - loss: 0.6641 - accuracy: 0.7746 - val_loss: 0.6778 - val_accuracy: 0.7839\n",
      "Epoch 5/30\n",
      "228/228 [==============================] - 9s 39ms/step - loss: 0.5817 - accuracy: 0.8036 - val_loss: 0.6663 - val_accuracy: 0.7955\n",
      "Epoch 6/30\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.5174 - accuracy: 0.8296 - val_loss: 0.6162 - val_accuracy: 0.8065\n",
      "Epoch 7/30\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.4645 - accuracy: 0.8526 - val_loss: 0.6744 - val_accuracy: 0.7942\n",
      "Epoch 8/30\n",
      "228/228 [==============================] - 10s 42ms/step - loss: 0.3867 - accuracy: 0.8755 - val_loss: 0.6048 - val_accuracy: 0.8200\n",
      "Epoch 9/30\n",
      "228/228 [==============================] - 10s 46ms/step - loss: 0.3348 - accuracy: 0.8923 - val_loss: 0.6729 - val_accuracy: 0.8019\n",
      "Epoch 10/30\n",
      "228/228 [==============================] - 10s 43ms/step - loss: 0.3076 - accuracy: 0.9100 - val_loss: 0.7111 - val_accuracy: 0.8006\n",
      "Epoch 11/30\n",
      "228/228 [==============================] - 10s 43ms/step - loss: 0.2631 - accuracy: 0.9221 - val_loss: 0.7440 - val_accuracy: 0.7981\n",
      "Epoch 12/30\n",
      "228/228 [==============================] - 10s 44ms/step - loss: 0.2299 - accuracy: 0.9322 - val_loss: 0.7696 - val_accuracy: 0.8052\n",
      "Epoch 13/30\n",
      "228/228 [==============================] - 10s 44ms/step - loss: 0.2094 - accuracy: 0.9393 - val_loss: 0.9009 - val_accuracy: 0.8142\n"
     ]
    }
   ],
   "source": [
    "history = colors_1_model.fit(\n",
    "  colors_1_train.cache(),\n",
    "  epochs=30,\n",
    "  callbacks=colors_1_callbacks_list,\n",
    "  validation_data=colors_1_val.cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:41:08.396634: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 1s 20ms/step - loss: 0.7045 - accuracy: 0.8027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7044712901115417, 0.8026992082595825]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colors_1_model.evaluate(colors_1_test)\n",
    "\n",
    "colors_1_model_eval = keras.models.load_model(\"models/colors_1_3_secondAug_checkpoint_path.keras\")\n",
    "colors_1_model_eval.evaluate(colors_1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Vehicle Type classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import train, test, and val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 840 files belonging to 3 classes.\n",
      "Found 180 files belonging to 3 classes.\n",
      "Found 180 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "vehicle_type_train = utils.image_dataset_from_directory(\"datasets/data/split/vehicle_type/train/\", image_size=(224, 224), batch_size=16)\n",
    "vehicle_type_val = utils.image_dataset_from_directory(\"datasets/data/split/vehicle_type/val\", image_size=(224, 224), batch_size=16)\n",
    "vehicle_type_test = utils.image_dataset_from_directory(\"datasets/data/split/vehicle_type/test\", image_size=(224, 224), batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_type_data_augmentation = keras.Sequential(\n",
    "[\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(height_factor=0.2,width_factor=0.3)\n",
    "] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_28 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_27 (Rescaling)    (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d_119 (Conv2D)         (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_92 (MaxPoolin  (None, 111, 111, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_120 (Conv2D)         (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_93 (MaxPoolin  (None, 54, 54, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_121 (Conv2D)         (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_94 (MaxPoolin  (None, 26, 26, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_122 (Conv2D)         (None, 24, 24, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_95 (MaxPoolin  (None, 12, 12, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_123 (Conv2D)         (None, 10, 10, 512)       1180160   \n",
      "                                                                 \n",
      " global_average_pooling2d_11  (None, 512)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,570,115\n",
      "Trainable params: 1,570,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vehicle_type_inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = vehicle_type_data_augmentation(vehicle_type_inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(vehicle_type_inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=512, kernel_size=3, activation=\"relu\")(x)\n",
    "\n",
    "# x = layers.Flatten()(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "vehicle_type_outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "vehicle_type_model = keras.Model(inputs=vehicle_type_inputs, outputs=vehicle_type_outputs)\n",
    "\n",
    "vehicle_type_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "vehicle_type_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_type_callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=5\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/vehicle_type_fourAug_checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:45:15.223172: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - ETA: 0s - loss: 1.2498 - accuracy: 0.3548"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:45:22.735823: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 9s 144ms/step - loss: 1.2498 - accuracy: 0.3548 - val_loss: 1.0517 - val_accuracy: 0.4667\n",
      "Epoch 2/30\n",
      "53/53 [==============================] - 7s 128ms/step - loss: 1.0634 - accuracy: 0.4536 - val_loss: 1.8007 - val_accuracy: 0.3333\n",
      "Epoch 3/30\n",
      "53/53 [==============================] - 7s 128ms/step - loss: 0.9977 - accuracy: 0.5512 - val_loss: 0.8311 - val_accuracy: 0.6333\n",
      "Epoch 4/30\n",
      "53/53 [==============================] - 7s 124ms/step - loss: 0.9066 - accuracy: 0.6048 - val_loss: 1.0043 - val_accuracy: 0.5500\n",
      "Epoch 5/30\n",
      "53/53 [==============================] - 7s 129ms/step - loss: 0.8322 - accuracy: 0.6369 - val_loss: 0.7349 - val_accuracy: 0.6611\n",
      "Epoch 6/30\n",
      "53/53 [==============================] - 7s 130ms/step - loss: 0.7556 - accuracy: 0.6774 - val_loss: 0.6798 - val_accuracy: 0.6944\n",
      "Epoch 7/30\n",
      "53/53 [==============================] - 7s 131ms/step - loss: 0.6374 - accuracy: 0.7381 - val_loss: 1.2025 - val_accuracy: 0.5167\n",
      "Epoch 8/30\n",
      "53/53 [==============================] - 7s 131ms/step - loss: 0.6399 - accuracy: 0.7679 - val_loss: 1.2354 - val_accuracy: 0.5222\n",
      "Epoch 9/30\n",
      "53/53 [==============================] - 7s 134ms/step - loss: 0.5490 - accuracy: 0.7869 - val_loss: 0.6843 - val_accuracy: 0.7000\n",
      "Epoch 10/30\n",
      "53/53 [==============================] - 7s 137ms/step - loss: 0.4657 - accuracy: 0.8107 - val_loss: 0.5242 - val_accuracy: 0.7778\n",
      "Epoch 11/30\n",
      "53/53 [==============================] - 7s 142ms/step - loss: 0.4829 - accuracy: 0.8274 - val_loss: 0.5150 - val_accuracy: 0.7778\n",
      "Epoch 12/30\n",
      "53/53 [==============================] - 7s 132ms/step - loss: 0.4040 - accuracy: 0.8417 - val_loss: 0.4345 - val_accuracy: 0.8611\n",
      "Epoch 13/30\n",
      "53/53 [==============================] - 7s 134ms/step - loss: 0.3708 - accuracy: 0.8607 - val_loss: 0.4331 - val_accuracy: 0.8778\n",
      "Epoch 14/30\n",
      "53/53 [==============================] - 7s 134ms/step - loss: 0.3463 - accuracy: 0.8726 - val_loss: 0.5498 - val_accuracy: 0.7889\n",
      "Epoch 15/30\n",
      "53/53 [==============================] - 7s 130ms/step - loss: 0.3129 - accuracy: 0.8893 - val_loss: 0.4340 - val_accuracy: 0.8778\n",
      "Epoch 16/30\n",
      "53/53 [==============================] - 7s 131ms/step - loss: 0.2656 - accuracy: 0.8833 - val_loss: 0.4402 - val_accuracy: 0.8778\n",
      "Epoch 17/30\n",
      "53/53 [==============================] - 7s 135ms/step - loss: 0.3154 - accuracy: 0.9048 - val_loss: 0.9400 - val_accuracy: 0.7667\n",
      "Epoch 18/30\n",
      "53/53 [==============================] - 7s 138ms/step - loss: 0.2963 - accuracy: 0.9071 - val_loss: 0.4333 - val_accuracy: 0.8889\n",
      "Epoch 19/30\n",
      "53/53 [==============================] - 8s 145ms/step - loss: 0.2921 - accuracy: 0.9214 - val_loss: 0.4255 - val_accuracy: 0.8889\n",
      "Epoch 20/30\n",
      "53/53 [==============================] - 7s 137ms/step - loss: 0.2411 - accuracy: 0.9310 - val_loss: 1.3109 - val_accuracy: 0.6889\n",
      "Epoch 21/30\n",
      "53/53 [==============================] - 7s 135ms/step - loss: 0.1887 - accuracy: 0.9405 - val_loss: 0.5099 - val_accuracy: 0.8889\n",
      "Epoch 22/30\n",
      "53/53 [==============================] - 7s 134ms/step - loss: 0.2136 - accuracy: 0.9369 - val_loss: 0.5137 - val_accuracy: 0.8833\n",
      "Epoch 23/30\n",
      "53/53 [==============================] - 7s 134ms/step - loss: 0.1753 - accuracy: 0.9464 - val_loss: 0.5151 - val_accuracy: 0.8722\n"
     ]
    }
   ],
   "source": [
    "history = vehicle_type_model.fit(\n",
    "  vehicle_type_train.cache(),\n",
    "  epochs=30,\n",
    "  callbacks=vehicle_type_callbacks_list,\n",
    "  validation_data=vehicle_type_val.cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:48:11.046077: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 47ms/step - loss: 0.3121 - accuracy: 0.9056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3120936453342438, 0.9055556058883667]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_types_eval = keras.models.load_model(\"models/vehicle_type_fourAug_checkpoint_path.keras\")\n",
    "vehicle_types_eval.evaluate(vehicle_type_test)\n",
    "# vehicle_type_model.evaluate(vehicle_type_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Colors_2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 90\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10917 files belonging to 8 classes.\n",
      "Found 2337 files belonging to 8 classes.\n",
      "Found 2347 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "colors_2_train = utils.image_dataset_from_directory(\"datasets/data/split/colors_2/train/\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "colors_2_val = utils.image_dataset_from_directory(\"datasets/data/split/colors_2/val\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "colors_2_test = utils.image_dataset_from_directory(\"datasets/data/split/colors_2/test\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_2_data_augmentation = keras.Sequential(\n",
    "[\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(height_factor=0.2,width_factor=0.3)\n",
    "] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_29 (InputLayer)       [(None, 90, 90, 3)]       0         \n",
      "                                                                 \n",
      " rescaling_28 (Rescaling)    (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " conv2d_124 (Conv2D)         (None, 88, 88, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_96 (MaxPoolin  (None, 44, 44, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_125 (Conv2D)         (None, 42, 42, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_97 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_126 (Conv2D)         (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_98 (MaxPoolin  (None, 9, 9, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_127 (Conv2D)         (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 8)                 100360    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 488,776\n",
      "Trainable params: 488,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "colors_2_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "x = colors_2_data_augmentation(colors_2_inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(colors_2_inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x) \n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "colors_2_outputs = layers.Dense(8, activation=\"softmax\")(x)\n",
    "\n",
    "colors_2_model = keras.Model(inputs=colors_2_inputs, outputs=colors_2_outputs)\n",
    "\n",
    "colors_2_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "colors_2_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_2_callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=5\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/colors_2_afterAug_checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:50:20.595652: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - ETA: 0s - loss: 0.9576 - accuracy: 0.6757"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:50:35.202758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 16s 45ms/step - loss: 0.9576 - accuracy: 0.6757 - val_loss: 0.7221 - val_accuracy: 0.7608\n",
      "Epoch 2/30\n",
      "342/342 [==============================] - 13s 39ms/step - loss: 0.4786 - accuracy: 0.8380 - val_loss: 0.4633 - val_accuracy: 0.8434\n",
      "Epoch 3/30\n",
      "342/342 [==============================] - 14s 40ms/step - loss: 0.3455 - accuracy: 0.8810 - val_loss: 0.3401 - val_accuracy: 0.8806\n",
      "Epoch 4/30\n",
      "342/342 [==============================] - 14s 41ms/step - loss: 0.2770 - accuracy: 0.9047 - val_loss: 0.3644 - val_accuracy: 0.8832\n",
      "Epoch 5/30\n",
      "342/342 [==============================] - 15s 44ms/step - loss: 0.2365 - accuracy: 0.9206 - val_loss: 0.4388 - val_accuracy: 0.8789\n",
      "Epoch 6/30\n",
      "342/342 [==============================] - 15s 43ms/step - loss: 0.1972 - accuracy: 0.9327 - val_loss: 0.3675 - val_accuracy: 0.8896\n",
      "Epoch 7/30\n",
      "342/342 [==============================] - 16s 45ms/step - loss: 0.1807 - accuracy: 0.9413 - val_loss: 0.3477 - val_accuracy: 0.9033\n",
      "Epoch 8/30\n",
      "342/342 [==============================] - 16s 46ms/step - loss: 0.1560 - accuracy: 0.9519 - val_loss: 0.4004 - val_accuracy: 0.9016\n",
      "Epoch 9/30\n",
      "342/342 [==============================] - 15s 44ms/step - loss: 0.1387 - accuracy: 0.9529 - val_loss: 0.4398 - val_accuracy: 0.8845\n",
      "Epoch 10/30\n",
      "342/342 [==============================] - 15s 44ms/step - loss: 0.1331 - accuracy: 0.9582 - val_loss: 0.3937 - val_accuracy: 0.9093\n",
      "Epoch 11/30\n",
      "342/342 [==============================] - 15s 44ms/step - loss: 0.1252 - accuracy: 0.9612 - val_loss: 0.3633 - val_accuracy: 0.9221\n",
      "Epoch 12/30\n",
      "342/342 [==============================] - 15s 44ms/step - loss: 0.1241 - accuracy: 0.9648 - val_loss: 0.5629 - val_accuracy: 0.8969\n",
      "Epoch 13/30\n",
      "342/342 [==============================] - 15s 44ms/step - loss: 0.1129 - accuracy: 0.9635 - val_loss: 0.5105 - val_accuracy: 0.9067\n",
      "Epoch 14/30\n",
      "342/342 [==============================] - 15s 44ms/step - loss: 0.1016 - accuracy: 0.9699 - val_loss: 0.5512 - val_accuracy: 0.9012\n",
      "Epoch 15/30\n",
      "342/342 [==============================] - 15s 43ms/step - loss: 0.1033 - accuracy: 0.9698 - val_loss: 0.5962 - val_accuracy: 0.9123\n",
      "Epoch 16/30\n",
      "342/342 [==============================] - 14s 42ms/step - loss: 0.0999 - accuracy: 0.9712 - val_loss: 0.6165 - val_accuracy: 0.9007\n"
     ]
    }
   ],
   "source": [
    "history = colors_2_model.fit(\n",
    "  colors_2_train.cache(),\n",
    "  epochs=30,\n",
    "  callbacks=colors_2_callbacks_list,\n",
    "  validation_data=colors_2_val.cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:34:08.735135: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 2s 20ms/step - loss: 0.3316 - accuracy: 0.8922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33162716031074524, 0.8922027945518494]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colors_2_model.evaluate(colors_2_test)\n",
    "\n",
    "colors_2_eval = keras.models.load_model(\"models/colors_2_afterAug_checkpoint_path.keras\")\n",
    "colors_2_eval.evaluate(colors_2_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
