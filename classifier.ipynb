{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Colors_1 classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, utils\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 90\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import train, test, and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7267 files belonging to 15 classes.\n",
      "Found 1550 files belonging to 15 classes.\n",
      "Found 1556 files belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "colors_1_train = utils.image_dataset_from_directory(\"datasets/data/split/colors_1/train/\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "colors_1_val = utils.image_dataset_from_directory(\"datasets/data/split/colors_1/val\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "colors_1_test = utils.image_dataset_from_directory(\"datasets/data/split/colors_1/test\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_1_data_augmentation = keras.Sequential(\n",
    "[\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(height_factor=0.2,width_factor=0.3)\n",
    "] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 90, 90, 3)]       0         \n",
      "                                                                 \n",
      " rescaling_14 (Rescaling)    (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 88, 88, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 44, 44, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 42, 42, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 9, 9, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 15)                188175    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 576,591\n",
      "Trainable params: 576,591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "colors_1_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "x = colors_1_data_augmentation(colors_1_inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(colors_1_inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x) \n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "colors_1_outputs = layers.Dense(15, activation=\"softmax\")(x)\n",
    "\n",
    "colors_1_model = keras.Model(inputs=colors_1_inputs, outputs=colors_1_outputs)\n",
    "\n",
    "colors_1_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "colors_1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_1_callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=5\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/2_firstAugmentation_colors_1_checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 06:49:53.815871: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - ETA: 0s - loss: 1.6006 - accuracy: 0.4796"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 06:50:04.094131: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228/228 [==============================] - 12s 49ms/step - loss: 1.6006 - accuracy: 0.4796 - val_loss: 1.2941 - val_accuracy: 0.5258\n",
      "Epoch 2/30\n",
      "228/228 [==============================] - 10s 43ms/step - loss: 0.9805 - accuracy: 0.6686 - val_loss: 1.3233 - val_accuracy: 0.6161\n",
      "Epoch 3/30\n",
      "228/228 [==============================] - 10s 43ms/step - loss: 0.7942 - accuracy: 0.7290 - val_loss: 1.1869 - val_accuracy: 0.5987\n",
      "Epoch 4/30\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.6724 - accuracy: 0.7761 - val_loss: 0.8606 - val_accuracy: 0.7071\n",
      "Epoch 5/30\n",
      "228/228 [==============================] - 9s 41ms/step - loss: 0.6021 - accuracy: 0.8078 - val_loss: 0.8984 - val_accuracy: 0.7245\n",
      "Epoch 6/30\n",
      "228/228 [==============================] - 10s 43ms/step - loss: 0.5448 - accuracy: 0.8254 - val_loss: 1.4706 - val_accuracy: 0.5710\n",
      "Epoch 7/30\n",
      "228/228 [==============================] - 10s 45ms/step - loss: 0.4692 - accuracy: 0.8514 - val_loss: 1.2200 - val_accuracy: 0.6394\n",
      "Epoch 8/30\n",
      "228/228 [==============================] - 10s 45ms/step - loss: 0.3987 - accuracy: 0.8757 - val_loss: 1.6384 - val_accuracy: 0.5716\n",
      "Epoch 9/30\n",
      "228/228 [==============================] - 10s 45ms/step - loss: 0.3544 - accuracy: 0.8929 - val_loss: 1.2974 - val_accuracy: 0.6555\n",
      "Epoch 10/30\n",
      "228/228 [==============================] - 10s 46ms/step - loss: 0.3080 - accuracy: 0.9073 - val_loss: 0.9272 - val_accuracy: 0.7484\n",
      "Epoch 11/30\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.2590 - accuracy: 0.9247 - val_loss: 0.9568 - val_accuracy: 0.7671\n",
      "Epoch 12/30\n",
      "228/228 [==============================] - 11s 49ms/step - loss: 0.2092 - accuracy: 0.9396 - val_loss: 0.8383 - val_accuracy: 0.7826\n",
      "Epoch 13/30\n",
      "228/228 [==============================] - 11s 48ms/step - loss: 0.1802 - accuracy: 0.9485 - val_loss: 1.1610 - val_accuracy: 0.7832\n",
      "Epoch 14/30\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.1638 - accuracy: 0.9557 - val_loss: 1.2488 - val_accuracy: 0.7761\n",
      "Epoch 15/30\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.1733 - accuracy: 0.9560 - val_loss: 1.0147 - val_accuracy: 0.7974\n",
      "Epoch 16/30\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.1472 - accuracy: 0.9633 - val_loss: 1.4059 - val_accuracy: 0.7852\n",
      "Epoch 17/30\n",
      "228/228 [==============================] - 11s 47ms/step - loss: 0.1291 - accuracy: 0.9644 - val_loss: 1.2368 - val_accuracy: 0.8006\n",
      "Epoch 18/30\n",
      "228/228 [==============================] - 12s 53ms/step - loss: 0.1326 - accuracy: 0.9675 - val_loss: 1.7927 - val_accuracy: 0.7768\n",
      "Epoch 19/30\n",
      "228/228 [==============================] - 13s 58ms/step - loss: 0.1434 - accuracy: 0.9666 - val_loss: 1.3138 - val_accuracy: 0.7877\n",
      "Epoch 20/30\n",
      "228/228 [==============================] - 13s 59ms/step - loss: 0.1254 - accuracy: 0.9733 - val_loss: 1.5149 - val_accuracy: 0.7735\n",
      "Epoch 21/30\n",
      "228/228 [==============================] - 14s 59ms/step - loss: 0.1153 - accuracy: 0.9722 - val_loss: 1.2666 - val_accuracy: 0.7916\n",
      "Epoch 22/30\n",
      "228/228 [==============================] - 14s 60ms/step - loss: 0.1110 - accuracy: 0.9743 - val_loss: 1.3928 - val_accuracy: 0.7974\n"
     ]
    }
   ],
   "source": [
    "history = colors_1_model.fit(\n",
    "  colors_1_train.cache(),\n",
    "  epochs=30,\n",
    "  callbacks=colors_1_callbacks_list,\n",
    "  validation_data=colors_1_val.cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:00:48.268620: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 1s 17ms/step - loss: 0.9264 - accuracy: 0.7943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9263811111450195, 0.7943444848060608]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colors_1_model.evaluate(colors_1_test)\n",
    "\n",
    "colors_1_model_eval = keras.models.load_model(\"models/2_firstAugmentation_colors_1_checkpoint_path.keras\")\n",
    "colors_1_model_eval.evaluate(colors_1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Vehicle Type classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import train, test, and val datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 840 files belonging to 3 classes.\n",
      "Found 180 files belonging to 3 classes.\n",
      "Found 180 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "vehicle_type_train = utils.image_dataset_from_directory(\"datasets/data/split/vehicle_type/train/\", image_size=(224, 224), batch_size=16)\n",
    "vehicle_type_val = utils.image_dataset_from_directory(\"datasets/data/split/vehicle_type/val\", image_size=(224, 224), batch_size=16)\n",
    "vehicle_type_test = utils.image_dataset_from_directory(\"datasets/data/split/vehicle_type/test\", image_size=(224, 224), batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_type_data_augmentation = keras.Sequential(\n",
    "[\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(height_factor=0.2,width_factor=0.3)\n",
    "] \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_15 (Rescaling)    (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_55 (MaxPoolin  (None, 111, 111, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 54, 54, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 52, 52, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 26, 26, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 24, 24, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 12, 12, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 10, 10, 512)       1180160   \n",
      "                                                                 \n",
      " global_average_pooling2d_10  (None, 512)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,570,115\n",
      "Trainable params: 1,570,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vehicle_type_inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "x = vehicle_type_data_augmentation(vehicle_type_inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(vehicle_type_inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=512, kernel_size=3, activation=\"relu\")(x)\n",
    "\n",
    "# x = layers.Flatten()(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "vehicle_type_outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "vehicle_type_model = keras.Model(inputs=vehicle_type_inputs, outputs=vehicle_type_outputs)\n",
    "\n",
    "vehicle_type_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "vehicle_type_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=5\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/3_secondAugmentation_vehicle_type_checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 06:54:36.170997: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - ETA: 0s - loss: 1.2319 - accuracy: 0.3417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 06:54:45.914341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 12s 201ms/step - loss: 1.2319 - accuracy: 0.3417 - val_loss: 1.0936 - val_accuracy: 0.3333\n",
      "Epoch 2/30\n",
      "53/53 [==============================] - 11s 202ms/step - loss: 1.1042 - accuracy: 0.3810 - val_loss: 1.0213 - val_accuracy: 0.5500\n",
      "Epoch 3/30\n",
      "53/53 [==============================] - 11s 209ms/step - loss: 1.2447 - accuracy: 0.5155 - val_loss: 0.8898 - val_accuracy: 0.5833\n",
      "Epoch 4/30\n",
      "53/53 [==============================] - 11s 211ms/step - loss: 1.0009 - accuracy: 0.5500 - val_loss: 0.8526 - val_accuracy: 0.6333\n",
      "Epoch 5/30\n",
      "53/53 [==============================] - 11s 209ms/step - loss: 0.9318 - accuracy: 0.5940 - val_loss: 0.8191 - val_accuracy: 0.6111\n",
      "Epoch 6/30\n",
      "53/53 [==============================] - 11s 203ms/step - loss: 0.8678 - accuracy: 0.6393 - val_loss: 0.9330 - val_accuracy: 0.5611\n",
      "Epoch 7/30\n",
      "53/53 [==============================] - 11s 209ms/step - loss: 0.7570 - accuracy: 0.6964 - val_loss: 0.7195 - val_accuracy: 0.7056\n",
      "Epoch 8/30\n",
      "53/53 [==============================] - 11s 201ms/step - loss: 0.6869 - accuracy: 0.7429 - val_loss: 0.7309 - val_accuracy: 0.6944\n",
      "Epoch 9/30\n",
      "53/53 [==============================] - 11s 205ms/step - loss: 0.6224 - accuracy: 0.7738 - val_loss: 0.5799 - val_accuracy: 0.7722\n",
      "Epoch 10/30\n",
      "53/53 [==============================] - 11s 203ms/step - loss: 0.5104 - accuracy: 0.7857 - val_loss: 0.4910 - val_accuracy: 0.8333\n",
      "Epoch 11/30\n",
      "53/53 [==============================] - 11s 208ms/step - loss: 0.5127 - accuracy: 0.8036 - val_loss: 0.4306 - val_accuracy: 0.8444\n",
      "Epoch 12/30\n",
      "53/53 [==============================] - 11s 207ms/step - loss: 0.4784 - accuracy: 0.8512 - val_loss: 0.4231 - val_accuracy: 0.8556\n",
      "Epoch 13/30\n",
      "53/53 [==============================] - 11s 206ms/step - loss: 0.4397 - accuracy: 0.8405 - val_loss: 0.8783 - val_accuracy: 0.6722\n",
      "Epoch 14/30\n",
      "53/53 [==============================] - 11s 203ms/step - loss: 0.3611 - accuracy: 0.8655 - val_loss: 0.5271 - val_accuracy: 0.8111\n",
      "Epoch 15/30\n",
      "53/53 [==============================] - 11s 201ms/step - loss: 0.3614 - accuracy: 0.8679 - val_loss: 0.4470 - val_accuracy: 0.8556\n",
      "Epoch 16/30\n",
      "53/53 [==============================] - 11s 201ms/step - loss: 0.3337 - accuracy: 0.8762 - val_loss: 0.6762 - val_accuracy: 0.8056\n",
      "Epoch 17/30\n",
      "53/53 [==============================] - 10s 196ms/step - loss: 0.2812 - accuracy: 0.8881 - val_loss: 0.6948 - val_accuracy: 0.7833\n"
     ]
    }
   ],
   "source": [
    "history = vehicle_type_model.fit(\n",
    "  vehicle_type_train.cache(),\n",
    "  epochs=30,\n",
    "  callbacks=callbacks_list,\n",
    "  validation_data=vehicle_type_val.cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 06:59:21.169610: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 40ms/step - loss: 0.3525 - accuracy: 0.8778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3525424301624298, 0.8777778148651123]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicle_types_eval = keras.models.load_model(\"models/3_secondAugmentation_vehicle_type_checkpoint_path.keras\")\n",
    "vehicle_types_eval.evaluate(vehicle_type_test)\n",
    "# vehicle_type_model.evaluate(vehicle_type_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Colors_2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 90\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10917 files belonging to 8 classes.\n",
      "Found 2337 files belonging to 8 classes.\n",
      "Found 2347 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "colors_2_train = utils.image_dataset_from_directory(\"datasets/data/split/colors_2/train/\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "colors_2_val = utils.image_dataset_from_directory(\"datasets/data/split/colors_2/val\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "colors_2_test = utils.image_dataset_from_directory(\"datasets/data/split/colors_2/test\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_2_data_augmentation = keras.Sequential(\n",
    "[\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2),\n",
    "    layers.RandomTranslation(height_factor=0.2,width_factor=0.3)\n",
    "] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 90, 90, 3)]       0         \n",
      "                                                                 \n",
      " rescaling_25 (Rescaling)    (None, 90, 90, 3)         0         \n",
      "                                                                 \n",
      " conv2d_111 (Conv2D)         (None, 88, 88, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_86 (MaxPoolin  (None, 44, 44, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_112 (Conv2D)         (None, 42, 42, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_87 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_88 (MaxPoolin  (None, 9, 9, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_114 (Conv2D)         (None, 7, 7, 256)         295168    \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 8)                 100360    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 488,776\n",
      "Trainable params: 488,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "colors_2_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "\n",
    "x = colors_2_data_augmentation(colors_2_inputs)\n",
    "\n",
    "x = layers.Rescaling(1./255)(colors_2_inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x) \n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x) \n",
    "# x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "# x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "colors_2_outputs = layers.Dense(8, activation=\"softmax\")(x)\n",
    "\n",
    "colors_2_model = keras.Model(inputs=colors_2_inputs, outputs=colors_2_outputs)\n",
    "\n",
    "colors_2_model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "colors_2_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_2_callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=5\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/1_base_colors_1_checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:22:14.914074: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - ETA: 0s - loss: 0.9532 - accuracy: 0.6761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:22:30.235878: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342/342 [==============================] - 17s 48ms/step - loss: 0.9532 - accuracy: 0.6761 - val_loss: 0.7938 - val_accuracy: 0.7082\n",
      "Epoch 2/30\n",
      "342/342 [==============================] - 14s 41ms/step - loss: 0.4671 - accuracy: 0.8400 - val_loss: 0.3817 - val_accuracy: 0.8695\n",
      "Epoch 3/30\n",
      "342/342 [==============================] - 15s 43ms/step - loss: 0.3435 - accuracy: 0.8806 - val_loss: 0.3045 - val_accuracy: 0.8909\n",
      "Epoch 4/30\n",
      "342/342 [==============================] - 15s 44ms/step - loss: 0.2732 - accuracy: 0.9071 - val_loss: 0.3213 - val_accuracy: 0.8926\n",
      "Epoch 5/30\n",
      "342/342 [==============================] - 16s 47ms/step - loss: 0.2316 - accuracy: 0.9235 - val_loss: 0.2479 - val_accuracy: 0.9157\n",
      "Epoch 6/30\n",
      "342/342 [==============================] - 16s 46ms/step - loss: 0.1966 - accuracy: 0.9363 - val_loss: 0.2807 - val_accuracy: 0.9123\n",
      "Epoch 7/30\n",
      "342/342 [==============================] - 16s 47ms/step - loss: 0.1711 - accuracy: 0.9427 - val_loss: 0.2761 - val_accuracy: 0.9089\n",
      "Epoch 8/30\n",
      "342/342 [==============================] - 16s 47ms/step - loss: 0.1517 - accuracy: 0.9488 - val_loss: 0.3074 - val_accuracy: 0.9089\n",
      "Epoch 9/30\n",
      "342/342 [==============================] - 16s 47ms/step - loss: 0.1372 - accuracy: 0.9565 - val_loss: 0.3520 - val_accuracy: 0.9076\n",
      "Epoch 10/30\n",
      "342/342 [==============================] - 16s 47ms/step - loss: 0.1167 - accuracy: 0.9630 - val_loss: 0.4173 - val_accuracy: 0.9024\n"
     ]
    }
   ],
   "source": [
    "history = colors_2_model.fit(\n",
    "  colors_2_train.cache(),\n",
    "  epochs=30,\n",
    "  callbacks=colors_2_callbacks_list,\n",
    "  validation_data=colors_2_val.cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-30 07:25:25.924046: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 2s 21ms/step - loss: 0.3316 - accuracy: 0.8922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3316270709037781, 0.8922027945518494]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# colors_2_model.evaluate(colors_2_test)\n",
    "\n",
    "colors_2_eval = keras.models.load_model(\"models/1_base_colors_1_checkpoint_path.keras\")\n",
    "colors_2_eval.evaluate(colors_2_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
