{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology and downloading datasets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This section defines the problem and has a script to download the dataset. After this, a measure of success is chosen, an evaluation protocol is decided, and the raw data is downloaded in the required form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defining the problem and assembling a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The problem is a multiclass single-label image classification problem. The objective is to build models that can accurately classify a vehicle depending on its type - for example, accurately predicting whether a given image is of a bike, pickup truck, mini bus etc.\n",
    "\n",
    "> A secondary objective is to build models that are small and efficient, and yet can predict with a relatively high degree of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The main dataset being used is called 'A Dataset Containing Tiny and Low Quality Images for Vehicle Classification' downloaded from this link: [https://zenodo.org/record/6634554](https://zenodo.org/record/6634554). It contains six classes of vehicles and 800 images for each of those classes. This dataset is referred to as 'zenodo' in this project.\n",
    "\n",
    "> The secondary dataset which will be used for transfer learning is called 'Vehicle Type Image Dataset (Version 2)' downloaded from this link: [https://data.mendeley.com/datasets/htsngg9tpc](https://data.mendeley.com/datasets/htsngg9tpc). This dataset contains 4356 images split between five classes of vehicles. This dataset is referred to as 'vtid2' in this project.\n",
    "\n",
    "> Both datasets have the licence of 'Creative Commons Attribution 4.0 International'. More information about them can be found in the file **datasets/dataset_sources.md** or in the **README.md** file.\n",
    "\n",
    "> The primary dataset (Zenodo) data is already in the datasets/data/raw folder, and running the code shown below will download the secondary dataset (VTID2) as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Downloading the VTID2 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download VTID2 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choosing a measure of success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The primary measure of success being chosen is **accuracy**. The primary metric (accuracy) will signal the overall success of the models. The secondary metrics which will be looked at are the *precision* and *recall* of each individual class. The secondary metrics will indicate where the model needs to improve further. \n",
    "\n",
    "> The dataset is perfectly balanced, and it is a multiclass classification problem, so using accuracy as a primary metric of success is the perfect choice for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Primary metric: **accuracy**\n",
    "\n",
    "Secondary metrics: *class wise precision and recall*\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deciding on an evaluation protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The evaluation protocol will be maintaining a hold-out validation set. 10% of the dataset will be used as a validation set, this will be used to tune hyperparameters and get the best models. The final models will be evaluated on the test set which will also be 10% of the dataset, so evidently, the training set will be 80% of the dataset. \n",
    "\n",
    "> Since the main dataset has 4800 images split equally among six classes, this means that there will be 480 images in the test set and 480 images in the validation set. This means that the dataset is sufficiently large to use the hold-out validation technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Evaluation Protocol: **Maintaining a hold-out validation set**\n",
    "\n",
    "----\n",
    "\n",
    "Dataset split ratio:\n",
    "\n",
    "| Split      | Ratio |\n",
    "|------------|-------|\n",
    "| Train      | 80%   |\n",
    "| Validation | 10%   |\n",
    "| Test       | 10%   |\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Last layer activation, optimization, and loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is a multiclass single-label image classification problem, so:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Last-layer activation - **sigmoid**\n",
    "\n",
    "2. Loss function - **sparse_categorical_crossentropy**\n",
    "\n",
    "3. Optimization Configuration - **rmsprop**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fixing issues before data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting raw paths for the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_zenodo_path = './datasets/data/raw/Dataset (Vehicles)'\n",
    "raw_vtid2_path = './datasets/data/raw/htsngg9tpc-2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming the 'other' folder in the VTID2 dataset since they are all clearly bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# If the directory exists, then rename it\n",
    "if os.path.exists(raw_vtid2_path + '/' + 'other'):\n",
    "  os.rename(raw_vtid2_path + '/' + 'other', raw_vtid2_path + '/' + 'bike')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
