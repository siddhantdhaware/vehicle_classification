{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, utils\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Image and Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the train, val, and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3360 files belonging to 6 classes.\n",
      "Found 720 files belonging to 6 classes.\n",
      "Found 720 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train = utils.image_dataset_from_directory(\"../../datasets/data/split/Zenodo/train\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "val = utils.image_dataset_from_directory(\"../../datasets/data/split/Zenodo/val\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "test = utils.image_dataset_from_directory(\"../../datasets/data/split/Zenodo/test\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding augmentation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this method for M1 Mac CPU acces to run augmentation\n",
    "with tf.device('/cpu:0'):\n",
    "  data_augmentation = keras.Sequential(\n",
    "  [\n",
    "      layers.RandomFlip(\"horizontal\"),\n",
    "      layers.RandomRotation(0.1),\n",
    "      layers.RandomZoom(0.2)\n",
    "      # layers.RandomContrast(0.2),\n",
    "      # layers.RandomTranslation(height_factor=0.2,width_factor=0.3)\n",
    "  ] \n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 100, 100, 3)  0           ['input_3[0][0]',                \n",
      "                                                                  'rescaling_2[0][0]']            \n",
      "                                                                                                  \n",
      " rescaling_2 (Rescaling)        (None, 100, 100, 3)  0           ['sequential_1[2][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 98, 98, 32)   896         ['sequential_1[3][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 49, 49, 32)  0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 47, 47, 64)   18496       ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 23, 23, 64)  0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 21, 21, 128)  73856       ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 10, 10, 128)  0          ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 8, 8, 256)    295168      ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 256)         0           ['conv2d_11[0][0]']              \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 256)          65792       ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 256)          0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 6)            1542        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 455,750\n",
      "Trainable params: 455,750\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "with tf.device('/cpu:0'):\n",
    "  x = data_augmentation(x)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = data_augmentation(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"../../models/zenodo/m4_Augmentation.h5\",\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 15:19:28.488875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - ETA: 0s - loss: 1.7924 - accuracy: 0.1807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 15:19:36.398141: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105/105 [==============================] - 9s 75ms/step - loss: 1.7924 - accuracy: 0.1807 - val_loss: 2.3359 - val_accuracy: 0.1667\n",
      "Epoch 2/40\n",
      "105/105 [==============================] - 8s 72ms/step - loss: 1.6759 - accuracy: 0.2905 - val_loss: 2.1983 - val_accuracy: 0.3444\n",
      "Epoch 3/40\n",
      "105/105 [==============================] - 7s 70ms/step - loss: 1.5577 - accuracy: 0.3688 - val_loss: 3.5789 - val_accuracy: 0.2153\n",
      "Epoch 4/40\n",
      "105/105 [==============================] - 7s 70ms/step - loss: 1.4881 - accuracy: 0.4164 - val_loss: 3.8642 - val_accuracy: 0.2347\n",
      "Epoch 5/40\n",
      "105/105 [==============================] - 7s 70ms/step - loss: 1.3767 - accuracy: 0.4583 - val_loss: 3.8515 - val_accuracy: 0.2764\n",
      "Epoch 6/40\n",
      "105/105 [==============================] - 7s 71ms/step - loss: 1.2963 - accuracy: 0.4866 - val_loss: 1.6292 - val_accuracy: 0.4556\n",
      "Epoch 7/40\n",
      "105/105 [==============================] - 7s 70ms/step - loss: 1.2340 - accuracy: 0.5170 - val_loss: 2.3514 - val_accuracy: 0.4014\n",
      "Epoch 8/40\n",
      "105/105 [==============================] - 7s 70ms/step - loss: 1.1627 - accuracy: 0.5387 - val_loss: 2.3032 - val_accuracy: 0.4458\n",
      "Epoch 9/40\n",
      "105/105 [==============================] - 7s 71ms/step - loss: 1.1009 - accuracy: 0.5673 - val_loss: 2.1419 - val_accuracy: 0.4375\n",
      "Epoch 10/40\n",
      "105/105 [==============================] - 8s 72ms/step - loss: 1.0544 - accuracy: 0.5890 - val_loss: 1.9323 - val_accuracy: 0.4931\n",
      "Epoch 11/40\n",
      "105/105 [==============================] - 8s 73ms/step - loss: 1.0161 - accuracy: 0.5961 - val_loss: 1.8719 - val_accuracy: 0.5097\n",
      "Epoch 12/40\n",
      "105/105 [==============================] - 8s 72ms/step - loss: 0.9490 - accuracy: 0.6262 - val_loss: 1.4150 - val_accuracy: 0.5486\n",
      "Epoch 13/40\n",
      "105/105 [==============================] - 8s 74ms/step - loss: 0.9101 - accuracy: 0.6476 - val_loss: 1.2496 - val_accuracy: 0.5819\n",
      "Epoch 14/40\n",
      "105/105 [==============================] - 8s 73ms/step - loss: 0.8720 - accuracy: 0.6661 - val_loss: 1.2796 - val_accuracy: 0.5819\n",
      "Epoch 15/40\n",
      "105/105 [==============================] - 8s 73ms/step - loss: 0.8221 - accuracy: 0.6857 - val_loss: 1.2070 - val_accuracy: 0.6319\n",
      "Epoch 16/40\n",
      "105/105 [==============================] - 8s 73ms/step - loss: 0.7772 - accuracy: 0.6997 - val_loss: 1.2138 - val_accuracy: 0.5681\n",
      "Epoch 17/40\n",
      "105/105 [==============================] - 8s 74ms/step - loss: 0.7326 - accuracy: 0.7196 - val_loss: 1.2639 - val_accuracy: 0.6181\n",
      "Epoch 18/40\n",
      "105/105 [==============================] - 8s 75ms/step - loss: 0.7019 - accuracy: 0.7339 - val_loss: 0.9288 - val_accuracy: 0.6736\n",
      "Epoch 19/40\n",
      "105/105 [==============================] - 8s 74ms/step - loss: 0.6869 - accuracy: 0.7423 - val_loss: 0.9221 - val_accuracy: 0.6819\n",
      "Epoch 20/40\n",
      "105/105 [==============================] - 8s 74ms/step - loss: 0.6609 - accuracy: 0.7509 - val_loss: 1.0519 - val_accuracy: 0.6542\n",
      "Epoch 21/40\n",
      "105/105 [==============================] - 8s 74ms/step - loss: 0.6215 - accuracy: 0.7560 - val_loss: 1.2607 - val_accuracy: 0.6125\n",
      "Epoch 22/40\n",
      "105/105 [==============================] - 8s 74ms/step - loss: 0.5828 - accuracy: 0.7717 - val_loss: 1.1079 - val_accuracy: 0.6486\n",
      "Epoch 23/40\n",
      "105/105 [==============================] - 8s 75ms/step - loss: 0.5543 - accuracy: 0.7911 - val_loss: 1.1208 - val_accuracy: 0.6542\n",
      "Epoch 24/40\n",
      "105/105 [==============================] - 8s 77ms/step - loss: 0.5279 - accuracy: 0.7967 - val_loss: 1.9597 - val_accuracy: 0.5514\n",
      "Epoch 25/40\n",
      "105/105 [==============================] - 8s 75ms/step - loss: 0.5333 - accuracy: 0.8015 - val_loss: 1.4950 - val_accuracy: 0.6028\n",
      "Epoch 26/40\n",
      "105/105 [==============================] - 8s 75ms/step - loss: 0.5200 - accuracy: 0.7949 - val_loss: 1.1272 - val_accuracy: 0.7139\n",
      "Epoch 27/40\n",
      "105/105 [==============================] - 8s 75ms/step - loss: 0.4810 - accuracy: 0.8271 - val_loss: 1.1435 - val_accuracy: 0.7014\n",
      "Epoch 28/40\n",
      "105/105 [==============================] - 8s 74ms/step - loss: 0.4727 - accuracy: 0.8214 - val_loss: 0.9782 - val_accuracy: 0.7319\n",
      "Epoch 29/40\n",
      "105/105 [==============================] - 8s 75ms/step - loss: 0.4404 - accuracy: 0.8330 - val_loss: 1.2288 - val_accuracy: 0.6694\n",
      "Epoch 30/40\n",
      "105/105 [==============================] - 8s 75ms/step - loss: 0.4310 - accuracy: 0.8494 - val_loss: 1.0903 - val_accuracy: 0.6889\n",
      "Epoch 31/40\n",
      "105/105 [==============================] - 8s 76ms/step - loss: 0.4272 - accuracy: 0.8420 - val_loss: 0.9367 - val_accuracy: 0.7500\n",
      "Epoch 32/40\n",
      "105/105 [==============================] - 8s 75ms/step - loss: 0.4024 - accuracy: 0.8539 - val_loss: 0.9276 - val_accuracy: 0.7417\n",
      "Epoch 33/40\n",
      "105/105 [==============================] - 8s 76ms/step - loss: 0.4177 - accuracy: 0.8393 - val_loss: 1.0081 - val_accuracy: 0.7333\n",
      "Epoch 34/40\n",
      "105/105 [==============================] - 8s 77ms/step - loss: 0.3794 - accuracy: 0.8557 - val_loss: 0.9172 - val_accuracy: 0.7569\n",
      "Epoch 35/40\n",
      "105/105 [==============================] - 8s 77ms/step - loss: 0.3542 - accuracy: 0.8693 - val_loss: 0.9967 - val_accuracy: 0.7542\n",
      "Epoch 36/40\n",
      "105/105 [==============================] - 8s 76ms/step - loss: 0.3471 - accuracy: 0.8705 - val_loss: 1.4100 - val_accuracy: 0.6903\n",
      "Epoch 37/40\n",
      "105/105 [==============================] - 8s 76ms/step - loss: 0.3370 - accuracy: 0.8717 - val_loss: 0.8674 - val_accuracy: 0.7736\n",
      "Epoch 38/40\n",
      "105/105 [==============================] - 8s 76ms/step - loss: 0.3217 - accuracy: 0.8824 - val_loss: 1.2583 - val_accuracy: 0.7306\n",
      "Epoch 39/40\n",
      "105/105 [==============================] - 8s 76ms/step - loss: 0.3409 - accuracy: 0.8720 - val_loss: 0.8683 - val_accuracy: 0.7764\n",
      "Epoch 40/40\n",
      "105/105 [==============================] - 8s 78ms/step - loss: 0.2972 - accuracy: 0.8890 - val_loss: 1.5907 - val_accuracy: 0.6681\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train.cache(),\n",
    "  epochs=40,\n",
    "  callbacks=callbacks_list,\n",
    "  validation_data=val.cache()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 1s 16ms/step - loss: 1.6387 - accuracy: 0.6708\n",
      " 4/23 [====>.........................] - ETA: 0s - loss: 0.8061 - accuracy: 0.8281"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 15:31:16.094795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 17ms/step - loss: 0.8682 - accuracy: 0.7625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8682317137718201, 0.7625000476837158]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.evaluate(test)\n",
    "\n",
    "load_model = keras.models.load_model(\"../../models/zenodo/m4_Augmentation.h5\")\n",
    "load_model.evaluate(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
