{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning by using the VTID2 dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, utils\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../helpers/')\n",
    "from plot_graphs import plot_loss, plot_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting batch and image size, and importing the datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main dataset - Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3840 files belonging to 6 classes.\n",
      "Found 480 files belonging to 6 classes.\n",
      "Found 480 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_zenodo = utils.image_dataset_from_directory(\"../datasets/data/split/Zenodo/train\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "val_zenodo = utils.image_dataset_from_directory(\"../datasets/data/split/Zenodo/val\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "test_zenodo = utils.image_dataset_from_directory(\"../datasets/data/split/Zenodo/test\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "\n",
    "train_zenodo = train_zenodo.prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n",
    "val_zenodo = val_zenodo.prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n",
    "test_zenodo = test_zenodo.prefetch(buffer_size=tf.data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Secondary dataset - VTID2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3484 files belonging to 5 classes.\n",
      "Found 435 files belonging to 5 classes.\n",
      "Found 437 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_vtid2 = utils.image_dataset_from_directory(\"../datasets/data/split/VTID2/train\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "val_vtid2 = utils.image_dataset_from_directory(\"../datasets/data/split/VTID2/val\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "test_vtid2 = utils.image_dataset_from_directory(\"../datasets/data/split/VTID2/test\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "\n",
    "train_vtid2 = train_vtid2.prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n",
    "val_vtid2 = val_vtid2.prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n",
    "test_vtid2 = test_vtid2.prefetch(buffer_size=tf.data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating a model for the VTID2 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is the model architecture for the best model from notebook 3_tuning_model_parameters with all default hyperparameters, but ran for the VTID2 dataset which has five classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_2 (Rescaling)     (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 94, 94, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 47, 47, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 43, 43, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 21, 21, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 256)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,182,789\n",
      "Trainable params: 1,182,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 09:38:30.245316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - ETA: 0s - loss: 1.5797 - accuracy: 0.3106"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 09:38:40.856616: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 12s 97ms/step - loss: 1.5797 - accuracy: 0.3106 - val_loss: 1.4992 - val_accuracy: 0.3931\n",
      "Epoch 2/40\n",
      "109/109 [==============================] - 10s 94ms/step - loss: 1.3129 - accuracy: 0.4673 - val_loss: 1.5658 - val_accuracy: 0.4138\n",
      "Epoch 3/40\n",
      "109/109 [==============================] - 10s 93ms/step - loss: 0.9703 - accuracy: 0.6404 - val_loss: 0.7945 - val_accuracy: 0.6828\n",
      "Epoch 4/40\n",
      "109/109 [==============================] - 10s 93ms/step - loss: 0.7350 - accuracy: 0.7331 - val_loss: 0.6720 - val_accuracy: 0.7333\n",
      "Epoch 5/40\n",
      "109/109 [==============================] - 10s 94ms/step - loss: 0.5476 - accuracy: 0.8048 - val_loss: 0.4802 - val_accuracy: 0.8299\n",
      "Epoch 6/40\n",
      "109/109 [==============================] - 10s 96ms/step - loss: 0.4018 - accuracy: 0.8639 - val_loss: 0.4089 - val_accuracy: 0.8621\n",
      "Epoch 7/40\n",
      "109/109 [==============================] - 11s 97ms/step - loss: 0.2831 - accuracy: 0.9087 - val_loss: 0.3653 - val_accuracy: 0.8897\n",
      "Epoch 8/40\n",
      "109/109 [==============================] - 11s 99ms/step - loss: 0.1906 - accuracy: 0.9371 - val_loss: 0.2110 - val_accuracy: 0.9379\n",
      "Epoch 9/40\n",
      "109/109 [==============================] - 11s 99ms/step - loss: 0.1532 - accuracy: 0.9492 - val_loss: 0.5152 - val_accuracy: 0.8276\n",
      "Epoch 10/40\n",
      "109/109 [==============================] - 11s 102ms/step - loss: 0.1361 - accuracy: 0.9595 - val_loss: 0.1909 - val_accuracy: 0.9471\n",
      "Epoch 11/40\n",
      "109/109 [==============================] - 11s 103ms/step - loss: 0.2192 - accuracy: 0.9644 - val_loss: 0.2234 - val_accuracy: 0.9379\n",
      "Epoch 12/40\n",
      "109/109 [==============================] - 11s 103ms/step - loss: 0.1005 - accuracy: 0.9779 - val_loss: 0.1883 - val_accuracy: 0.9425\n",
      "Epoch 13/40\n",
      "109/109 [==============================] - 11s 103ms/step - loss: 0.1068 - accuracy: 0.9745 - val_loss: 0.1727 - val_accuracy: 0.9517\n",
      "Epoch 14/40\n",
      "109/109 [==============================] - 11s 104ms/step - loss: 0.1226 - accuracy: 0.9724 - val_loss: 0.0912 - val_accuracy: 0.9747\n",
      "Epoch 15/40\n",
      "109/109 [==============================] - 11s 103ms/step - loss: 0.0696 - accuracy: 0.9828 - val_loss: 0.2590 - val_accuracy: 0.9333\n",
      "Epoch 16/40\n",
      "109/109 [==============================] - 11s 103ms/step - loss: 0.0671 - accuracy: 0.9831 - val_loss: 0.1169 - val_accuracy: 0.9793\n",
      "Epoch 17/40\n",
      "109/109 [==============================] - 11s 102ms/step - loss: 0.0647 - accuracy: 0.9834 - val_loss: 0.4348 - val_accuracy: 0.9034\n",
      "Epoch 18/40\n",
      "109/109 [==============================] - 11s 103ms/step - loss: 0.0728 - accuracy: 0.9871 - val_loss: 0.1025 - val_accuracy: 0.9793\n",
      "Epoch 19/40\n",
      "109/109 [==============================] - 11s 104ms/step - loss: 0.0586 - accuracy: 0.9839 - val_loss: 0.0981 - val_accuracy: 0.9747\n",
      "Epoch 20/40\n",
      "109/109 [==============================] - 380s 4s/step - loss: 0.1239 - accuracy: 0.9854 - val_loss: 0.1700 - val_accuracy: 0.9793\n",
      "Epoch 21/40\n",
      "109/109 [==============================] - 10s 95ms/step - loss: 0.0716 - accuracy: 0.9891 - val_loss: 0.1422 - val_accuracy: 0.9586\n",
      "Epoch 22/40\n",
      "109/109 [==============================] - 10s 91ms/step - loss: 0.0404 - accuracy: 0.9920 - val_loss: 0.8319 - val_accuracy: 0.8943\n",
      "Epoch 23/40\n",
      "109/109 [==============================] - 10s 89ms/step - loss: 0.1042 - accuracy: 0.9854 - val_loss: 0.1753 - val_accuracy: 0.9678\n",
      "Epoch 24/40\n",
      "109/109 [==============================] - 10s 90ms/step - loss: 0.0447 - accuracy: 0.9902 - val_loss: 0.1592 - val_accuracy: 0.9632\n",
      "Epoch 25/40\n",
      "109/109 [==============================] - 10s 90ms/step - loss: 0.0647 - accuracy: 0.9859 - val_loss: 0.1713 - val_accuracy: 0.9655\n",
      "Epoch 26/40\n",
      "109/109 [==============================] - 10s 90ms/step - loss: 0.0332 - accuracy: 0.9917 - val_loss: 0.2171 - val_accuracy: 0.9655\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "model_5_vtid2 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_5_vtid2.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_5_vtid2.summary()\n",
    "\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=10\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"../models/5_vtid2.h5\",\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history_5_vtid2 = model_5_vtid2.fit(\n",
    "  train_vtid2,\n",
    "  epochs=40,\n",
    "  callbacks=callbacks_list,\n",
    "  validation_data=val_vtid2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 09:59:53.551749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 35ms/step - loss: 0.2059 - accuracy: 0.9817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2059335559606552, 0.9816934466362]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_vtid2 = keras.models.load_model(\"../models/5_vtid2.h5\")\n",
    "load_vtid2.evaluate(test_vtid2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This model worked extremely well for the VTID2 dataset with a test accuracy of 98.17%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Partially trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Importing the trained VTID2 model shown in the section above, and training it from the 4th Conv2D layer onwards for the Zenodo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_2 (Rescaling)     (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 94, 94, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 47, 47, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 43, 43, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 21, 21, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 256)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " classifier (Dense)          (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,183,046\n",
      "Trainable params: 1,163,654\n",
      "Non-trainable params: 19,392\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vtid2 = keras.models.load_model('../models/5_vtid2.h5')\n",
    "vtid2.layers\n",
    "vtid2.trainable = False\n",
    "\n",
    "for layer in vtid2.layers[6:]:\n",
    "  layer.trainable = True\n",
    "\n",
    "x = vtid2.layers[-2].output\n",
    "outputs = layers.Dense(6, activation='softmax', name='classifier')(x)\n",
    "model_partially_trained = keras.Model(vtid2.inputs, outputs)\n",
    "model_partially_trained.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_partially_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 10:01:14.609316: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1.0543 - accuracy: 0.6063"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 10:01:22.463792: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 9s 64ms/step - loss: 1.0543 - accuracy: 0.6063 - val_loss: 0.5408 - val_accuracy: 0.8146\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.4615 - accuracy: 0.8383 - val_loss: 0.3878 - val_accuracy: 0.8604\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.2782 - accuracy: 0.9042 - val_loss: 0.3359 - val_accuracy: 0.8813\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.1747 - accuracy: 0.9391 - val_loss: 0.3709 - val_accuracy: 0.9021\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.1524 - accuracy: 0.9549 - val_loss: 0.4003 - val_accuracy: 0.8875\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 7s 60ms/step - loss: 0.0951 - accuracy: 0.9690 - val_loss: 1.9205 - val_accuracy: 0.7729\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 7s 61ms/step - loss: 0.0977 - accuracy: 0.9763 - val_loss: 0.4025 - val_accuracy: 0.9167\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0816 - accuracy: 0.9773 - val_loss: 0.2582 - val_accuracy: 0.9354\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0883 - accuracy: 0.9784 - val_loss: 0.3718 - val_accuracy: 0.9250\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 7s 62ms/step - loss: 0.0719 - accuracy: 0.9815 - val_loss: 0.4067 - val_accuracy: 0.9167\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 8s 63ms/step - loss: 0.0585 - accuracy: 0.9833 - val_loss: 0.4232 - val_accuracy: 0.9313\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.0756 - accuracy: 0.9826 - val_loss: 0.3731 - val_accuracy: 0.9438\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.0606 - accuracy: 0.9857 - val_loss: 0.3784 - val_accuracy: 0.9313\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 8s 64ms/step - loss: 0.0507 - accuracy: 0.9867 - val_loss: 0.3913 - val_accuracy: 0.9354\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.0616 - accuracy: 0.9893 - val_loss: 0.3597 - val_accuracy: 0.9521\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 8s 66ms/step - loss: 0.0645 - accuracy: 0.9867 - val_loss: 0.4973 - val_accuracy: 0.9458\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.0690 - accuracy: 0.9841 - val_loss: 0.5385 - val_accuracy: 0.9250\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.0478 - accuracy: 0.9870 - val_loss: 0.4034 - val_accuracy: 0.9479\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 8s 67ms/step - loss: 0.0332 - accuracy: 0.9917 - val_loss: 0.4759 - val_accuracy: 0.9479\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.0505 - accuracy: 0.9898 - val_loss: 0.8241 - val_accuracy: 0.9083\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 8s 69ms/step - loss: 0.0658 - accuracy: 0.9883 - val_loss: 0.6492 - val_accuracy: 0.8938\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 8s 68ms/step - loss: 0.0614 - accuracy: 0.9880 - val_loss: 0.6757 - val_accuracy: 0.9375\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.0406 - accuracy: 0.9930 - val_loss: 0.4350 - val_accuracy: 0.9396\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.0573 - accuracy: 0.9901 - val_loss: 0.8063 - val_accuracy: 0.8917\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 8s 70ms/step - loss: 0.0754 - accuracy: 0.9906 - val_loss: 0.5343 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=10\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"../models/5_partially_trainable.h5\",\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history_partially_trained = model_partially_trained.fit(\n",
    "  train_zenodo,\n",
    "  epochs=50,\n",
    "  callbacks=callbacks_list,\n",
    "  validation_data=val_zenodo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 10:07:22.997842: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 31ms/step - loss: 0.5899 - accuracy: 0.9146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5899118781089783, 0.9145833849906921]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_partially_trainable = keras.models.load_model(\"../models/5_partially_trainable.h5\")\n",
    "load_partially_trainable.evaluate(test_zenodo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This gives a test accuracy of 91.46% which definitely does not beat the best model for the Zenodo dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. All Trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this model, we again use the trained VTID2 model from section 1 of this notebook, but this time, set all layer to trainable and train it on the Zenodo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_2 (Rescaling)     (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 94, 94, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 47, 47, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 43, 43, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 21, 21, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 256)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " classifier (Dense)          (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,183,046\n",
      "Trainable params: 1,183,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vtid2 = keras.models.load_model('../models/5_vtid2.h5')\n",
    "\n",
    "x = vtid2.layers[-2].output\n",
    "outputs = keras.layers.Dense(6, activation='softmax', name='classifier')(x)\n",
    "all_trainable = keras.Model(vtid2.inputs, outputs)\n",
    "all_trainable.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "all_trainable.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 10:11:45.516599: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1.0694 - accuracy: 0.6031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 10:11:56.982958: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 12s 93ms/step - loss: 1.0694 - accuracy: 0.6031 - val_loss: 0.5586 - val_accuracy: 0.8021\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.4844 - accuracy: 0.8276 - val_loss: 0.4009 - val_accuracy: 0.8458\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.2913 - accuracy: 0.9068 - val_loss: 0.2875 - val_accuracy: 0.8833\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.1954 - accuracy: 0.9331 - val_loss: 1.2331 - val_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.1555 - accuracy: 0.9518 - val_loss: 0.3250 - val_accuracy: 0.9021\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 11s 92ms/step - loss: 0.1772 - accuracy: 0.9560 - val_loss: 0.2584 - val_accuracy: 0.9083\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 11s 92ms/step - loss: 0.1017 - accuracy: 0.9669 - val_loss: 0.5204 - val_accuracy: 0.8708\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.1081 - accuracy: 0.9688 - val_loss: 0.2529 - val_accuracy: 0.9292\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 11s 95ms/step - loss: 0.0835 - accuracy: 0.9724 - val_loss: 0.2463 - val_accuracy: 0.9271\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 12s 96ms/step - loss: 0.0687 - accuracy: 0.9815 - val_loss: 0.2975 - val_accuracy: 0.9229\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 12s 98ms/step - loss: 0.0748 - accuracy: 0.9797 - val_loss: 0.2187 - val_accuracy: 0.9396\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 12s 98ms/step - loss: 0.0735 - accuracy: 0.9846 - val_loss: 0.2021 - val_accuracy: 0.9354\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 12s 99ms/step - loss: 0.0814 - accuracy: 0.9807 - val_loss: 0.2367 - val_accuracy: 0.9333\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 0.0754 - accuracy: 0.9826 - val_loss: 0.2844 - val_accuracy: 0.9458\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 0.0828 - accuracy: 0.9805 - val_loss: 0.2781 - val_accuracy: 0.9396\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 12s 99ms/step - loss: 0.0671 - accuracy: 0.9857 - val_loss: 0.2522 - val_accuracy: 0.9458\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 0.0833 - accuracy: 0.9849 - val_loss: 0.2028 - val_accuracy: 0.9458\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 0.0547 - accuracy: 0.9880 - val_loss: 0.4628 - val_accuracy: 0.9146\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 0.0555 - accuracy: 0.9867 - val_loss: 0.4176 - val_accuracy: 0.9333\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.0724 - accuracy: 0.9823 - val_loss: 0.4600 - val_accuracy: 0.9208\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.0570 - accuracy: 0.9867 - val_loss: 0.3020 - val_accuracy: 0.9396\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.0519 - accuracy: 0.9883 - val_loss: 0.3782 - val_accuracy: 0.9208\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 0.0416 - accuracy: 0.9885 - val_loss: 0.3141 - val_accuracy: 0.9521\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.0611 - accuracy: 0.9880 - val_loss: 0.3701 - val_accuracy: 0.9417\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.0592 - accuracy: 0.9885 - val_loss: 0.4038 - val_accuracy: 0.9417\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.0447 - accuracy: 0.9901 - val_loss: 0.3614 - val_accuracy: 0.9479\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.0444 - accuracy: 0.9935 - val_loss: 0.4901 - val_accuracy: 0.9250\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.0564 - accuracy: 0.9904 - val_loss: 0.3430 - val_accuracy: 0.9542\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.0647 - accuracy: 0.9893 - val_loss: 1.1347 - val_accuracy: 0.8896\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.0415 - accuracy: 0.9935 - val_loss: 0.5161 - val_accuracy: 0.9542\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.0524 - accuracy: 0.9885 - val_loss: 0.4510 - val_accuracy: 0.9521\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.0642 - accuracy: 0.9901 - val_loss: 0.4581 - val_accuracy: 0.9521\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.0616 - accuracy: 0.9896 - val_loss: 0.3593 - val_accuracy: 0.9521\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 0.0501 - accuracy: 0.9898 - val_loss: 0.3886 - val_accuracy: 0.9479\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 0.0476 - accuracy: 0.9901 - val_loss: 0.7676 - val_accuracy: 0.9229\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 0.0651 - accuracy: 0.9932 - val_loss: 0.3441 - val_accuracy: 0.9563\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 14s 119ms/step - loss: 0.0497 - accuracy: 0.9930 - val_loss: 0.3782 - val_accuracy: 0.9375\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 14s 120ms/step - loss: 0.0447 - accuracy: 0.9924 - val_loss: 0.4980 - val_accuracy: 0.9417\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 139s 1s/step - loss: 0.0493 - accuracy: 0.9898 - val_loss: 0.6534 - val_accuracy: 0.9354\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 12s 98ms/step - loss: 0.0343 - accuracy: 0.9924 - val_loss: 0.8835 - val_accuracy: 0.9333\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.0481 - accuracy: 0.9930 - val_loss: 0.5706 - val_accuracy: 0.9375\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 11s 92ms/step - loss: 0.0580 - accuracy: 0.9919 - val_loss: 0.3252 - val_accuracy: 0.9563\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.0310 - accuracy: 0.9956 - val_loss: 0.7188 - val_accuracy: 0.9167\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 11s 92ms/step - loss: 0.0473 - accuracy: 0.9940 - val_loss: 0.4039 - val_accuracy: 0.9604\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.0584 - accuracy: 0.9924 - val_loss: 1.4947 - val_accuracy: 0.8979\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.0432 - accuracy: 0.9930 - val_loss: 0.7771 - val_accuracy: 0.9188\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.0251 - accuracy: 0.9956 - val_loss: 0.7534 - val_accuracy: 0.9438\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 11s 96ms/step - loss: 0.0469 - accuracy: 0.9951 - val_loss: 0.9290 - val_accuracy: 0.9375\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 12s 98ms/step - loss: 0.0565 - accuracy: 0.9914 - val_loss: 0.5093 - val_accuracy: 0.9292\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 12s 99ms/step - loss: 0.0205 - accuracy: 0.9958 - val_loss: 1.0841 - val_accuracy: 0.9417\n"
     ]
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=10\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"../models/5_all_trainable.h5\",\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history_all_trainable = all_trainable.fit(\n",
    "  train_zenodo,\n",
    "  epochs=50,\n",
    "  callbacks=callbacks_list,\n",
    "  validation_data=val_zenodo\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 32ms/step - loss: 0.5740 - accuracy: 0.9438\n",
      " 1/15 [=>............................] - ETA: 2s - loss: 0.5552 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 10:24:56.086883: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 1s 31ms/step - loss: 0.5740 - accuracy: 0.9438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5739955306053162, 0.9437500238418579]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trainable_model = keras.models.load_model(\"../models/5_all_trainable.h5\")\n",
    "all_trainable_model.evaluate(test_zenodo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This model gives a test accuracy of 94.38% which is excellent, and comes very close to the best accuracy of Zenodo model. But the fact remains that despite using transfer learning, it does not beat the best accuracy of the best Zenodo model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
