{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning hyperparameters and model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This section will have many models and in each iteration, we will change different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, utils\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../helpers/')\n",
    "from plot_graphs import plot_loss, plot_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting batch and image size, and importing the datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3840 files belonging to 6 classes.\n",
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Found 480 files belonging to 6 classes.\n",
      "Found 480 files belonging to 6 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 01:28:53.902080: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-08-29 01:28:53.902254: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train = utils.image_dataset_from_directory(\"../datasets/data/split/Zenodo/train\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "val = utils.image_dataset_from_directory(\"../datasets/data/split/Zenodo/val\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "test = utils.image_dataset_from_directory(\"../datasets/data/split/Zenodo/test\", image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE)\n",
    "\n",
    "train = train.prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n",
    "val = val.prefetch(buffer_size=tf.data.AUTOTUNE).cache()\n",
    "test = test.prefetch(buffer_size=tf.data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Finding ideal model architecture, dropout rate, and no. of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Experiment with layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding more layers than baseline model with larger layer size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 23, 23, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 389,958\n",
      "Trainable params: 389,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 01:28:58.291947: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-08-29 01:28:58.292054: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1.6876 - accuracy: 0.2883"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 01:29:03.947858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 6s 46ms/step - loss: 1.6876 - accuracy: 0.2883 - val_loss: 1.3303 - val_accuracy: 0.5208\n",
      "Epoch 2/25\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 1.3415 - accuracy: 0.4667 - val_loss: 1.1628 - val_accuracy: 0.5625\n",
      "Epoch 3/25\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 1.1519 - accuracy: 0.5531 - val_loss: 1.0342 - val_accuracy: 0.6104\n",
      "Epoch 4/25\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 1.0114 - accuracy: 0.6203 - val_loss: 0.8923 - val_accuracy: 0.6750\n",
      "Epoch 5/25\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.8836 - accuracy: 0.6685 - val_loss: 0.7515 - val_accuracy: 0.7396\n",
      "Epoch 6/25\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.7701 - accuracy: 0.7224 - val_loss: 0.6223 - val_accuracy: 0.7854\n",
      "Epoch 7/25\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.6698 - accuracy: 0.7648 - val_loss: 0.5715 - val_accuracy: 0.8021\n",
      "Epoch 8/25\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.5891 - accuracy: 0.7940 - val_loss: 0.5470 - val_accuracy: 0.8042\n",
      "Epoch 9/25\n",
      "120/120 [==============================] - 5s 42ms/step - loss: 0.5231 - accuracy: 0.8177 - val_loss: 0.4746 - val_accuracy: 0.8313\n",
      "Epoch 10/25\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.4759 - accuracy: 0.8279 - val_loss: 0.4131 - val_accuracy: 0.8563\n",
      "Epoch 11/25\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.4236 - accuracy: 0.8513 - val_loss: 0.3950 - val_accuracy: 0.8583\n",
      "Epoch 12/25\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.3831 - accuracy: 0.8607 - val_loss: 0.3422 - val_accuracy: 0.8771\n",
      "Epoch 13/25\n",
      "120/120 [==============================] - 5s 43ms/step - loss: 0.3419 - accuracy: 0.8768 - val_loss: 0.4104 - val_accuracy: 0.8646\n",
      "Epoch 14/25\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.3100 - accuracy: 0.8885 - val_loss: 0.3086 - val_accuracy: 0.8792\n",
      "Epoch 15/25\n",
      "120/120 [==============================] - 5s 44ms/step - loss: 0.2692 - accuracy: 0.9031 - val_loss: 0.3636 - val_accuracy: 0.8667\n",
      "Epoch 16/25\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.2672 - accuracy: 0.9086 - val_loss: 0.3370 - val_accuracy: 0.8667\n",
      "Epoch 17/25\n",
      "120/120 [==============================] - 6s 48ms/step - loss: 0.2396 - accuracy: 0.9208 - val_loss: 0.2868 - val_accuracy: 0.8896\n",
      "Epoch 18/25\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.2105 - accuracy: 0.9294 - val_loss: 0.2688 - val_accuracy: 0.9000\n",
      "Epoch 19/25\n",
      "120/120 [==============================] - 5s 45ms/step - loss: 0.1760 - accuracy: 0.9419 - val_loss: 0.3833 - val_accuracy: 0.8667\n",
      "Epoch 20/25\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.1785 - accuracy: 0.9385 - val_loss: 0.3098 - val_accuracy: 0.8917\n",
      "Epoch 21/25\n",
      "120/120 [==============================] - 5s 46ms/step - loss: 0.1581 - accuracy: 0.9435 - val_loss: 0.2964 - val_accuracy: 0.9000\n",
      "Epoch 22/25\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.1445 - accuracy: 0.9521 - val_loss: 0.2411 - val_accuracy: 0.9167\n",
      "Epoch 23/25\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.1427 - accuracy: 0.9529 - val_loss: 0.3740 - val_accuracy: 0.8875\n",
      "Epoch 24/25\n",
      "120/120 [==============================] - 6s 47ms/step - loss: 0.1339 - accuracy: 0.9529 - val_loss: 0.2560 - val_accuracy: 0.9188\n",
      "Epoch 25/25\n",
      "120/120 [==============================] - 6s 46ms/step - loss: 0.1351 - accuracy: 0.9602 - val_loss: 0.3062 - val_accuracy: 0.9104\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model_1_1 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_1_1.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_1_1.summary()\n",
    "\n",
    "history_1_1 = model_1_1.fit(\n",
    "  train,\n",
    "  epochs=25,\n",
    "  validation_data=val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzJ0lEQVR4nO3de7xNZf7A8c8XB8klt5oiDo1LhEOHFEnTNFIGSRedSExodNNMZVIxGs1Upl8p1eimi5JJmS66jErSZXJIomjIIV2EBkeHcHx/fzzrsB1777P3Pnudffu+X6/z2nuv/ay1vmtv1nev53nW84iqYowxJnNVSnQAxhhjEssSgTHGZDhLBMYYk+EsERhjTIazRGCMMRnOEoExxmQ4SwQmrkTkNRG5NN5lE0lECkTk1z5sV0Xkl97zh0TklkjKxrCfPBF5M9Y4w2y3p4hsiPd2TcWrkugATOKJyI6AlzWAn4Fi7/VIVZ0R6bZUtbcfZdOdqo6Kx3ZEJBtYC2Sp6l5v2zOAiL9Dk3ksERhUtWbJcxEpAH6nqvNKlxORKiUnF2NM+rCqIRNSyaW/iNwoIt8Dj4tIXRF5RUQ2icj/vOeNA9aZLyK/854PFZGFIjLZK7tWRHrHWLaZiCwQkUIRmSciU0Xk6RBxRxLjbSLyvre9N0WkQcD7g0VknYhsEZFxYT6friLyvYhUDlh2rogs8553EZEPRWSriHwnIveLSNUQ25ouIn8JeH29t863IjKsVNlzROQTEdkuIl+LyISAtxd4j1tFZIeInFzy2Qasf4qILBKRbd7jKZF+NuGIyPHe+ltFZIWI9A1472wR+dzb5jci8kdveQPv+9kqIj+KyHsiYuelCmYfuCnLL4B6QFNgBO7fzOPe6ybATuD+MOufBKwCGgB3Ao+KiMRQ9hngY6A+MAEYHGafkcR4MXAZcCRQFSg5MbUBHvS2f4y3v8YEoaofAT8Bvyq13We858XAGO94TgbOAH4fJm68GM7y4jkTaAGUbp/4CRgCHAGcA1whIv2993p4j0eoak1V/bDUtusBrwJTvGO7G3hVROqXOoZDPpsyYs4CXgbe9Na7CpghIq28Io/iqhlrAScAb3vL/wBsABoCRwE3ATbuTQWzRGDKsg8Yr6o/q+pOVd2iqrNVtUhVC4FJwGlh1l+nqg+rajHwBHA07j98xGVFpAnQGbhVVXer6kLgpVA7jDDGx1X1S1XdCcwCcrzlA4FXVHWBqv4M3OJ9BqE8CwwCEJFawNneMlR1sap+pKp7VbUA+EeQOIK5wItvuar+hEt8gcc3X1U/U9V9qrrM218k2wWXOP6rqk95cT0LrAR+G1Am1GcTTlegJvA37zt6G3gF77MB9gBtRKS2qv5PVZcELD8aaKqqe1T1PbUB0CqcJQJTlk2quqvkhYjUEJF/eFUn23FVEUcEVo+U8n3JE1Ut8p7WjLLsMcCPAcsAvg4VcIQxfh/wvCggpmMCt+2diLeE2hfu1/8AEakGDACWqOo6L46WXrXH914ct+OuDspyUAzAulLHd5KIvONVfW0DRkW43ZJtryu1bB3QKOB1qM+mzJhVNTBpBm73PFySXCci74rIyd7yu4DVwJsi8pWIjI3sMEw8WSIwZSn96+wPQCvgJFWtzYGqiFDVPfHwHVBPRGoELDs2TPnyxPhd4La9fdYPVVhVP8ed8HpzcLUQuCqmlUALL46bYokBV70V6BncFdGxqloHeChgu2X9mv4WV2UWqAnwTQRxlbXdY0vV7+/frqouUtV+uGqjObgrDVS1UFX/oKrNcVcl14nIGeWMxUTJEoGJVi1cnftWr755vN879H5h5wMTRKSq92vyt2FWKU+MzwN9RKS717A7kbL/nzwDXI1LOP8sFcd2YIeItAauiDCGWcBQEWnjJaLS8dfCXSHtEpEuuARUYhOuKqt5iG3PBVqKyMUiUkVELgTa4KpxyuM/uLaLG0QkS0R64r6jmd53licidVR1D+4zKQYQkT4i8kuvLahkeXHQPRjfWCIw0boHOAzYDHwEvF5B+83DNbhuAf4CPIe73yGYe4gxRlVdAYzGndy/A/6Ha8wM51mgJ/C2qm4OWP5H3Em6EHjYizmSGF7zjuFtXLXJ26WK/B6YKCKFwK14v669dYtwbSLvez1xupba9hagD+6qaQtwA9CnVNxRU9XdQF/cldFm4AFgiKqu9IoMBgq8KrJRwCXe8hbAPGAH8CHwgKrOL08sJnpi7TImFYnIc8BKVfX9isSYdGdXBCYliEhnETlORCp53Sv74eqajTHlZHcWm1TxC+AFXMPtBuAKVf0ksSEZkx6sasgYYzKcVQ0ZY0yGS7mqoQYNGmh2dnaiwzDGmJSyePHizaraMNh7KZcIsrOzyc/PT3QYxhiTUkSk9B3l+1nVkDHGZDhLBMYYk+EsERhjTIZLuTYCY0zF27NnDxs2bGDXrl1lFzYJVb16dRo3bkxWVlbE61giMMaUacOGDdSqVYvs7GxCzytkEk1V2bJlCxs2bKBZs2YRr5cRVUMzZkB2NlSq5B5n2DTexkRl165d1K9f35JAkhMR6tevH/WVW9pfEcyYASNGQJE3pcm6de41QF5e4uIyJtVYEkgNsXxPaX9FMG7cgSRQoqjILTfGGJMBiWD9+uiWG2OSz5YtW8jJySEnJ4df/OIXNGrUaP/r3bt3h103Pz+fq6++usx9nHLKKXGJdf78+fTp0ycu26ooaZ8ImpSe5K+M5caY8ot3u1z9+vVZunQpS5cuZdSoUYwZM2b/66pVq7J3796Q6+bm5jJlypQy9/HBBx+UL8gUlvaJYNIkqFHj4GU1arjlxpj4K2mXW7cOVA+0y8W7k8bQoUO57rrrOP3007nxxhv5+OOPOeWUU+jYsSOnnHIKq1atAg7+hT5hwgSGDRtGz549ad68+UEJombNmvvL9+zZk4EDB9K6dWvy8vIoGaV57ty5tG7dmu7du3P11VeX+cv/xx9/pH///rRv356uXbuybNkyAN599939VzQdO3aksLCQ7777jh49epCTk8MJJ5zAe++9F98PLIy0bywuaRAeN85VBzVp4pKANRQb449w7XLx/n/35ZdfMm/ePCpXrsz27dtZsGABVapUYd68edx0003Mnj37kHVWrlzJO++8Q2FhIa1ateKKK644pM/9J598wooVKzjmmGPo1q0b77//Prm5uYwcOZIFCxbQrFkzBg0aVGZ848ePp2PHjsyZM4e3336bIUOGsHTpUiZPnszUqVPp1q0bO3bsoHr16kybNo1evXoxbtw4iouLKSr9Ifoo7RMBuH98duI3pmJUZLvc+eefT+XKlQHYtm0bl156Kf/9738REfbs2RN0nXPOOYdq1apRrVo1jjzySDZu3Ejjxo0PKtOlS5f9y3JycigoKKBmzZo0b958f//8QYMGMW3atLDxLVy4cH8y+tWvfsWWLVvYtm0b3bp147rrriMvL48BAwbQuHFjOnfuzLBhw9izZw/9+/cnJyenPB9NVNK+asgYU7Eqsl3u8MMP3//8lltu4fTTT2f58uW8/PLLIfvSV6tWbf/zypUrB21fCFYmlkm8gq0jIowdO5ZHHnmEnTt30rVrV1auXEmPHj1YsGABjRo1YvDgwTz55JNR7y9WlgiMMXGVqHa5bdu20ahRIwCmT58e9+23bt2ar776ioKCAgCee+65Mtfp0aMHM7zGkfnz59OgQQNq167NmjVraNeuHTfeeCO5ubmsXLmSdevWceSRR3L55ZczfPhwlixZEvdjCMUSgTEmrvLyYNo0aNoURNzjtGn+V8/ecMMN/OlPf6Jbt24UFxfHffuHHXYYDzzwAGeddRbdu3fnqKOOok6dOmHXmTBhAvn5+bRv356xY8fyxBNPAHDPPfdwwgkn0KFDBw477DB69+7N/Pnz9zcez549m2uuuSbuxxCKb3MWi8hjQB/gB1U9IUSZnsA9QBawWVVPK2u7ubm5ahPTGFOxvvjiC44//vhEh5FwO3bsoGbNmqgqo0ePpkWLFowZMybRYR0i2PclIotVNTdYeT+vCKYDZ4V6U0SOAB4A+qpqW+B8H2Mxxphye/jhh8nJyaFt27Zs27aNkSNHJjqkuPCt15CqLhCR7DBFLgZeUNX1Xvkf/IrFGGPiYcyYMUl5BVBeiWwjaAnUFZH5IrJYRIaEKigiI0QkX0TyN23aVIEhGmNM+ktkIqgCnAicA/QCbhGRlsEKquo0Vc1V1dyGDRtWZIzGGJP2EnlD2QZcA/FPwE8isgDoAHyZwJiMMSbjJPKK4F/AqSJSRURqACcBXyQwHmOMyUi+JQIReRb4EGglIhtEZLiIjBKRUQCq+gXwOrAM+Bh4RFWX+xWPMSZ19ezZkzfeeOOgZffccw+///3vw65T0tX87LPPZuvWrYeUmTBhApMnTw677zlz5vD555/vf33rrbcyb968KKIPLpmGq/az11CZIzKp6l3AXX7FYIxJD4MGDWLmzJn06tVr/7KZM2dy112RnT7mzp0b877nzJlDnz59aNOmDQATJ06MeVvJyu4sNsYkvYEDB/LKK6/w888/A1BQUMC3335L9+7dueKKK8jNzaVt27aMHz8+6PrZ2dls3rwZgEmTJtGqVSt+/etf7x+qGtw9Ap07d6ZDhw6cd955FBUV8cEHH/DSSy9x/fXXk5OTw5o1axg6dCjPP/88AG+99RYdO3akXbt2DBs2bH982dnZjB8/nk6dOtGuXTtWrlwZ9vgSPVx1Row+aoyJn2uvhaVL47vNnBy4557Q79evX58uXbrw+uuv069fP2bOnMmFF16IiDBp0iTq1atHcXExZ5xxBsuWLaN9+/ZBt7N48WJmzpzJJ598wt69e+nUqRMnnngiAAMGDODyyy8H4Oabb+bRRx/lqquuom/fvvTp04eBAwcetK1du3YxdOhQ3nrrLVq2bMmQIUN48MEHufbaawFo0KABS5Ys4YEHHmDy5Mk88sgjIY8v0cNV2xWBMSYllFQPgasWKpkPYNasWXTq1ImOHTuyYsWKg+rzS3vvvfc499xzqVGjBrVr16Zv377731u+fDmnnnoq7dq1Y8aMGaxYsSJsPKtWraJZs2a0bOl6vV966aUsWLBg//sDBgwA4MQTT9w/UF0oCxcuZPDgwUDw4aqnTJnC1q1bqVKlCp07d+bxxx9nwoQJfPbZZ9SqVSvstiNhVwTGmKiE++Xup/79+3PdddexZMkSdu7cSadOnVi7di2TJ09m0aJF1K1bl6FDh4YcfrqEiARdPnToUObMmUOHDh2YPn068+fPD7udssZpKxnKOtRQ12Vtq2S46nPOOYe5c+fStWtX5s2bt3+46ldffZXBgwdz/fXXM2RIyPtxI2JXBMaYlFCzZk169uzJsGHD9l8NbN++ncMPP5w6deqwceNGXnvttbDb6NGjBy+++CI7d+6ksLCQl19+ef97hYWFHH300ezZs2f/0NEAtWrVorCw8JBttW7dmoKCAlavXg3AU089xWmnlTluZsi4EjlctV0RGGNSxqBBgxgwYMD+KqIOHTrQsWNH2rZtS/PmzenWrVvY9Tt16sSFF15ITk4OTZs25dRTT93/3m233cZJJ51E06ZNadeu3f6T/0UXXcTll1/OlClT9jcSA1SvXp3HH3+c888/n71799K5c2dGjRoV03FNmDCByy67jPbt21OjRo2Dhqt+5513qFy5Mm3atKF37977e0tlZWVRs2bNuExg49sw1H6xYaiNqXg2DHVqSaZhqI0xxqQASwTGGJPhLBEYYyKSatXImSqW78kSgTGmTNWrV2fLli2WDJKcqrJlyxaqV68e1XrWa8gYU6bGjRuzYcMGbGKo5Fe9enUaN24c1TqWCIwxZcrKyqJZs2aJDsP4xKqGjDEmw1kiMMaYDGeJwBhjMpwlAmOMyXB+TlX5mIj8ICJhp58Ukc4iUiwiA8OVM8YY4w8/rwimA2eFKyAilYE7gDfClTPGGOMf3xKBqi4Afiyj2FXAbOAHv+IwxhgTXsLaCESkEXAu8FAEZUeISL6I5NsNLcYYE1+JbCy+B7hRVYvLKqiq01Q1V1VzGzZs6H9kxhiTQRJ5Z3EuMNObNq4BcLaI7FXVOQmMyRhjMk7CEoGq7r9fXUSmA69YEjDGmIrnZ/fRZ4EPgVYiskFEhovIKBGJbS63CjZjBmRnQ6VK7jFgClNjjEkrvl0RqOqgKMoO9SuOWMyYASNGQFGRe71unXsNkJeXuLiMMcYPdmdxEOPGHUgCJYqK3HJjjEk3GZUI1q6NrNz69dEtN8aYVJYxieCpp6BFC1i6tOyyTZpEt9wYY1JZxiSCPn2gXj248kooa7a9SZOgRo2Dl9Wo4ZYbY0y6yZhEULcu/O1v8P778PTT4cvm5cG0adC0KYi4x2nTrKHYGJOeJNUmo87NzdX8/PyY1t23D04+2fUC+vJLqF07zsEZY0ySEpHFqpob7L2MuSIAd0/A1Knwww8wYUKiozHGmOSQUYkAIDcXLr8cpkyBFSsSHY0xxiRexiUCcI2+tWvDVVeV3XBsjDHpLiMTQYMGLhm88w7MmpXoaIwxJrEyMhGAGzKiY0f4wx9gx45ER2OMMYmTsYmgcmXXcPzNN3Z/gDEms2VsIgDXlXToUPj732HVqkRHY4wxiZHRiQDcTWaHHQZXX20Nx8aYzJTxieCoo2DiRHjzTZgzJ9HRGGNMxcv4RAAwejSccAKMGXPo8NPGGJPu/Jyh7DER+UFElod4P09Elnl/H4hIB79iKUuVKnD//W7oiTvuSFQUxhiTGH5eEUwHzgrz/lrgNFVtD9wGTPMxljKddhoMGuQSwZo1iYzEGGMqlm+JQFUXAD+Gef8DVf2f9/IjoLFfsURq8mTIynJVRMYYkymSpY1gOPBaqDdFZISI5ItI/qZNm3wL4phj4NZb4eWX4dVXfduNMcYkFV+HoRaRbOAVVT0hTJnTgQeA7qq6paxtlmcY6kjs3g0dOsCePbB8OVSv7tuujDGmwiTtMNQi0h54BOgXSRKoCFWrupFJ16xxN5oZY0y6S1giEJEmwAvAYFX9MlFxBHPmmXDeeW7oiWgmrJ8xA7Kz3bwH2dnutTHGJDs/u48+C3wItBKRDSIyXERGicgor8itQH3gARFZKiL+1ffE4O673WOkdxzPmOEGslu3zpVft869tmRgjEl2GTVVZbQmT4brr4d773UJIZzsbHfyL61pUygo8CM6Y4yJXNK2ESS7666Dvn3dUNUffBC+bKgqpGiqlowxJhEsEYRRqRI88YT7VX/++bBxY+iyTZpEt9wYY5KFJYIyHHEEzJ4NP/7o7jzeuzd4uUmToEaNg5fVqGFzHRhjkp8lggh06AAPPeSmtrzlluBl8vJg2jR39SDiHqdNc8uNMSaZWWNxFEaOdCf3OXOgX7+EhGCMMTGxxuI4ufdeyM2FIUNg9epER2OMMfFhiSAK1avD88+7YavPO8/mLjDGpAdLBFFq2tTdJPbZZzBqlE1vaYxJfZYIYnDWWTB+PDz1lGszMMaYVGaJIEa33OISwtVXw6JFiY7GGGNiZ4kgRpUqwdNPw9FHw8CBsHlzoiMyxpjYWCIoh/r1XePx99+7+wWKixMdkTHGRM8SQTnl5rqJ7998EyZOTHQ0xhgTPUsEcfC738HQoS4RzJ2b6GiMMSY6lgjiQASmTnVDUVxyCaxdm+iIjDEmcpYI4qRGDTc43b59rr0g1OB0gWxGM2NMMrBEEEfHHecGp/vwQ/jrX8OXtRnNjDHJws+pKh8TkR9EZHmI90VEpojIahFZJiKd/IqlIl10kbsi+POf4eOPQ5cbN+7QISqKitxyY4ypSH5eEUwHzgrzfm+ghfc3AnjQx1gq1P33wzHHuISwY0fwMjajmTEmWfiWCFR1AfBjmCL9gCfV+Qg4QkSO9iueinTEEfDkk7BmjZvmMhib0cwYkywS2UbQCPg64PUGb9khRGSEiOSLSP6mTZsqJLjy6tnTTXw/bRq89NKh79uMZsaYZJHIRCBBlgUdy1NVp6lqrqrmNmzY0Oew4mfiRMjJcfcZlJ7v2GY0M8Yki0Qmgg3AsQGvGwPfJigWX1Sr5noBFRbC8OGHDlmdlwcFBa7LaUGBJQFjTGJElAhE5HARqeQ9bykifUUkq5z7fgkY4vUe6gpsU9XvyrnNpNOmDdx5J7z6KvzjH4mOxhhjDhXpFcECoLqINALeAi7D9QoKSUSeBT4EWonIBhEZLiKjRGSUV2Qu8BWwGngY+H0M8aeE0aOhVy+47jpYtSrR0RhjzMGqRFhOVLVIRIYD96nqnSLySbgVVHVQGe8rMDrC/ae0SpXgscegfXtX/fPhh5BV3uspY4yJk0ivCERETgbygFe9ZZEmEYO7r2DaNFi82N1sZowxySLSRHAt8CfgRVVdISLNgXd8iypNDRgAl13mhp9YuDDR0RhjjCMa5ezrXqNxTVXd7k9I4eXm5mp+fn4idh0XhYWuS+m+ffDpp1C7dqIjMsZkAhFZrKq5wd6LtNfQMyJSW0QOBz4HVonI9fEMMlPUquUmvV+/Hq65JtHRGGNM5FVDbbwrgP643j5NgMF+BZXuTjnFDS43fbqb6tIYYxIp0kSQ5d030B/4l6ruIcRdwCYyt9wCnTvDyJHwzTeJjsYYk8kiTQT/AAqAw4EFItIUSEgbQbrIyoKnn4Zdu9w0l/v2RbaeTWZjjIm3iBKBqk5R1UaqerY3Wug64HSfY0t7LVvC//0fzJsHU6aUXd4mszHG+CGiXkMiUgcYD/TwFr0LTFTVbT7GFlSq9xoqTRX694c33oBFi6Bdu9Bls7Pdyb+0pk3dWEXGGBNKuXsNAY8BhcAF3t924PH4hJfZROCRR9wcBhdf7KqKQrHJbIwxfog0ERynquNV9Svv789Acz8DyyQNG8Ljj8Py5TB2bOhyNpmNMcYPkSaCnSLSveSFiHQDdvoTUmbq3RuuugruvRfefDN4GZvMxhjjh0gTwShgqogUiEgBcD8w0reoMtQdd0DbtnDppbB586Hv22Q2xhg/RDXEhIjUBlDV7SJyrare41dgoaRbY3Fpn34KXbq4K4QXX3QnfGOMKa94NBYDLgEEjDF0XbkjM4fo0AFuvx3+9S/XiGyMMX4rz1SV9lvVJ2PGwBlnwLXXwpdfJjoaY0y6K08iKLNOSUTOEpFVIrJaRA7pDyMidUTkZRH5VERWiMhl5YgnbVSqBE884eY8vuQS2LMn0REZY9JZ2EQgIoUisj3IXyFwTBnrVgamAr2BNsAgEWlTqtho4HNV7QD0BP4uIlVjPZh00qgRPPywu8nMJrIxxvgpbCJQ1VqqWjvIXy1VLWuGsi7Aau++g93ATKBf6V0AtUREgJrAj8DeGI8l7Zx3npvI5vbb4b33Eh2NMSZdladqqCyNgK8DXm/wlgW6Hzge+Bb4DLhGVQ8Zfk1ERohIvojkb9q0ya94k9K990Lz5jB4MGyr8AE9jDGZwM9EEKwxuXS7Qi9gKa6aKQe4v6SL6kErqU5T1VxVzW3YsGG840xqtWq5UUo3bIDRo2Pbho1YaowJx89EsAE4NuB1Y9wv/0CXAS94I5quBtYCrX2MKSV17Qq33upO4M88E926NmKpMaYsfiaCRUALEWnmNQBfBLxUqsx64AwAETkKaAV85WNMKeumm9zMZldcEXwE0lDGjYOiooOXFRW55cYYAz4mAlXdC1wJvAF8AcxS1RUiMkpERnnFbgNOEZHPgLeAG1U1yOAKpkoVN9exqmsvKC6ObD0bsdQYU5ayev6Ui6rOxc1xHLjsoYDn3wK/8TOGdNK8Odx3n5vR7I473FVCWZo0CX4FYSOWGmNK+Fk1ZHwwZAhccIFrM4ikS6mNWGqMKYslghQj4kYcbdbMJYTvvw9f3kYsNcaUJarRR5NBuo8+Gqlly1xvoi5d3JzHVXyt5DPGpLq4jT5qkkf79vDQQ/Duu3DzzYmOxhiTyiwRpLAhQ2DkSNdw/K9/JToaY0yqskSQ4u65B3Jz3axmq1cnOhpjTCqyRJDiqleHf/7TDR8xcCDstJmkjTFRskSQBkrGD1q2DH7/e3fTmTHGRMoSQZro3ds1Gk+fDo8+Wv7t2UB1xmQOSwRpZPx4OPNMuPJKWLIk9u3YQHXGZBa7jyDNbN4MHTu6+wqWLIG6daPfRnZ28GEpmjaFgoLyRmiMSQS7jyCDNGjgGo+/+cZ1L913yDQ/ZbOB6ozJLJYI0lDXrnD33fDKK+4eg2iFGpDOBqozJj1ZIkhTo0fDoEGuAfmtt6Jb1waqMyazWCJIUyWD07Vq5RLCN99Evq4NVGdMZrHG4jS3ciV07uzGJpo/H7KyEh2RMSYREtZYLCJnicgqEVktImNDlOkpIktFZIWIvOtnPJmodWt3X8EHH8BvfgMffZToiIwxyca3RCAilYGpQG+gDTBIRNqUKnME8ADQV1XbAuf7FU8mu+ACN1Lp8uVw8slwzjmweHGiozLGJAs/rwi6AKtV9StV3Q3MBPqVKnMx8IKqrgdQ1R98jCejjRwJa9fCX//qrgpyc6F/f/j00/hs3+5ENiZ1+ZkIGgFfB7ze4C0L1BKoKyLzRWSxiAzxMZ6MV7MmjB3rEsLEia7NICcHzj8fVqyIfbt2J7Ixqc3PRCBBlpVuma4CnAicA/QCbhGRlodsSGSEiOSLSP6mTZviH2mGqV0bbrnFJYRbboE33oB27eDii2HVqui3N24cFBUdvKyoyC03xiQ/PxPBBuDYgNeNgW+DlHldVX9S1c3AAqBD6Q2p6jRVzVXV3IYNG/oWcKapW9ddGaxdCzfe6Ca3adMm+rkN7E5kY1Kbn4lgEdBCRJqJSFXgIuClUmX+BZwqIlVEpAZwEvCFjzGZIOrXd20Ha9fCmDEwa5brbTRsGLz6KmzbFn59uxPZmNTmWyJQ1b3AlcAbuJP7LFVdISKjRGSUV+YL4HVgGfAx8IiqLvcrJhPekUfC5Mnw1VfuzuRnn4U+faBePejUySWJOXNgy5aD17M7kY1JbXZDmQmpqAj+8x94913399FHsGuXe69dO+jRA047zT3Om+faBNavd1cCkybZncjGJJNwN5RZIjAR+/lnWLToQGJ4//0DjcStW7uk0LcvnH12YuM0xhzKhqE2cVGtGnTv7n75v/kmbN3qrhLuuAOaN3dVSeec4xqbCwvL3p7de2BMcrBEYGKWlQUnnQQ33OAalbdscbOkPf20a1MId/ey3XtgTPKwRGDipkoVmDAB3nnHtSWcfDL8/e/BJ8exew+MSR6WCEzc9ejhhq7o0wf++EdXXbRx48Fl7N4DY5KHJQLji3r1YPZsePBBN5RFhw6uXaGE3XtgTPKwRGB8IwKjRrmeRg0aQK9erj1h926798CYZGKJwPjuhBNcMrjiCrjrLujWzTUyxzILmvU0Mib+LBGYCnHYYfDAA/DCC7BmDXTs6HoLFRS4xuSCgsiSgPU0Mib+LBGYCnXuubB0qUsEgwfDkCGR3XMA1tPIGL9YIjAVrkkTePtt19V0xgw34umcOe5XfjjW08gYf1giMAlRpYq7+WzhQjcc9rnnQr9+rronFOtpZIw/LBGYhDr5ZHcH8l13wVtvuauDO++EPXsOLWs9jYzxhyUCk3BZWe7Gsy++gN/8xk2S06mTu1oIlJcXW08jY0x4lghM0mjSBF580c2Utn07nHoq/O53B89/kJcXfU8j625qTHiWCEzS6dsXPv8crr8epk+HVq3cY7Qjplt3U2MiY4nAJKXDD3dtBZ984hLBZZdBz54uQUTKupsaExlfE4GInCUiq0RktYiMDVOus4gUi8hAP+MxqaddO3jvPXjkEVi+3I1ZNHYs5OfDzp3h163o7qYpNseTMfv5lghEpDIwFegNtAEGiUibEOXuwM1tbMwhKlWC4cNh5Uq45BI3EU7nzlCzJhx/PFx0Edx+u5sT4euvD5yQK6q76b59cN990LChu3vamFTj5xVBF2C1qn6lqruBmUC/IOWuAmYDP/gYi0kDDRvC44/DV1/B88/DzTe7aqOPP3bVPX36uJN8/fquGqlVK6ha9eBtRNLdNJoG5vXr4cwz4eqr3b5Gj3Y9mYxJJVV83HYj4OuA1xuAkwILiEgj4FzgV0DnUBsSkRHACIAmdvdQxmvWzP2dd96BZdu3w2efwbJlbi6EZcvc/Qm7dx8oU6eOmygnXE+jkgbmkraFkgZmOHg9VXjySZcA9u1zJ/8hQ1xMI0e6G+aGDYvfMRvjK1X15Q84H3gk4PVg4L5SZf4JdPWeTwcGlrXdE088UY2JRHGx6urVqrNnqw4YoAqqDRuq3nuv6q5dwddp2tSVK/3XtOmBMhs3qvbr55afeqrqmjUH3tu5U7VXL1UR1See8PHgUtyePaqTJ6suXZroSDIHkK+hzteh3ijvH3Ay8EbA6z8BfypVZi1Q4P3twFUP9Q+3XUsEJlYffaR6+ukHTuxPPKG6d+/BZUSCJwIR9/7s2aoNGqhWq+ZOZKXXV1UtKlI94wzVSpVUn3nG98NKOfv2qY4a5T7XqlVV77vPLUtVu3apzpvnfngks0QlgirAV0AzoCrwKdA2THm7IjC+27dP9c03VU880f3rb9tWdc6cAyeiUFcExx6reskl7nmnTqrLl4ffz08/qZ52mmrlyqqzZsU3/mQ/4ZTlzjvd53jVVarnnOOen3uu6o8/Jjqy2Awd6o7h5psTHUl4CUkEbr+cDXwJrAHGectGAaOClLVEYCrMvn2q//ynasuW7n9B166q8+erPv20ao0aByeBatVU69Z1J/Vbb1XdvfvQ7T39tEsiIu7x6adVCwtVu3dXrVJF9cUXyxdvcbHq9OkuIdWpo9q/v+rUqaqrVqXWr+nnnnOf6YUXumMqLlb9+99Vs7JUmzRRff/9REcYnccfd8fzy1+6x6eeSnREoSUsEfjxZ4nAxNOePaoPP6zaqJH739Crl+pttx24MqhZ0z22bq368cfBtxEsedSo4ZZv3+6STFaW6ssvxxbjv/+tmpPjtpubqzp8+MFXLsceq3rZZa4a6vvvY/0k/LdwoUuq3bu7tpRAH3+s2qyZS7Z//WtqXPUsX6562GGqPXu66sDTT3dVXQsXJjqy4CwRGFOGoiJX51+vnvtfMXCg+5UnojpmjHs/lLIamLdudSfwqlVVX3st8pg++0y1d+8D23rmmQMnyH37XEP4gw+qnneeu2Ip2W/79qrXXef2tWNHjB9InH35pftsW7ZU3bw5eJmtW1UvuMAdw5lnJndS27FDtU0b1SOPVP32W7dsyxbVFi1cG1JgB4JkYYnAmAht3erqemvUcCffd94pe52yGphVXf13x47uF/G//x1+e9984371V6qkesQRqnfddegv6NL27lVdtEj19ttVf/Url3TAXYmcdprqs88Gb9iuCD/8oHrcce4EuXp1+LL79qn+4x+q1aurHnVU2Z9Volx6qft+S8e3apVLyscf7/4tJRNLBMZE6X//C38VECiSLqeq7pdwu3auOiFYgiksdG0QNWq4E/i114b+9VyWn35yjeLXX3+gHaRNG1dHX5HVLkVFrmqsenXVDz+MfL1ly9zJVET1pptcFV6yKGkXuPXW4O+//bZrF/rNb5IrbksExvgoXBtBaRs3uhNytWruF6+IayQdNsy9Blc9UtYv52gUF6vOnOlOrCU9pWbN8j8hFBe7aisR1+02Wjt2uCsjUO3WTXXduvjHGK3AdoFwV1gPP+ziHj264mIriyUCY3wWrNdQKPffH7w6qWXL6H41R2vvXtfO0Lq121+7dqrPP+9fQvjDH9x+7r67fNt55hnXaF+3rktomzcnpqfUjh0umQa2C4Tzxz+647/vvvjFUJ7jtkRgTBIJVZXUpEnF7H/vXpeoSqqMOnRQfeGF+J5c77/fbfvKK+Oz3f/+192/UfJZ1anj2lzOO0/1hhtUH3rI1devWeNfdUyodoFQ9u51d6BXqhRdJ4FgFi1y91yU5251SwTGJJFIGpcrwp49rt97ixZu/zk5B99cF6uXXnInv75949tAvWuX2/bdd7sE07u3aqtWBxrGS/4qV1Zt3lz1179WHTlSdcaM8l/1lNUuEEphoftca9VyvcCitXix6m9/6/Zdr56rcoqVJQJjkkikjcsVZc8e90vzuON0/53Ts2a56o9ok8KiRa59JDe34rqu7t2run69a4B/9FHXuHzRRaqdOx/oVpuT44aBiEWk7QKhfP216tFHu+9348bI1vnkkwPjWdWtq/qXv6hu2xb9vgNZIjAmiUTTuFx6vUjbIWJZZ88e98u3efMDcTVo4MZNGjPG3dm8ZEnoAfvWrnUN3tnZyXMPQHGx6zpbknzPPrvs4UECRdsuEMqiRS6ZnHxy+K7AS5e64TbAdR2eODF+3VAtERiTZKI9qceSPGJNOLt3u+E2pkxxvXY6d3YnscCql7ZtVS++WPVvf1OdO1d15Up3wjziCNXPP4/20/Dfzp3ufow6dVy11eWXq373XdnrlbQLxHo1Eeif/3Sf38UXH3qltWzZgRFy69RRnTDBdWGOJ0sExqS4WKqT4lkFtXevO9k/95zquHGqffq4xu3A7WZluQSSzDZvVr3mGtfP//DDVf/859BVWCXtAuPHx2//t9/utjlxonv92WfuLnZQrV3btUHEOwGUsERgTIqLpYE5lnWivVL53/9U333XdZFMpQHjvvzS9TgC1WOOcW0LgfX/Je0Cp58e3wbvfftUhwxx+/31r93nXKuWu5t9y5b47ScYSwTGpLiKuCKItSoplS1cqHrSSbr/voo33jjQLnDUUZFVH0Vr1y7VHj3cvRE33eR/AigRLhH4OWexMSZOJk1y8y0HKmv+5WjXGTfuwBSdJYqK3PJ01a0bfPghzJoFO3ZAr15uruuVK920pb/4Rfz3Wa0azJsHGze676JevfjvI1qWCIxJAXl5bl7kpk1BxD1OmxZ+/uVo11m/Prrl6UIEzj8fvvgC7r7bzXP9l7/AGWf4t8+srEOTdCKJu2JIHbm5uZqfn5/oMIxJO9nZsG7docubNoWCgtDrzZjhrhrWr4cmTdyv3HAJKtmpuuSQbkRksarmBnvP1ysCETlLRFaJyGoRGRvk/TwRWeb9fSAiHfyMxxgTWizVTzNmwIgRLoGouscRI9zyVJWOSaAsviUCEakMTAV6A22AQSLSplSxtcBpqtoeuA2Y5lc8xpjwYql+ysR2hXRUxcdtdwFWq+pXACIyE+gHfF5SQFU/CCj/EdDYx3iMMWXIy4uuWidT2xXSjZ9VQ42ArwNeb/CWhTIceM3HeIwxcdakSXTLYzVjhmvDqFTJPaZy1VMy8jMRBKtpC9oyLSKn4xLBjSHeHyEi+SKSv2nTpjiGaIwpj1jaFSC6E3s6tkMkGz8TwQbg2IDXjYFvSxcSkfbAI0A/Vd0SbEOqOk1Vc1U1t2HDhr4Ea4yJXiztCtGe2K0dwn9+JoJFQAsRaSYiVYGLgJcCC4hIE+AFYLCqfuljLMYYn+Tlue6l+/a5x7LaGKI9scfaDmHVSZHzrbFYVfeKyJXAG0Bl4DFVXSEio7z3HwJuBeoDD4jrs7U3VD9XY0x6iPbE3qRJ8PsbwrVDlFx1lCSckqsOSO17HPzi630EqjpXVVuq6nGqOslb9pCXBFDV36lqXVXN8f4sCRiT5qJtYI6lHSLW6qRoryLS5qoj1CBEyfpng84Zk9pinVshmlFRYx15NZq4knWCoVCw0UeNMckkHie2cCpitNZY9lGREwyVFi4R2FhDxpi0U7qNAFx1UrgeTZUqudNsaSKuIby85SG28ZxiHQPq0LgSNNaQMcYkQizdWqNtu4jlZrpYekBVxN3blgiMMWkp2m6t0TZKx9KIHUvyqIi7ty0RGGMM0V9FxHLVURETDMXC2giMMaYCxTJ/QzzmfAjXRmCJwBhjMoA1FhtjjAnJEoExxmQ4SwTGGJPhLBEYY0yGs0RgjDEZLuV6DYnIJqDkhusGwOYEhpNImXzskNnHb8eeucpz/E1VNejMXimXCAKJSH6o7lDpLpOPHTL7+O3YM/PYwb/jt6ohY4zJcJYIjDEmw6V6IpiW6AASKJOPHTL7+O3YM5cvx5/SbQTGGGPKL9WvCIwxxpSTJQJjjMlwKZkIROQsEVklIqtFZGyi46loIlIgIp+JyFIRSeuhWEXkMRH5QUSWByyrJyL/FpH/eo91Exmjn0Ic/wQR+cb7/peKyNmJjNEvInKsiLwjIl+IyAoRucZbnvbff5hj9+W7T7k2AhGpDHwJnAlsABYBg1T184QGVoFEpADIVdW0v7FGRHoAO4AnVfUEb9mdwI+q+jfvh0BdVb0xkXH6JcTxTwB2qOrkRMbmNxE5GjhaVZeISC1gMdAfGEqaf/9hjv0CfPjuU/GKoAuwWlW/UtXdwEygX4JjMj5R1QXAj6UW9wOe8J4/gfsPkpZCHH9GUNXvVHWJ97wQ+AJoRAZ8/2GO3RepmAgaAV8HvN6Ajx9QklLgTRFZLCIjEh1MAhylqt+B+w8DHJngeBLhShFZ5lUdpV3VSGkikg10BP5Dhn3/pY4dfPjuUzERSJBlqVW/VX7dVLUT0BsY7VUfmMzxIHAckAN8B/w9odH4TERqArOBa1V1e6LjqUhBjt2X7z4VE8EG4NiA142BbxMUS0Ko6rfe4w/Ai7jqskyy0atDLalL/SHB8VQoVd2oqsWqug94mDT+/kUkC3cinKGqL3iLM+L7D3bsfn33qZgIFgEtRKSZiFQFLgJeSnBMFUZEDvcajxCRw4HfAMvDr5V2XgIu9Z5fCvwrgbFUuJKToOdc0vT7FxEBHgW+UNW7A95K++8/1LH79d2nXK8hAK/L1D1AZeAxVZ2U2Igqjog0x10FAFQBnknn4xeRZ4GeuOF3NwLjgTnALKAJsB44X1XTskE1xPH3xFUNKFAAjCypM08nItIdeA/4DNjnLb4JV1ee1t9/mGMfhA/ffUomAmOMMfGTilVDxhhj4sgSgTHGZDhLBMYYk+EsERhjTIazRGCMMRnOEoExHhEpDhjVcWk8R7YVkezAEUSNSSZVEh2AMUlkp6rmJDoIYyqaXREYUwZv/oc7RORj7++X3vKmIvKWNwDYWyLSxFt+lIi8KCKfen+neJuqLCIPe+PLvykih3nlrxaRz73tzEzQYZoMZonAmAMOK1U1dGHAe9tVtQtwP+6udrznT6pqe2AGMMVbPgV4V1U7AJ2AFd7yFsBUVW0LbAXO85aPBTp62xnlz6EZE5rdWWyMR0R2qGrNIMsLgF+p6lfeQGDfq2p9EdmMmzxkj7f8O1VtICKbgMaq+nPANrKBf6tqC+/1jUCWqv5FRF7HTT4zB5ijqjt8PlRjDmJXBMZERkM8D1UmmJ8DnhdzoI3uHGAqcCKwWESs7c5UKEsExkTmwoDHD73nH+BGvwXIAxZ6z98CrgA3taqI1A61URGpBByrqu8ANwBHAIdclRjjJ/vlYcwBh4nI0oDXr6tqSRfSaiLyH9yPp0HesquBx0TkemATcJm3/BpgmogMx/3yvwI3iUgwlYGnRaQObtKl/1PVrXE6HmMiYm0ExpTBayPIVdXNiY7FGD9Y1ZAxxmQ4uyIwxpgMZ1cExhiT4SwRGGNMhrNEYIwxGc4SgTHGZDhLBMYYk+H+H6iyTWunBueIAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history_1_1)\n",
    "plot_acc(history_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal no. of layers (and layer size) as well as dropout rate and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_10 (Rescaling)    (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d_57 (Conv2D)          (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 94, 94, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 47, 47, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 43, 43, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " global_average_pooling2d_9   (None, 256)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,183,046\n",
      "Trainable params: 1,183,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 02:02:25.694324: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1.8185 - accuracy: 0.1716"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 02:02:37.694722: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 13s 97ms/step - loss: 1.8185 - accuracy: 0.1716 - val_loss: 1.7257 - val_accuracy: 0.2979\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 12s 98ms/step - loss: 1.5603 - accuracy: 0.3810 - val_loss: 1.0479 - val_accuracy: 0.5938\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 12s 98ms/step - loss: 0.9994 - accuracy: 0.6346 - val_loss: 0.5859 - val_accuracy: 0.8021\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 12s 99ms/step - loss: 0.6377 - accuracy: 0.7740 - val_loss: 0.4096 - val_accuracy: 0.8583\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 12s 97ms/step - loss: 0.4694 - accuracy: 0.8281 - val_loss: 0.3491 - val_accuracy: 0.8750\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 0.3449 - accuracy: 0.8766 - val_loss: 0.3096 - val_accuracy: 0.9000\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 12s 99ms/step - loss: 0.2511 - accuracy: 0.9135 - val_loss: 0.4772 - val_accuracy: 0.8667\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.2107 - accuracy: 0.9289 - val_loss: 0.2539 - val_accuracy: 0.9250\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 0.1623 - accuracy: 0.9458 - val_loss: 0.2869 - val_accuracy: 0.9458\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.1457 - accuracy: 0.9539 - val_loss: 0.2987 - val_accuracy: 0.9042\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.1271 - accuracy: 0.9646 - val_loss: 0.2013 - val_accuracy: 0.9458\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.0925 - accuracy: 0.9724 - val_loss: 0.3139 - val_accuracy: 0.9354\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 14s 120ms/step - loss: 0.1031 - accuracy: 0.9714 - val_loss: 0.3516 - val_accuracy: 0.9333\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 16s 136ms/step - loss: 0.0877 - accuracy: 0.9773 - val_loss: 0.4369 - val_accuracy: 0.9188\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.0905 - accuracy: 0.9758 - val_loss: 0.7900 - val_accuracy: 0.8771\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.0867 - accuracy: 0.9786 - val_loss: 0.6740 - val_accuracy: 0.9042\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 0.0849 - accuracy: 0.9828 - val_loss: 0.4495 - val_accuracy: 0.9104\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 16s 136ms/step - loss: 0.0561 - accuracy: 0.9865 - val_loss: 0.4233 - val_accuracy: 0.9458\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 16s 130ms/step - loss: 0.0522 - accuracy: 0.9893 - val_loss: 0.2705 - val_accuracy: 0.9542\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 15s 126ms/step - loss: 0.0638 - accuracy: 0.9865 - val_loss: 0.3460 - val_accuracy: 0.9479\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 15s 126ms/step - loss: 0.0641 - accuracy: 0.9852 - val_loss: 0.6824 - val_accuracy: 0.9063\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0658 - accuracy: 0.9854 - val_loss: 0.3275 - val_accuracy: 0.9458\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.0441 - accuracy: 0.9878 - val_loss: 0.3041 - val_accuracy: 0.9563\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.0545 - accuracy: 0.9891 - val_loss: 0.3453 - val_accuracy: 0.9417\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.0325 - accuracy: 0.9914 - val_loss: 0.5213 - val_accuracy: 0.9396\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 0.0756 - accuracy: 0.9878 - val_loss: 0.4495 - val_accuracy: 0.9417\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0407 - accuracy: 0.9901 - val_loss: 0.3093 - val_accuracy: 0.9583\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 15s 127ms/step - loss: 0.0434 - accuracy: 0.9938 - val_loss: 0.4080 - val_accuracy: 0.9583\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 15s 126ms/step - loss: 0.0398 - accuracy: 0.9904 - val_loss: 0.3790 - val_accuracy: 0.9646\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.0376 - accuracy: 0.9924 - val_loss: 0.5889 - val_accuracy: 0.9521\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model_1_2 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_1_2.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_1_2.summary()\n",
    "\n",
    "history_1_2 = model_1_2.fit(\n",
    "  train,\n",
    "  epochs=30,\n",
    "  validation_data=val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzJ0lEQVR4nO3deXgUVdb48e9JACFsKioiW0BBlmGPqIgKig6OjoobYBxFVAR3HbcZ13GG3+su+roNKq4ZQUdFXwc3cB/UJLIpCCEgYEARUZawZjm/P2516ITupDt0pdPd5/M8/XRX9e3qU11Jnap7q+4VVcUYY0zqSot3AMYYY+LLEoExxqQ4SwTGGJPiLBEYY0yKs0RgjDEpzhKBMcakOEsEZjci8o6IXBDrsvEkIitEZJgPy1UROcR7/aSI3BZJ2Vp8T7aIvF/bOI2pjth9BMlBRIqDJjOAHUCZN32pqubUfVT1h4isAC5W1ZkxXq4CXVS1MFZlRSQT+B5oqKqlMQnUmGo0iHcAJjZUtVngdXU7PRFpYDsXU1/Y32P9YFVDSU5EhohIkYjcJCI/Ac+KyD4i8raIrBOR37zX7YI+87GIXOy9HiMin4vI/V7Z70XkpFqW7SQin4rIZhGZKSKPichLYeKOJMa/i8h/veW9LyL7Bb3/JxFZKSLrReSWan6fI0TkJxFJD5o3QkQWeK8HisgXIrJBRH4UkUdFpFGYZT0nIv8Imr7B+8waERlbpezJIjJXRDaJyA8icmfQ2596zxtEpFhEjgz8tkGfHyQieSKy0XseFOlvE+XvvK+IPOutw28iMj3ovdNEZJ63DstEZLg3v1I1nIjcGdjOIpLpVZFdJCKrgA+9+a9622Gj9zfSM+jzTUTkAW97bvT+xpqIyH9E5Moq67NARE4Pta4mPEsEqeFAYF+gIzAOt92f9aY7ANuAR6v5/OHAEmA/4F7gGRGRWpT9F5ALtALuBP5UzXdGEuO5wIXAAUAj4HoAEekBPOEt/yDv+9oRgqp+CWwBjquy3H95r8uAa731ORI4HrismrjxYhjuxXMC0AWo2j6xBTgf2Bs4GZgQtAM7xnveW1WbqeoXVZa9L/Af4BFv3R4E/iMiraqsw26/TQg1/c4v4qoae3rLesiLYSDwAnCDtw7HACvCfEcoxwLdgd970+/gfqcDgDlAcFXm/cAAYBDu7/hGoBx4HjgvUEhE+gBtgRlRxGEAVNUeSfbA/UMO814PAXYCjasp3xf4LWj6Y1zVEsAYoDDovQxAgQOjKYvbyZQCGUHvvwS8FOE6hYrx1qDpy4B3vde3A1OD3mvq/QbDwiz7H8AU73Vz3E66Y5iy1wBvBE0rcIj3+jngH97rKcDdQeW6BpcNsdxJwEPe60yvbIOg98cAn3uv/wTkVvn8F8CYmn6baH5noA1uh7tPiHL/DMRb3d+fN31nYDsHrVvnamLY2yvTEpeotgF9QpTbC/gV1+4CLmE87sf/VLI/7IwgNaxT1e2BCRHJEJF/eqfam3BVEXsHV49U8VPghapu9V42i7LsQcCvQfMAfggXcIQx/hT0emtQTAcFL1tVtwDrw30X7uj/DBHZCzgDmKOqK704unrVJT95cfw/3NlBTSrFAKyssn6Hi8hHXpXMRmB8hMsNLHtllXkrcUfDAeF+m0pq+J3b47bZbyE+2h5YFmG8oVT8NiKSLiJ3e9VLm9h1ZrGf92gc6rtUdQfwCnCeiKQBo3FnMCZKlghSQ9VLw/4MHAocrqot2FUVEa66JxZ+BPYVkYygee2rKb8nMf4YvGzvO1uFK6yqi3A70pOoXC0EroppMe6oswXw19rEgDsjCvYv4C2gvaq2BJ4MWm5Nl/KtwVXlBOsArI4grqqq+51/wG2zvUN87gfg4DDL3II7Gww4MESZ4HU8FzgNV33WEnfWEIjhF2B7Nd/1PJCNq7LbqlWq0UxkLBGkpua40+0NXn3zHX5/oXeEnQ/cKSKNRORI4I8+xfhv4BQRGew17N5FzX/r/wKuwu0IX60SxyagWES6ARMijOEVYIyI9PASUdX4m+OOtrd79e3nBr23Dlcl0znMsmcAXUXkXBFpICIjgR7A2xHGVjWOkL+zqv6Iq7t/3GtUbigigUTxDHChiBwvImki0tb7fQDmAaO88lnAWRHEsAN31paBO+sKxFCOq2Z7UEQO8s4ejvTO3vB2/OXAA9jZQK1ZIkhNk4AmuKOtL4F36+h7s3ENrutx9fLTcDuAUCZRyxhVdSFwOW7n/iPwG1BUw8dexrWnfKiqvwTNvx63k94MPOXFHEkM73jr8CFQ6D0Huwy4S0Q249o0Xgn67FZgIvBfcVcrHVFl2euBU3BH8+txjaenVIk7UpOo/nf+E1CCOyv6GddGgqrm4hqjHwI2Ap+w6yzlNtwR/G/A36h8hhXKC7gzstXAIi+OYNcD3wB5uDaBe6i873oB6IVrczK1YDeUmbgRkWnAYlX1/YzEJC8ROR8Yp6qD4x1LorIzAlNnROQwETnYq0oYjqsXnh7nsEwC86rdLgMmxzuWRGaJwNSlA3GXNhbjroGfoKpz4xqRSVgi8ntce8paaq5+MtWwqiFjjElxdkZgjDEpLuE6ndtvv/00MzMz3mEYY0xC+frrr39R1f1DvZdwiSAzM5P8/Px4h2GMMQlFRKrejV7BqoaMMSbFWSIwxpgUZ4nAGGNSnCUCY4xJcb4lAhGZIiI/i8i3Yd4XEXlERAq9UYX6+xWLMcaY8Pw8I3gOGF7N+yfhRiTqghs16wkfYzHGmDqRkwOZmZCW5p5zcmr6RPz5lghU9VNcT4HhnAa8oM6XuMEw2vgVjzGpJBF3RjWJdJ38WPdovnvcOFi5ElTd87hxoctHE6fv29PP4c9wA0x8G+a9t4HBQdOzgKwwZcfh+rLP79ChgxqTql56SbVjR1UR9/zSS6HLZGSoul2Re2RkhC4b6TKjKefHMiNdJz/WPZplduxYuVzg0bFj7ZcZ7TqFA+RruH11uDdi8aghEfwnRCIYUNMyBwwYEN3aG1PPxXpnGOnOKJpl+rHj8mMH68e6R7NMkdBlRWq/zGjKVqe+JoJ/AqODppcAbWpapiUC44dojnZjuUw/doaR7oyiWaYfOy4/drB+rHu8lxlN2erU10RwMm4YPAGOAHIjWaYlAhPrnXa0R7vxOnr342jTjx1sPHfa8f49/djuCX1GgBv670fcMHdFwEXAeGC8974AjwHLcMPQhWwfqPqwRJDa/Nhp+1GvG8+jzXhXucSzGife9fmB8rE8E0z4NgI/HpYIklM8d9rxPNL2Y2cYze+ZKG0E0a5TLNc9mmVGw4/G9+pYIjD1Wrx32oly9B4oH68dUjyvGvJLvL+/LlkiMPVavHfa8bwaJ1A2VXZGRrW8XLWoSPXjj1Wfekp10iTV+fPdfD9ZIjBxE8lOLt477UjjrA9H7yYxVN3Z33ST6hlnqPbqtfvfUODRtq3qxRervvaa6saNsY/JEoGJi0TaaUezTrZzj521a92O75FHVJcujXc0oW3ZovrCC6pDh6qmp7ttX9Oj6t9yw4aqhx6qesopqtdeq/rYY6rvv6+6fLnqqlWqTz+teuaZqi1auPINGqgee6zqPfeoLlgQm7OF6hJBwg1en5WVpTZCWXzl5MAtt8CqVdChA0ycCNnZu5fLzHS32FfVsSOsWFF5eePGwdatu+ZlZMDkyaGXG+s4k8XPP8O8eTB37q5HUZHbDl26wCGHVH5u1851WVBXVN12/+yzXY8lSyqX6dcPzjkHzj4bDj647mKrShVyc2HKFJg6FTZtgs6dYcQI97cZiQMP3PV7d+gA6ek1f6akBL74At55B2bMgAUL3Px27WD4cDjvPDj22Nqtk4h8rapZId+zRGCiEc1OOy3N/UNVJQLl5bsvN5V22nsisEMN3uHPnQtr1uwqk5npdqodOrhkvHQpLFsG27fvKrPXXm5nG9hZXXgh9OwZuzjLy2HRIrfD//RT97x6tXtv773hqKPg6KPdo3VrePNNeOUV+OorV6Z//11JoXPn2MVVnbVr4cUX4dlnXewZGe77L7zQxVmXiRPc7/Xuuy4xfPAB/PnPcPvttVuWJQITM5Ee5UdbFmDSJLjnHujeHY45xv3jHXEENG26x2EnjYUL4cwzdx1Jp6dDt25upx949O0L++yz+2fLy92OZelS9ygsrPy6cWO3wxk0aM/jLCyEk0+GggI3fdBBu3b6Rx8Nv/td+J3qypXw73/Dq6/uSgoDBrgdsh9JoaTErfeUKfCf/0BpKRx5JIwd6xJRixax/b7aKilxibx589p93hKBiYkvv3T/IKGEO8qP5OxBFf7+d7jjDneUuHWrq+JQhQYN3JFhYAcyeDC0ahXzVUsI06fDn/4EzZq5o8IBA6BXL2jSZM+XvWoVDBvmzireeguOO672y/r6azjpJLf97rkHhgyBTp3c30i0AknhlVdcVQ24A4NmzdyjefNdr4MfzZtDo0awZQsUF8Pmze656mPzZvcoKXFnJeef747+u3ev/frXV5YITERCVc+cey58+KF7/dFH7iiu6g4fYP/9XR11JMusmgRuvhnuvRcuuACeftrt/DduhNmzd9Ul5+bCzp3uMz16uKRwyCG7//OH2yEksvJy+Mc/XKIcOBBefx3ato399/z0E5xwgjtDeO01d0QfrZkzXT16q1bw/vvQtWvs4luxwiXDoqLQO/bgeZs3uyP7jIzQfxNV5w0a5JJXw4axi7e+qS4RxP0qoGgfdtWQP0JdZdOokerBB7vXbdqoPvCAu7qharm0NPfIyYnuO8vKVC+7zC1jwgQ3Hc62baqffqo6caLq8OGqzZuHvtIo1KNFC9Vzz1WdPt0tJ5Fs2qQ6YoRbjwsu8D/+X35RHTDAXeXy6qvRffbll93nevdWXb3an/iiUd3fUyrCLh81NQl3CWeDBqr//Kfq9u27yla9hPKpp1SHDHHTTz0V2feVlLgdG6hef330l8eVlbmd5Jo1qgUFqnPmqH7yiep//qM6bZrqM8+4G3X+8Q/VCy9U3Xdf913Nm6tmZ6u++Wb9TwqFhao9e7pLFh96yP8bjgI2bFA96iiX3J9/PrLPPPyw+32POUb1t998Dc/UkiUCU6NwN3VBZJ/fulX1pJNc+UmTqi+7Y4fq2We7snfeWTc7uJ07Vd99V/WiiyonhfPOc0khONHVBx98oLrPPu7xwQd1//3FxarDhrnf6fHHw5crL1f9619duREj6n9yTWWWCFJYrDtzq8727e7uSXBVOKFs2+ZuqgHV+++Pbl1iJTgp7LOPVlQfnXeeu9U/nsrLVR980B2N9+zpzgripaZtVVKiOnase3/cONXS0rqP0UTOEkGKiubu2kBd/Z7eiVtS4naooPqXv1Q+2i8uVj3+ePfeE0/s2brFSiApjB2ruvfe7izhs8/iE8u2barnn7/r6HrTpvjEEWznTtVzztn97G3LFtU//tHNv/32uqu2MrVniSBFRXqUv2SJarNmql27qnbosOfdJ5SVqV56qfuuq65yO4na1DvXtR9+cN0ANGnibv+vC7/8ovrFF6ovvqh62GHuN/vb3+pXQ2dpqeqYMS62G25QXb/ebUsR11WCSQzVJYIGdXbtkqlzq1bVPH/7dnfTTKNG7tK/9u33/HvT0uCJJ9ylew895C4F/fZbmD8fpk2Ds87a8+/wQ7t27g7YE06AU05x16//8Y97vtz163e/eSvw/Ntvu8q1aAFvvAGnn77n3xlL6enwzDNue953n7vEd8sWd21/fd2WJjqWCJJYoHuBUPMDrr3W7aDffjs2SSBABB54wF2zfdddrjuD6dNrd216XTrgAHe/xEknwRlnwEsvwciRtVvWBx/AlVdW7k9HxP3+XbrAqFGV+//p3Nn9TvVRWho8+qhLVs8847o9GDo03lGZmAl3qlBfH1Y15MyY4a7XHjFC9ddfQ5epqY3g5ZfdvBtv9DfWqVNVv/zS3++ItY0b3aWQaWmqU6ZE99kff1QdPdr9tl26qN53n7syadGi+nd1Um1Ye0BiwtoIkseiRbsu08zMdDfwZGaq5uWFLh/uqqGCAtcuMGiQaxA0u9uyRfXEE91v/b//W3P5sjLXCN6ypbsZ74477HJKU39YIkgC69e7htf0dLejeeABdz3+l1+qtm/vdjyPPx7Z0dq2bap9+7rr6Veu9D30hLZ9u+rpp7v/lLvvDl9u3jzVww935YYOVV28uO5iNCYS1SWCOu5U1USrtNTVzXbp4p4vvtg1NLZu7fpxOfJIV+nTrRtcdpnrr7y4uPplXned69Tt+ecrtxeY3e21l2sUPfdc1yfSbbdV7lq7uBiuv951ALd8ObzwAsyaBYceGr+YjYlauAxRXx+pdEbw3nuqPXq4o8zjjtt1s1Oouv8mTdzdumlpqt27qy5cGHqZ06ZpRbcOJnKlpW4YQXAjTJWXu3r/9u3dvEsucWdtxtRXWNVQYlm8eNcdnQcf7DpLC67yqe7+gFmzVA84IPTNYEuXuhumjjjC2gVqo7xc9eqr3W/dvbt7/t3vVD//PN6RGVOz6hKBVQ3VE2VlbnCMc85xg3Z88onrmnnhQjjttMp9uVd3f8Bxx7nRqgYMcNVEEya4ewUC9ws0aOCG3kvm7nb9IuLui7j1VtcV8t13w5w5bgwFYxKZjUcQZ0uXwnPPufr61atdP+7nnw833eTaAUKJZOSv0lI3DsC997qBXbp3d2MDvPkmnHqqTyuTQsrL637YQmP2RHXjEdifchwUF7ud/zHHuAbfu+92wwu+9pobIerBB8MnAXCDu1QdQDsjw80PaNDAjQ715pturNqcHNdIbEkgNiwJmGRidxbXEVU34taUKe4qlOJilwT+53/cGcBBB0W+rMAIX5EM9n7qqa764q233FVFxhhTlVUN1YEdO2D4cPj4Yzfe6siRbmDsQYNqN46rMcZEq7qqITsjqAPXXOOSwIMPwiWXuDFSjTGmvrBE4LMXXoAnn4Qbb3QdvBljTH1jTV4+WrAAxo+HIUMqN+QaY0x9YonAJxs2uG6M99nHXbffwM69jDH1lCUCH5SXwwUXuGv9X321+ktBg+XkuHsE0tLcc06On1EaY4xjx6k+uPded7nmww+7K4MikZMD48bB1q1ueuVKNw2hLws1xphYsctHY2zWLDjxRDj7bHj55cgvD43kbmFjjKktu7O4jhQVwejRrkvop5+O7h6BSMYXNsYYP1giiJGdO91ZwLZtrquIaO8VCDcugI0XYIzxmyWCGPnzn+HLL+HZZ90ZQbQi6T/IGGP8YIkgBnJy3Ohh110HZ51Vu2VkZ8Pkya5NQMQ9T55sDcXGGP/52lgsIsOBh4F04GlVvbvK+y2Bl4AOuCuY7lfVZ6tbZn1rLP72Wzj8cNf//6xZ1s+/MaZ+iktjsYikA48BJwE9gNEi0qNKscuBRaraBxgCPCAijfyKKdY2b4Yzz4QWLWDaNEsCxpjE5Od9BAOBQlVdDiAiU4HTgEVBZRRoLiICNAN+BUp9jCmmpk2DggJ3JtCmTbyjMcaY2vGzjaAt8EPQdJE3L9ijQHdgDfANcLWqllddkIiME5F8Eclft26dX/FG7auvYN99YejQeEdijDG152ciCHUVfdUGid8D84CDgL7AoyLSYrcPqU5W1SxVzdp///1jHWet5ebCYYfZmALGmMTmZyIoAtoHTbfDHfkHuxB4XZ1C4HugFhdf1r0tW9zA8gMHxjsSY4zZM34mgjygi4h08hqARwFvVSmzCjgeQERaA4cCy32MKWbmzoWyssgSgXUmZ4ypz3xrLFbVUhG5AngPd/noFFVdKCLjvfefBP4OPCci3+Cqkm5S1V/8iimW8vLc82GHVV/OOpMzxtR31ulcLY0e7QajD9VRXDDrTM4YUx9Yp3M+yM2NrFrIOpMzxtR3lghqYf16WL685mohsM7kjDH1nyWCWgi0D0RyRmCdyRlj6jtLBLWQm+vuHRgwoOay1pmcMaa+s6EqayEvD7p3h+bNIyufnW07fmNM/WVnBFFSjbyh2BhjEoElgiitWgU//xxZQ7ExxiQCSwRRiqah2BhjEoElgijl5kKjRtC7d7wjMcaY2LBEEKW8POjb1yUDY4xJBpYIolBWBvn5Vi1kjEkulgiisHgxFBdbQ7ExJrlYIoiCNRQbY5KRJYIo5Oa6geq7do13JMYYEzuWCKKQmwtZWW6AGWOMSRa2S4vQ9u2wYIFVCxljko8lggjNnw8lJZYIjDHJxxJBhHJz3bNdMWSMSTaWCCKUlwdt2kDbtvGOxBhjYssSQYRyc93ZgEi8IzHGmNiyRBCBjRthyRJrHzDGJCdLBBHIz3fPlgiMMcnIEkEEAg3FWVnxjcMYY/xgiSACeXnQpQvss0+8IzHGmNizRBABG5rSGJPMLBHUYM0aWL3a7h8wxiSvGhOBiJwiIimbMKzHUWNMsotkBz8KWCoi94pId78Dqm9yc6FBAzcqmTHGJKMaE4Gqngf0A5YBz4rIFyIyTkSa+x5dPZCXB716QZMm8Y7EGGP8EVGVj6puAl4DpgJtgBHAHBG50sfY4q683CUCqxYyxiSzSNoI/igibwAfAg2Bgap6EtAHuN7n+OKqsBA2bLCGYmNMcovkjOBs4CFV7a2q96nqzwCquhUY62t0cVZdQ3FODmRmukFqMjPdtDHGJKIGEZS5A/gxMCEiTYDWqrpCVWf5Flk9kJsLTZtCjx6V5+fkwLhxsHWrm1650k0DZGfXbYzGGLOnIjkjeBUoD5ou8+Ylvdxc6N8f0tMrz7/lll1JIGDrVjffGGMSTSSJoIGq7gxMeK8b+RdS/VBSAnPnhq4WWrUq9GfCzTfGmPoskkSwTkRODUyIyGnAL/6FVD988w3s2BE6EXToEPoz4eYbY0x9FkkiGA/8VURWicgPwE3Apf6GFX/VDU05cSJkZFSel5Hh5htjTKKpsbFYVZcBR4hIM0BUdbP/YcVfXh7st5+7IqiqQIPwLbe46qAOHVwSsIZiY0wiiuSqIUTkZKAn0Fi8sRpV9S4f44q7moamzM62Hb8xJjlEckPZk8BI4EpAcPcVdIxk4SIyXESWiEihiNwcpswQEZknIgtF5JMoYvdNcTEsWmR3FBtjUkMkbQSDVPV84DdV/RtwJNC+pg+JSDrwGHAS0AMYLSI9qpTZG3gcOFVVe+KSTNzNmeO6l7BEYIxJBZEkgu3e81YROQgoATpF8LmBQKGqLvcuOZ0KnFalzLnA66q6CiBw13K8VddQbIwxySaSRPB/3pH7fcAcYAXwcgSfawv8EDRd5M0L1hXYR0Q+FpGvReT8UAvyejvNF5H8devWRfDVeyYvzzUS77+/719ljDFxV21jsTcgzSxV3QC8JiJvA41VdWMEyw7VzKohvn8AcDzQBPhCRL5U1YJKH1KdDEwGyMrKqrqMmJszBwYM8PtbjDGmfqj2jEBVy4EHgqZ3RJgEwJ0BBLcltAPWhCjzrqpuUdVfgE9xvZrGzc6d8P330D3lhuAxxqSqSKqG3heRM0XCXUgZVh7QRUQ6iUgj3Ehnb1Up8yZwtIg0EJEM4HDguyi/J6a+/x7KyqBr13hGYYwxdSeS+wiuA5oCpSKyHVflo6raoroPqWqpiFwBvAekA1NUdaGIjPfef1JVvxORd4EFuI7tnlbVb/dgffZYgVcpZYnAGJMqIrmzuNZDUqrqDGBGlXlPVpm+D9cQXS8EEkGXLvGNwxhj6kqNiUBEjgk1X1U/jX048bd0KbRqBfvuG+9IjDGmbkRSNXRD0OvGuPsDvgaO8yWiOCsosGohY0xqiaRq6I/B0yLSHrjXt4jirKAAhg2LdxTGGFN3IrlqqKoi4HexDqQ+KC6G1avtjMAYk1oiaSP4X3bdCJYG9AXm+xhT3BQWumdrKDbGpJJI2gjyg16XAi+r6n99iieuli51z3ZGYIxJJZEkgn8D21W1DFyvoiKSoapba/hcwglcOnrIIfGNwxhj6lIkbQSzcP0ABTQBZvoTTnwVFEC7dtC0abwjMcaYuhNJImisqsWBCe91RjXlE5ZdOmqMSUWRJIItItI/MCEiA4Bt/oUUP0uXWkOxMSb1RNJGcA3wqogEeg5tgxu6MqmsX+8edkZgjEk1kdxQlici3YBDcR3OLVbVEt8jq2N2xZAxJlVFMnj95UBTVf1WVb8BmonIZf6HVres11FjTKqKpI3gEm+EMgBU9TfgEt8iipOCAkhPh06RjMZsjDFJJJJEkBY8KI2IpAON/AspPpYudUmgYcN4R2KMMXUrksbi94BXRORJXFcT44F3fI0qDuzSUWNMqorkjOAm3E1lE4DLcaOJNan2EwlG1RKBMSZ11ZgIvAHsvwSWA1nA8cR5XOFYW7MGtm61RGCMSU1hq4ZEpCtuwPnRwHpgGoCqDq2b0OqODU9pjEll1bURLAY+A/6oqoUAInJtnURVx+weAmNMKquuauhM4CfgIxF5SkSOx91QlnQKCqBxY9fhnDHGpJqwiUBV31DVkUA34GPgWqC1iDwhIifWUXx1oqDAVQul1Wa8NmOMSXCRNBZvUdUcVT0FaAfMA272O7C6FEgExhiTiqI6BlbVX1X1n6p6nF8B1bXSUli+3NoHjDGpK+UrQ1auhJISSwTGmNSV8onAOpszxqQ6SwR2D4ExJsVZIiiAli1h//3jHYkxxsRHyieCpUtdtZAk5R0SxhhTs5RPBNbZnDEm1aV0Iti2DVatskRgjEltKZ0Ili1zXVBbQ7ExJpWldCKwzuaMMSbFE4FdOmqMMZYIOPBAaNEi3pEYY0z8pHwisLMBY0yqS/lEYO0DxphUl7KJYONG+PlnSwTGGJOyicCuGDLGGMfXRCAiw0VkiYgUikjYwWxE5DARKRORs/yMJ5j1OmqMMY5viUBE0oHHgJOAHsBoEekRptw9wHt+xRJKQYHrX6hz57r8VmOMqX/8PCMYCBSq6nJV3QlMBU4LUe5K4DXgZx9j2c3SpdCxoxu03hhjUpmfiaAt8EPQdJE3r4KItAVGAE9WtyARGSci+SKSv27dupgEZ1cMGWOM42ciCNWxs1aZngTcpKpl1S1IVSerapaqZu0fg4EDVC0RGGNMgJ+JoAhoHzTdDlhTpUwWMFVEVgBnAY+LyOk+xgS4y0Y3bQp9M1lODmRmQlqae87J8TsaY4yJrwY+LjsP6CIinYDVwCjg3OACqtop8FpEngPeVtXpPsYEhL9iKCcHxo2DrVvd9MqVbhogO9vvqIwxJj58OyNQ1VLgCtzVQN8Br6jqQhEZLyLj/freSIS7h+CWW3YlgYCtW918Y4xJVn6eEaCqM4AZVeaFbBhW1TF+xhKsoAAaNnRXDQVbtSp0+XDzjTEmGaTkncUFBXDIIZCeXnl+hw6hy4ebb4wxySBlE0GohuKJEyEjo/K8jAw33xhjklXKJYLycigsDH3paHY2TJ7sqoxE3PPkydZQbIxJbr62EdRHP/wAO3aEv4cgO9t2/MaY1JJyZwTW2ZwxxlSWsonARiYzxhgnJRNB06bQpk28IzHGmPoh5RLB0qWuWkhC9YRkjDEpKOUSgXU2Z4wxlaVUIti5E77/3toHjDEmWEolguXL3X0EdkZgjDG7pFQisAHrjTFmdymVCOzSUWOM2V3KJYL99oN99413JMYYU3+kXCKwswFjjKks5RKBtQ8YY0xlKZMIiothzRpLBMYYU1XKJILCQvdsicAYYypLmURgVwwZY0xoKZMIjj0WXn/dzgiMMaaqlBmYpnVrGDEi3lEYY0z9kzKJwJhkVFJSQlFREdu3b493KKaeaNy4Me3ataNhw4YRf8YSgTEJrKioiObNm5OZmYlY3+opT1VZv349RUVFdOrUKeLPpUwbgTHJaPv27bRq1cqSgAFARGjVqlXUZ4iWCIxJcJYETLDa/D1YIjDGmBRnicCYFJKTA5mZkJbmnnNy9mx569evp2/fvvTt25cDDzyQtm3bVkzv3Lmz2s/m5+dz1VVX1fgdgwYN2rMgTY2ssdiYFJGTA+PGwdatbnrlSjcNkJ1du2W2atWKefPmAXDnnXfSrFkzrr/++or3S0tLadAg9G4mKyuLrKysGr9j9uzZtQsujsrKykhPT493GBGzMwJjUsQtt+xKAgFbt7r5sTRmzBiuu+46hg4dyk033URubi6DBg2iX79+DBo0iCVLlgDw8ccfc8oppwAuiYwdO5YhQ4bQuXNnHnnkkYrlNWvWrKL8kCFDOOuss+jWrRvZ2dmoKgAzZsygW7duDB48mKuuuqpiucFWrFjB0UcfTf/+/enfv3+lBHPvvffSq1cv+vTpw8033wxAYWEhw4YNo0+fPvTv359ly5ZVihngiiuu4LnnngMgMzOTu+66i8GDB/Pqq6/y1FNPcdhhh9GnTx/OPPNMtno//tq1axkxYgR9+vShT58+zJ49m9tuu42HH364Yrm33HJLpd/Ab3ZGYEyKWLUquvl7oqCggJkzZ5Kens6mTZv49NNPadCgATNnzuSvf/0rr7322m6fWbx4MR999BGbN2/m0EMPZcKECbtdCz937lwWLlzIQQcdxFFHHcV///tfsrKyuPTSS/n000/p1KkTo0ePDhnTAQccwAcffEDjxo1ZunQpo0ePJj8/n3feeYfp06fz1VdfkZGRwa+//gpAdnY2N998MyNGjGD79u2Ul5fzww8/VLvejRs35vPPPwdctdkll1wCwK233sozzzzDlVdeyVVXXcWxxx7LG2+8QVlZGcXFxRx00EGcccYZXH311ZSXlzN16lRyc3Oj/t1ryxKBMSmiQwdXHRRqfqydffbZFVUjGzdu5IILLmDp0qWICCUlJSE/c/LJJ7PXXnux1157ccABB7B27VratWtXqczAgQMr5vXt25cVK1bQrFkzOnfuXHHd/OjRo5k8efJuyy8pKeGKK65g3rx5pKenU+B1QDZz5kwuvPBCMjIyANh3333ZvHkzq1evZoTXHUHjxo0jWu+RI0dWvP7222+59dZb2bBhA8XFxfz+978H4MMPP+SFF14AID09nZYtW9KyZUtatWrF3LlzWbt2Lf369aNVq1YRfWcsWCIwJkVMnFi5jQAgI8PNj7WmTZtWvL7tttsYOnQob7zxBitWrGDIkCEhP7PXXntVvE5PT6e0tDSiMoHqoZo89NBDtG7dmvnz51NeXl6xc1fV3S65DLfMBg0aUF5eXjFd9Xr94PUeM2YM06dPp0+fPjz33HN8/PHH1cZ38cUX89xzz/HTTz8xduzYiNYpVqyNwJgUkZ0NkydDx44g4p4nT659Q3GkNm7cSNu2bQEq6tNjqVu3bixfvpwVK1YAMG3atLBxtGnThrS0NF588UXKysoAOPHEE5kyZUpFHf6vv/5KixYtaNeuHdOnTwdgx44dbN26lY4dO7Jo0SJ27NjBxo0bmTVrVti4Nm/eTJs2bSgpKSEn6PKs448/nieeeAJwjcqbNm0CYMSIEbz77rvk5eVVnD3UFUsExqSQ7GxYsQLKy92z30kA4MYbb+Qvf/kLRx11VMXON5aaNGnC448/zvDhwxk8eDCtW7emZcuWu5W77LLLeP755zniiCMoKCioOHofPnw4p556KllZWfTt25f7778fgBdffJFHHnmE3r17M2jQIH766Sfat2/POeecQ+/evcnOzqZfv35h4/r73//O4YcfzgknnEC3bt0q5j/88MN89NFH9OrViwEDBrBw4UIAGjVqxNChQznnnHPq/IojifS0qr7IysrS/Pz8eIdhTL3w3Xff0b1793iHEXfFxcU0a9YMVeXyyy+nS5cuXHvttfEOKyrl5eX079+fV199lS57OHBKqL8LEflaVUNer2tnBMaYhPfUU0/Rt29fevbsycaNG7n00kvjHVJUFi1axCGHHMLxxx+/x0mgNqyx2BiT8K699tqEOwMI1qNHD5YvXx6377czAmOMSXGWCIwxJsX5mghEZLiILBGRQhG5OcT72SKywHvMFpE+fsZjjDFmd74lAhFJBx4DTgJ6AKNFpEeVYt8Dx6pqb+DvwO63AxpjjPGVn2cEA4FCVV2uqjuBqcBpwQVUdbaq/uZNfgm0wxiTMIYMGcJ7771Xad6kSZO47LLLqv1M4BLwP/zhD2zYsGG3MnfeeWfF9fzhTJ8+nUWLFlVM33777cycOTOK6E2An4mgLRDcQ1ORNy+ci4B3Qr0hIuNEJF9E8tetWxfDEI0xe2L06NFMnTq10rypU6eG7fitqhkzZrD33nvX6rurJoK77rqLYcOG1WpZ8eLHDXa14WciCDVeWsi710RkKC4R3BTqfVWdrKpZqpq1//77xzBEY5LHNdfAkCGxfVxzTfXfedZZZ/H222+zY8cOwHX1vGbNGgYPHsyECRPIysqiZ8+e3HHHHSE/n5mZyS+//ALAxIkTOfTQQxk2bFhFV9VAyO6cZ8+ezVtvvcUNN9xA3759WbZsGWPGjOHf//43ALNmzaJfv3706tWLsWPHVsSXmZnJHXfcQf/+/enVqxeLFy/eLaZU7K7az0RQBLQPmm4HrKlaSER6A08Dp6nqeh/jMcbEWKtWrRg4cCDvvvsu4M4GRo4ciYgwceJE8vPzWbBgAZ988gkLFiwIu5yvv/6aqVOnMnfuXF5//XXy8vIq3jvjjDPIy8tj/vz5dO/enWeeeYZBgwZx6qmnct999zFv3jwOPvjgivLbt29nzJgxTJs2jW+++YbS0tKKvn0A9ttvP+bMmcOECRNCVj8FuqueM2cO06ZNqxhFLbi76vnz53PjjTcCrrvqyy+/nPnz5zN79mzatGlT4+8W6K561KhRIdcPqOiuev78+cyZM4eePXty0UUX8fzzzwNUdFedHYN+Qvy8oSwP6CIinYDVwCjg3OACItIBeB34k6oW+BiLMUlv0qT4fG+geui0005j6tSpTJkyBYBXXnmFyZMnU1payo8//siiRYvo3bt3yGV89tlnjBgxoqIr6FNPPbXivXDdOYezZMkSOnXqRNeuXQG44IILeOyxx7jGO70544wzABgwYACvv/76bp9Pxe6qfTsjUNVS4ArgPeA74BVVXSgi40VkvFfsdqAV8LiIzBMRXzoRivU4rcaYXU4//XRmzZrFnDlz2LZtG/379+f777/n/vvvZ9asWSxYsICTTz55ty6bq6raFXTAmDFjePTRR/nmm2+44447alxOTf2nBbqyDtfVdXB31fn5+RVjL/vZXXU06xforvrZZ5+NWXfVvt5HoKozVLWrqh6sqhO9eU+q6pPe64tVdR9V7es9ah7ANEqBcVpXrgTVXeO0WjIwJjaaNWvGkCFDGDt2bEUj8aZNm2jatCktW7Zk7dq1vPNOyOtAKhxzzDG88cYbbNu2jc2bN/N///d/Fe+F6865efPmbN68ebdldevWjRUrVlBYWAi4XkSPPfbYiNcnFburTvo7i+tqnFZjUtno0aOZP38+o0aNAqBPnz7069ePnj17MnbsWI466qhqP9+/f39GjhxJ3759OfPMMzn66KMr3gvXnfOoUaO477776NevH8uWLauY37hxY5599lnOPvtsevXqRVpaGuPHjydSqdhdddJ3Q52W5s4EqhJxfbIbk8isG+rUE0l31dYNdRXhxmP1Y5xWY4zxk1/dVSd9N9R1OU6rMcb4ya/uqpP+jCBe47QaU1cSrXrX+Ks2fw9Jf0YAbqdvO36TjBo3bsz69etp1apV2MsvTepQVdavXx/x/QwBKZEIjElW7dq1o6ioCOuDywQ0btyYdu2i67/TEoExCaxhw4Z06tQp3mGYBJf0bQTGGGOqZ4nAGGNSnCUCY4xJcQl3Z7GIrANWVpm9H/BLHMLxS7KtDyTfOiXb+kDyrVOyrQ/s2Tp1VNWQA7okXCIIRUTy/eiwLl6SbX0g+dYp2dYHkm+dkm19wL91sqohY4xJcZYIjDEmxSVLIpgc7wBiLNnWB5JvnZJtfSD51inZ1gd8WqekaCMwxhhTe8lyRmCMMaaWLBEYY0yKS+hEICLDRWSJiBSKyM3xjicWRGSFiHwjIvNEJPKh2OoREZkiIj+LyLdB8/YVkQ9EZKn3vE88Y4xGmPW5U0RWe9tpnoj8IZ4xRkNE2ovIRyLynYgsFJGrvfmJvI3CrVNCbicRaSwiuSIy31ufv3nzfdlGCdtGICLpQAFwAlAE5AGjVXVRXAPbQyKyAshS1YS9EUZEjgGKgRdU9XfevHuBX1X1bi9p76OqN8UzzkiFWZ87gWJVvT+esdWGiLQB2qjqHBFpDnwNnA6MIXG3Ubh1OocE3E7i+hRvqqrFItIQ+By4GjgDH7ZRIp8RDAQKVXW5qu4EpgKnxTkmA6jqp8CvVWafBjzvvX4e90+aEMKsT8JS1R9VdY73ejPwHdCWxN5G4dYpIalT7E029B6KT9sokRNBW+CHoOkiEnjDB1HgfRH5WkTGxTuYGGqtqj+C+6cFDohzPLFwhYgs8KqOEqYaJZiIZAL9gK9Ikm1UZZ0gQbeTiKSLyDzgZ+ADVfVtGyVyIgg1HFNi1nNVdpSq9gdOAi73qiVM/fMEcDDQF/gReCCu0dSCiDQDXgOuUdVN8Y4nFkKsU8JuJ1UtU9W+QDtgoIj8zq/vSuREUAS0D5puB6yJUywxo6prvOefgTdwVWDJYK1Xjxuoz/05zvHsEVVd6/2jlgNPkWDbyat3fg3IUdXXvdkJvY1CrVOibycAVd0AfAwMx6dtlMiJIA/oIiKdRKQRMAp4K84x7RERaeo1dCEiTYETgW+r/1TCeAu4wHt9AfBmHGPZY4F/Rs8IEmg7eQ2RzwDfqeqDQW8l7DYKt06Jup1EZH8R2dt73QQYBizGp22UsFcNAXiXgk0C0oEpqjoxvhHtGRHpjDsLADeM6L8ScZ1E5GVgCK7L3LXAHcB04BWgA7AKOFtVE6IBNsz6DMFVNyiwArg0UHdb34nIYOAz4Bug3Jv9V1ydeqJuo3DrNJoE3E4i0hvXGJyOO2B/RVXvEpFW+LCNEjoRGGOM2XOJXDVkjDEmBiwRGGNMirNEYIwxKc4SgTHGpDhLBMYYk+IsERjjEZGyoF4q58WyR1sRyQzuvdSY+qRBvAMwph7Z5t3Sb0xKsTMCY2rgjRFxj9c/fK6IHOLN7ygis7wOzWaJSAdvfmsRecPrS36+iAzyFpUuIk95/cu/790xiohcJSKLvOVMjdNqmhRmicCYXZpUqRoaGfTeJlUdCDyKu5sd7/ULqtobyAEe8eY/Anyiqn2A/sBCb34X4DFV7QlsAM705t8M9POWM96fVTMmPLuz2BiPiBSrarMQ81cAx6nqcq9js59UtZWI/IIbDKXEm/+jqu4nIuuAdqq6I2gZmbiuhLt40zcBDVX1HyLyLm7gm+nA9KB+6I2pE3ZGYExkNMzrcGVC2RH0uoxdbXQnA48BA4CvRcTa7kydskRgTGRGBj1/4b2ejev1FiAbN5wgwCxgAlQMLtIi3EJFJA1or6ofATcCewO7nZUY4yc78jBmlybeiFAB76pq4BLSvUTkK9zB02hv3lXAFBG5AVgHXOjNvxqYLCIX4Y78J+AGRQklHXhJRFriBlt6yOt/3pg6Y20ExtTAayPIUtVf4h2LMX6wqiFjjElxdkZgjDEpzs4IjDEmxVkiMMaYFGeJwBhjUpwlAmOMSXGWCIwxJsX9f9IjGB7eikZwAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(history_1_2)\n",
    "plot_acc(history_1_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trying Global Max Pooling and layers.Flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Which last layer to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_11 (Rescaling)    (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 94, 94, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 47, 47, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 43, 43, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 256)              0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,183,046\n",
      "Trainable params: 1,183,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 02:12:59.088829: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1.7943 - accuracy: 0.1555"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 02:13:11.330927: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 13s 94ms/step - loss: 1.7943 - accuracy: 0.1555 - val_loss: 1.7918 - val_accuracy: 0.1667\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 1.8069 - accuracy: 0.1797 - val_loss: 1.7908 - val_accuracy: 0.1667\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 11s 92ms/step - loss: 1.6691 - accuracy: 0.3060 - val_loss: 1.1956 - val_accuracy: 0.5688\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 1.0842 - accuracy: 0.5880 - val_loss: 0.6539 - val_accuracy: 0.7521\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 11s 92ms/step - loss: 0.6770 - accuracy: 0.7565 - val_loss: 0.4578 - val_accuracy: 0.8271\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.4642 - accuracy: 0.8318 - val_loss: 0.3832 - val_accuracy: 0.8729\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 12s 97ms/step - loss: 0.3128 - accuracy: 0.8938 - val_loss: 0.3566 - val_accuracy: 0.8875\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 0.2269 - accuracy: 0.9201 - val_loss: 0.2709 - val_accuracy: 0.9063\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 0.1468 - accuracy: 0.9487 - val_loss: 0.2318 - val_accuracy: 0.9229\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.1188 - accuracy: 0.9656 - val_loss: 0.3192 - val_accuracy: 0.9271\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 0.0984 - accuracy: 0.9664 - val_loss: 0.3314 - val_accuracy: 0.9250\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 0.0756 - accuracy: 0.9745 - val_loss: 0.6012 - val_accuracy: 0.8917\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.0796 - accuracy: 0.9755 - val_loss: 0.3177 - val_accuracy: 0.9063\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 0.0624 - accuracy: 0.9815 - val_loss: 0.2986 - val_accuracy: 0.9333\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.0515 - accuracy: 0.9839 - val_loss: 0.4971 - val_accuracy: 0.9188\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 0.0567 - accuracy: 0.9859 - val_loss: 0.4458 - val_accuracy: 0.9333\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 14s 120ms/step - loss: 0.0517 - accuracy: 0.9846 - val_loss: 0.5105 - val_accuracy: 0.9229\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.0513 - accuracy: 0.9880 - val_loss: 0.7396 - val_accuracy: 0.9146\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 15s 126ms/step - loss: 0.0527 - accuracy: 0.9872 - val_loss: 0.3358 - val_accuracy: 0.9417\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 15s 126ms/step - loss: 0.0371 - accuracy: 0.9880 - val_loss: 0.6201 - val_accuracy: 0.9375\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.0571 - accuracy: 0.9857 - val_loss: 0.3778 - val_accuracy: 0.9417\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.5648 - val_accuracy: 0.9417\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0532 - accuracy: 0.9888 - val_loss: 0.4708 - val_accuracy: 0.9375\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 0.0410 - accuracy: 0.9885 - val_loss: 0.5914 - val_accuracy: 0.9333\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 15s 125ms/step - loss: 0.0517 - accuracy: 0.9878 - val_loss: 0.6890 - val_accuracy: 0.9292\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0332 - accuracy: 0.9914 - val_loss: 0.9566 - val_accuracy: 0.9208\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 0.0427 - accuracy: 0.9909 - val_loss: 0.6001 - val_accuracy: 0.9521\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 0.0574 - accuracy: 0.9904 - val_loss: 0.6132 - val_accuracy: 0.9354\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 0.0319 - accuracy: 0.9951 - val_loss: 0.6805 - val_accuracy: 0.9500\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 0.0600 - accuracy: 0.9906 - val_loss: 1.1188 - val_accuracy: 0.9125\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model_2_1 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_2_1.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_2_1.summary()\n",
    "\n",
    "history_2_1 = model_2_1.fit(\n",
    "  train,\n",
    "  epochs=30,\n",
    "  validation_data=val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_12 (Rescaling)    (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 94, 94, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 47, 47, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_78 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_79 (Conv2D)          (None, 43, 43, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_42 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_80 (Conv2D)          (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_81 (Conv2D)          (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_43 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_82 (Conv2D)          (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_83 (Conv2D)          (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 6)                 24582     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,206,086\n",
      "Trainable params: 1,206,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 02:19:45.836245: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1.8636 - accuracy: 0.1909"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 02:19:59.642267: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 15s 110ms/step - loss: 1.8636 - accuracy: 0.1909 - val_loss: 1.7503 - val_accuracy: 0.3417\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 14s 119ms/step - loss: 1.2142 - accuracy: 0.5453 - val_loss: 0.8133 - val_accuracy: 0.7000\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 15s 121ms/step - loss: 0.7119 - accuracy: 0.7391 - val_loss: 0.4855 - val_accuracy: 0.8229\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 0.4437 - accuracy: 0.8445 - val_loss: 0.3889 - val_accuracy: 0.8479\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.2811 - accuracy: 0.9016 - val_loss: 0.3960 - val_accuracy: 0.8792\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.1879 - accuracy: 0.9383 - val_loss: 0.3437 - val_accuracy: 0.9000\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.1486 - accuracy: 0.9521 - val_loss: 0.4034 - val_accuracy: 0.9083\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.1062 - accuracy: 0.9667 - val_loss: 0.4435 - val_accuracy: 0.9063\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0839 - accuracy: 0.9695 - val_loss: 0.3886 - val_accuracy: 0.9292\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0694 - accuracy: 0.9789 - val_loss: 0.6957 - val_accuracy: 0.8792\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0642 - accuracy: 0.9826 - val_loss: 1.5322 - val_accuracy: 0.7875\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 0.0798 - accuracy: 0.9794 - val_loss: 0.3295 - val_accuracy: 0.9333\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 16s 131ms/step - loss: 0.0493 - accuracy: 0.9872 - val_loss: 0.4543 - val_accuracy: 0.9375\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 15s 126ms/step - loss: 0.0444 - accuracy: 0.9883 - val_loss: 0.5178 - val_accuracy: 0.9146\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0539 - accuracy: 0.9854 - val_loss: 0.4557 - val_accuracy: 0.9167\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0437 - accuracy: 0.9919 - val_loss: 0.7137 - val_accuracy: 0.9271\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 15s 127ms/step - loss: 0.0430 - accuracy: 0.9891 - val_loss: 0.5609 - val_accuracy: 0.9354\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0643 - accuracy: 0.9870 - val_loss: 0.4234 - val_accuracy: 0.9229\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0506 - accuracy: 0.9867 - val_loss: 0.7249 - val_accuracy: 0.8896\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0434 - accuracy: 0.9904 - val_loss: 0.5668 - val_accuracy: 0.8979\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0430 - accuracy: 0.9893 - val_loss: 0.7283 - val_accuracy: 0.9125\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0707 - accuracy: 0.9875 - val_loss: 0.5432 - val_accuracy: 0.9313\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0455 - accuracy: 0.9893 - val_loss: 0.8094 - val_accuracy: 0.9042\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 1.4556 - val_accuracy: 0.9104\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 0.0729 - accuracy: 0.9896 - val_loss: 1.0587 - val_accuracy: 0.9146\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 0.0405 - accuracy: 0.9919 - val_loss: 0.6751 - val_accuracy: 0.9313\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 0.0526 - accuracy: 0.9917 - val_loss: 0.6043 - val_accuracy: 0.9292\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0351 - accuracy: 0.9948 - val_loss: 0.8040 - val_accuracy: 0.9188\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0246 - accuracy: 0.9953 - val_loss: 0.9972 - val_accuracy: 0.9250\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 0.0634 - accuracy: 0.9906 - val_loss: 1.2345 - val_accuracy: 0.8875\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model_2_2 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_2_2.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_2_2.summary()\n",
    "\n",
    "history_2_2 = model_2_2.fit(\n",
    "  train,\n",
    "  epochs=30,\n",
    "  validation_data=val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Regularizing the model and testing different learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Regularizer and different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_19 (InputLayer)       [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_18 (Rescaling)    (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d_129 (Conv2D)         (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " conv2d_130 (Conv2D)         (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_131 (Conv2D)         (None, 94, 94, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 47, 47, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_132 (Conv2D)         (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_133 (Conv2D)         (None, 43, 43, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_134 (Conv2D)         (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_135 (Conv2D)         (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_136 (Conv2D)         (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_137 (Conv2D)         (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " global_average_pooling2d_15  (None, 256)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,248,838\n",
      "Trainable params: 1,248,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 02:41:14.606606: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1.8071 - accuracy: 0.1732"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 02:41:27.367319: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 14s 99ms/step - loss: 1.8071 - accuracy: 0.1732 - val_loss: 1.7936 - val_accuracy: 0.1667\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 1.7884 - accuracy: 0.2029 - val_loss: 1.7842 - val_accuracy: 0.1667\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 11s 93ms/step - loss: 1.5900 - accuracy: 0.3646 - val_loss: 0.9973 - val_accuracy: 0.6542\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 11s 95ms/step - loss: 1.0763 - accuracy: 0.6216 - val_loss: 0.7668 - val_accuracy: 0.7271\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 12s 97ms/step - loss: 0.6778 - accuracy: 0.7651 - val_loss: 0.5766 - val_accuracy: 0.8229\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 12s 100ms/step - loss: 0.4874 - accuracy: 0.8268 - val_loss: 0.3824 - val_accuracy: 0.8625\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 12s 101ms/step - loss: 0.3522 - accuracy: 0.8867 - val_loss: 0.3025 - val_accuracy: 0.8917\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.2874 - accuracy: 0.9091 - val_loss: 0.2952 - val_accuracy: 0.9104\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.2409 - accuracy: 0.9305 - val_loss: 0.3174 - val_accuracy: 0.8958\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.1985 - accuracy: 0.9341 - val_loss: 0.2599 - val_accuracy: 0.9292\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.1556 - accuracy: 0.9529 - val_loss: 0.3546 - val_accuracy: 0.9271\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.1472 - accuracy: 0.9576 - val_loss: 0.3214 - val_accuracy: 0.9063\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.1176 - accuracy: 0.9651 - val_loss: 0.3234 - val_accuracy: 0.9208\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.1009 - accuracy: 0.9714 - val_loss: 0.2594 - val_accuracy: 0.9417\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.1151 - accuracy: 0.9747 - val_loss: 0.2994 - val_accuracy: 0.9375\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 13s 107ms/step - loss: 0.1141 - accuracy: 0.9747 - val_loss: 0.2221 - val_accuracy: 0.9542\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 0.0810 - accuracy: 0.9792 - val_loss: 0.3148 - val_accuracy: 0.9583\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 13s 109ms/step - loss: 0.1107 - accuracy: 0.9745 - val_loss: 0.2528 - val_accuracy: 0.9396\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.0762 - accuracy: 0.9833 - val_loss: 0.3137 - val_accuracy: 0.9500\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.0828 - accuracy: 0.9799 - val_loss: 0.4975 - val_accuracy: 0.9354\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 13s 107ms/step - loss: 0.0741 - accuracy: 0.9826 - val_loss: 0.3323 - val_accuracy: 0.9500\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 0.0795 - accuracy: 0.9820 - val_loss: 0.3698 - val_accuracy: 0.9229\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 13s 107ms/step - loss: 0.0725 - accuracy: 0.9849 - val_loss: 0.3534 - val_accuracy: 0.9354\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.0557 - accuracy: 0.9883 - val_loss: 0.3698 - val_accuracy: 0.9354\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.0867 - accuracy: 0.9831 - val_loss: 0.3609 - val_accuracy: 0.9396\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 13s 107ms/step - loss: 0.0655 - accuracy: 0.9880 - val_loss: 0.2948 - val_accuracy: 0.9542\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 0.0764 - accuracy: 0.9883 - val_loss: 0.2310 - val_accuracy: 0.9625\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 0.0546 - accuracy: 0.9904 - val_loss: 0.7061 - val_accuracy: 0.9063\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 13s 107ms/step - loss: 0.0515 - accuracy: 0.9927 - val_loss: 1.2898 - val_accuracy: 0.8938\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 13s 107ms/step - loss: 0.1323 - accuracy: 0.9841 - val_loss: 0.2861 - val_accuracy: 0.9646\n"
     ]
    }
   ],
   "source": [
    "# adding l2 regularization\n",
    "# regularizer = keras.regularizers.L2(0.00004)\n",
    "# regularizer = keras.regularizers.l1_l2(0.00004)\n",
    "regularizer = keras.regularizers.L2(0.00004)\n",
    "\n",
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Dense(256, kernel_regularizer=regularizer, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model_3_1 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_3_1.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_3_1.summary()\n",
    "\n",
    "history_3_1 = model_3_1.fit(\n",
    "  train,\n",
    "  epochs=30,\n",
    "  validation_data=val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adding residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_35 (InputLayer)          [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling_31 (Rescaling)       (None, 100, 100, 3)  0           ['input_35[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)            (None, 98, 98, 32)   864         ['rescaling_31[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 98, 98, 32)  128         ['conv2d_249[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 98, 98, 32)   0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)            (None, 98, 98, 32)   9216        ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 98, 98, 32)  128         ['conv2d_250[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 98, 98, 32)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)            (None, 98, 98, 32)   9216        ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_110 (MaxPooling2  (None, 49, 49, 32)  0           ['conv2d_251[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)            (None, 49, 49, 32)   1024        ['conv2d_249[0][0]']             \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 49, 49, 32)   0           ['max_pooling2d_110[0][0]',      \n",
      "                                                                  'conv2d_252[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 49, 49, 32)  128         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 49, 49, 32)   0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)            (None, 49, 49, 64)   18432       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 49, 49, 64)  256         ['conv2d_253[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 49, 49, 64)   0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)            (None, 49, 49, 64)   36864       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_111 (MaxPooling2  (None, 25, 25, 64)  0           ['conv2d_254[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)            (None, 25, 25, 64)   2048        ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 25, 25, 64)   0           ['max_pooling2d_111[0][0]',      \n",
      "                                                                  'conv2d_255[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 25, 25, 64)  256         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)            (None, 25, 25, 128)  73728       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 25, 25, 128)  512        ['conv2d_256[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 25, 25, 128)  0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)            (None, 25, 25, 128)  147456      ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_112 (MaxPooling2  (None, 13, 13, 128)  0          ['conv2d_257[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_258 (Conv2D)            (None, 13, 13, 128)  8192        ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 13, 13, 128)  0           ['max_pooling2d_112[0][0]',      \n",
      "                                                                  'conv2d_258[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 13, 13, 128)  512        ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 13, 13, 128)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_259 (Conv2D)            (None, 13, 13, 256)  294912      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_259[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 13, 13, 256)  0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_260 (Conv2D)            (None, 13, 13, 256)  589824      ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_113 (MaxPooling2  (None, 7, 7, 256)   0           ['conv2d_260[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_261 (Conv2D)            (None, 7, 7, 256)    32768       ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 7, 7, 256)    0           ['max_pooling2d_113[0][0]',      \n",
      "                                                                  'conv2d_261[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 7, 7, 256)   1024        ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 7, 7, 256)    0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_262 (Conv2D)            (None, 7, 7, 512)    1179648     ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_262[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)            (None, 7, 7, 512)    2359296     ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_114 (MaxPooling2  (None, 4, 4, 512)   0           ['conv2d_263[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)            (None, 4, 4, 512)    131072      ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 4, 4, 512)    0           ['max_pooling2d_114[0][0]',      \n",
      "                                                                  'conv2d_264[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_31 (G  (None, 512)         0           ['add_16[0][0]']                 \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_33 (Dropout)           (None, 512)          0           ['global_average_pooling2d_31[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_35 (Dense)               (None, 6)            3078        ['dropout_33[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,903,654\n",
      "Trainable params: 4,900,646\n",
      "Non-trainable params: 3,008\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "regularizer = keras.regularizers.L2(0.00004)\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, use_bias=False)(x)\n",
    "\n",
    "for size in [32, 64, 128, 256, 512]:\n",
    "  residual = x\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Activation(\"relu\")(x)\n",
    "  x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False, kernel_regularizer=regularizer)(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Activation(\"relu\")(x)\n",
    "  x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
    "  x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "  residual = layers.Conv2D(size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
    "  x = layers.add([x, residual])\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model_4_1 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_4_1.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_4_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 05:37:44.882674: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 6.9660 - accuracy: 0.3336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 05:38:13.100071: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 30s 208ms/step - loss: 6.9660 - accuracy: 0.3336 - val_loss: 4.6550 - val_accuracy: 0.1667\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 25s 204ms/step - loss: 2.0950 - accuracy: 0.4987 - val_loss: 7.0950 - val_accuracy: 0.1833\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 25s 211ms/step - loss: 1.1525 - accuracy: 0.6669 - val_loss: 2.1183 - val_accuracy: 0.4313\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 26s 216ms/step - loss: 0.7136 - accuracy: 0.7797 - val_loss: 0.9841 - val_accuracy: 0.6771\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 26s 220ms/step - loss: 0.4613 - accuracy: 0.8487 - val_loss: 0.5663 - val_accuracy: 0.8313\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 27s 225ms/step - loss: 0.3278 - accuracy: 0.8966 - val_loss: 10.0095 - val_accuracy: 0.4354\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 27s 226ms/step - loss: 0.2629 - accuracy: 0.9177 - val_loss: 0.9413 - val_accuracy: 0.7854\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 28s 230ms/step - loss: 0.2136 - accuracy: 0.9359 - val_loss: 4.8676 - val_accuracy: 0.5333\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 28s 229ms/step - loss: 0.1622 - accuracy: 0.9508 - val_loss: 1.4522 - val_accuracy: 0.7792\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 30s 253ms/step - loss: 0.1461 - accuracy: 0.9604 - val_loss: 1.2549 - val_accuracy: 0.7875\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 32s 268ms/step - loss: 0.1384 - accuracy: 0.9633 - val_loss: 6.3426 - val_accuracy: 0.4458\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 0.1182 - accuracy: 0.9714 - val_loss: 0.6210 - val_accuracy: 0.9042\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 33s 277ms/step - loss: 0.0946 - accuracy: 0.9771 - val_loss: 1.4827 - val_accuracy: 0.7938\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 33s 275ms/step - loss: 0.0918 - accuracy: 0.9753 - val_loss: 2.3613 - val_accuracy: 0.7313\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 0.1062 - accuracy: 0.9745 - val_loss: 0.8788 - val_accuracy: 0.9021\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 33s 273ms/step - loss: 0.0831 - accuracy: 0.9784 - val_loss: 2.2001 - val_accuracy: 0.7354\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 33s 275ms/step - loss: 0.0469 - accuracy: 0.9878 - val_loss: 0.5263 - val_accuracy: 0.9167\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 33s 276ms/step - loss: 0.0612 - accuracy: 0.9841 - val_loss: 0.5853 - val_accuracy: 0.8875\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 33s 274ms/step - loss: 0.0686 - accuracy: 0.9857 - val_loss: 0.3878 - val_accuracy: 0.9583\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 33s 275ms/step - loss: 0.0613 - accuracy: 0.9878 - val_loss: 1.0343 - val_accuracy: 0.8854\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 33s 279ms/step - loss: 0.0754 - accuracy: 0.9883 - val_loss: 0.5267 - val_accuracy: 0.9188\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 0.0739 - accuracy: 0.9867 - val_loss: 0.7377 - val_accuracy: 0.9042\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 35s 289ms/step - loss: 0.0723 - accuracy: 0.9883 - val_loss: 1.5411 - val_accuracy: 0.8063\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 35s 290ms/step - loss: 0.0720 - accuracy: 0.9849 - val_loss: 2.4600 - val_accuracy: 0.8042\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 35s 289ms/step - loss: 0.0414 - accuracy: 0.9914 - val_loss: 2.0287 - val_accuracy: 0.8563\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 35s 292ms/step - loss: 0.0389 - accuracy: 0.9922 - val_loss: 0.4503 - val_accuracy: 0.9104\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 35s 289ms/step - loss: 0.0686 - accuracy: 0.9875 - val_loss: 0.4261 - val_accuracy: 0.9458\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 34s 287ms/step - loss: 0.0460 - accuracy: 0.9898 - val_loss: 5.2728 - val_accuracy: 0.6896\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 34s 286ms/step - loss: 0.0518 - accuracy: 0.9893 - val_loss: 5.3322 - val_accuracy: 0.7250\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 0.0406 - accuracy: 0.9906 - val_loss: 3.6230 - val_accuracy: 0.6938\n"
     ]
    }
   ],
   "source": [
    "history_4_1 = model_4_1.fit(\n",
    "  train,\n",
    "  epochs=30,\n",
    "  validation_data=val\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experimenting with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this method for M1 Mac CPU acces to run augmentation\n",
    "with tf.device('/cpu:0'):\n",
    "  data_augmentation = keras.Sequential(\n",
    "  [\n",
    "      layers.RandomFlip(\"horizontal\"),\n",
    "      layers.RandomRotation(0.1),\n",
    "      layers.RandomZoom(0.2),\n",
    "      layers.RandomContrast(0.2),\n",
    "      layers.RandomTranslation(height_factor=0.2,width_factor=0.3)\n",
    "  ] \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_24 (InputLayer)       [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " rescaling_23 (Rescaling)    (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d_174 (Conv2D)         (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " conv2d_175 (Conv2D)         (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_176 (Conv2D)         (None, 94, 94, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_74 (MaxPoolin  (None, 47, 47, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_177 (Conv2D)         (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_178 (Conv2D)         (None, 43, 43, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_75 (MaxPoolin  (None, 21, 21, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_179 (Conv2D)         (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_180 (Conv2D)         (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_76 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_181 (Conv2D)         (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_182 (Conv2D)         (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " global_average_pooling2d_20  (None, 256)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,183,046\n",
      "Trainable params: 1,183,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 03:28:26.276497: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1.7965 - accuracy: 0.1646"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 03:28:42.678326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 18s 128ms/step - loss: 1.7965 - accuracy: 0.1646 - val_loss: 1.7916 - val_accuracy: 0.1667\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 16s 131ms/step - loss: 1.8456 - accuracy: 0.1865 - val_loss: 1.7169 - val_accuracy: 0.2646\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 1.6755 - accuracy: 0.3221 - val_loss: 1.4007 - val_accuracy: 0.4188\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 16s 134ms/step - loss: 1.3497 - accuracy: 0.4560 - val_loss: 1.0895 - val_accuracy: 0.5417\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 16s 132ms/step - loss: 1.1588 - accuracy: 0.5474 - val_loss: 0.9553 - val_accuracy: 0.6250\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 16s 132ms/step - loss: 0.9877 - accuracy: 0.6242 - val_loss: 0.8074 - val_accuracy: 0.7104\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 16s 131ms/step - loss: 0.8530 - accuracy: 0.6750 - val_loss: 0.8520 - val_accuracy: 0.6625\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 16s 129ms/step - loss: 0.7695 - accuracy: 0.7107 - val_loss: 0.5763 - val_accuracy: 0.7854\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 15s 129ms/step - loss: 0.7153 - accuracy: 0.7380 - val_loss: 0.5742 - val_accuracy: 0.7792\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 15s 126ms/step - loss: 0.6284 - accuracy: 0.7698 - val_loss: 0.4859 - val_accuracy: 0.8125\n",
      "Epoch 11/30\n",
      "119/120 [============================>.] - ETA: 0s - loss: 0.5520 - accuracy: 0.7936"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sid/Documents/FP_final_repo/vehicle_classification/notebooks_new/3_tuning_model_parameters.ipynb Cell 32\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sid/Documents/FP_final_repo/vehicle_classification/notebooks_new/3_tuning_model_parameters.ipynb#X55sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m model_5_1\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mRMSprop(\u001b[39m0.001\u001b[39m), loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sid/Documents/FP_final_repo/vehicle_classification/notebooks_new/3_tuning_model_parameters.ipynb#X55sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model_5_1\u001b[39m.\u001b[39msummary()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sid/Documents/FP_final_repo/vehicle_classification/notebooks_new/3_tuning_model_parameters.ipynb#X55sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m history_5_1 \u001b[39m=\u001b[39m model_5_1\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sid/Documents/FP_final_repo/vehicle_classification/notebooks_new/3_tuning_model_parameters.ipynb#X55sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m   train\u001b[39m.\u001b[39;49mcache(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sid/Documents/FP_final_repo/vehicle_classification/notebooks_new/3_tuning_model_parameters.ipynb#X55sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sid/Documents/FP_final_repo/vehicle_classification/notebooks_new/3_tuning_model_parameters.ipynb#X55sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m   validation_data\u001b[39m=\u001b[39;49mval\u001b[39m.\u001b[39;49mcache()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sid/Documents/FP_final_repo/vehicle_classification/notebooks_new/3_tuning_model_parameters.ipynb#X55sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py:1221\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1219\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1221\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1222\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1223\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/callbacks.py:436\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \n\u001b[1;32m    431\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 436\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/callbacks.py:295\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    294\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 295\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. Expected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    314\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 316\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    319\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/callbacks.py:354\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    353\u001b[0m   hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 354\u001b[0m   hook(batch, logs)\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    357\u001b[0m   \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/callbacks.py:1032\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1032\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/callbacks.py:1104\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1102\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1103\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1104\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1105\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/utils/tf_utils.py:554\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    552\u001b[0m   \u001b[39mreturn\u001b[39;00m t  \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tensorflow/python/util/nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    866\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    868\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    870\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tensorflow/python/util/nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    865\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    866\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    868\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    870\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/utils/tf_utils.py:550\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    549\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 550\u001b[0m     x \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    551\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    552\u001b[0m   \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1149\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \n\u001b[1;32m   1128\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1148\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1149\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1115\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1114\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1115\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1116\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "with tf.device('/cpu:0'):\n",
    "  x = data_augmentation(inputs)\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model_5_1 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_5_1.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_5_1.summary()\n",
    "\n",
    "history_5_1 = model_5_1.fit(\n",
    "  train,\n",
    "  epochs=30,\n",
    "  validation_data=val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Experimenting with image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new modified train, test and val datasets after applying image processing\n",
    "\n",
    "def process_image(x):\n",
    "  x = tf.image.adjust_brightness(x, 0.8)\n",
    "  x = tf.image.adjust_contrast(x, 3)\n",
    "  x = tf.image.adjust_saturation(x, 2)\n",
    "  return x\n",
    "\n",
    "def process_ds(dataset):\n",
    "  return dataset.map(lambda x, y: (process_image(x), y)).prefetch(tf.data.AUTOTUNE).cache()\n",
    "  \n",
    "train_processed = process_ds(train)\n",
    "val_processed = process_ds(val)\n",
    "test_processed = process_ds(test)\n",
    "\n",
    "# train_modified = train.map(lambda x, y: (\n",
    "#   tf.image.adjust_saturation(\n",
    "#     tf.image.adjust_contrast(tf.image.adjust_brightness(x, 0.8), 3), 2) , y)\n",
    "#     ).prefetch(tf.data.AUTOTUNE).cache()\n",
    "  \n",
    "# val_modified = val.map(lambda x, y: (\n",
    "#   tf.image.adjust_saturation(\n",
    "#     tf.image.adjust_contrast(tf.image.adjust_brightness(x, 0.8), 3), 2) , y)\n",
    "#     ).prefetch(tf.data.AUTOTUNE).cache()\n",
    "    \n",
    "# test_modified = test.map(lambda x, y: (\n",
    "#   tf.image.adjust_saturation(\n",
    "#     tf.image.adjust_contrast(tf.image.adjust_brightness(x, 0.8), 3), 2) , y)\n",
    "#     ).prefetch(tf.data.AUTOTUNE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_36 (InputLayer)       [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " rescaling_32 (Rescaling)    (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d_265 (Conv2D)         (None, 98, 98, 32)        896       \n",
      "                                                                 \n",
      " conv2d_266 (Conv2D)         (None, 96, 96, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_267 (Conv2D)         (None, 94, 94, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_115 (MaxPooli  (None, 47, 47, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_268 (Conv2D)         (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_269 (Conv2D)         (None, 43, 43, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_116 (MaxPooli  (None, 21, 21, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_270 (Conv2D)         (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_271 (Conv2D)         (None, 17, 17, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_117 (MaxPooli  (None, 8, 8, 128)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_272 (Conv2D)         (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_273 (Conv2D)         (None, 4, 4, 256)         590080    \n",
      "                                                                 \n",
      " global_average_pooling2d_32  (None, 256)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,183,046\n",
      "Trainable params: 1,183,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 07:56:57.639266: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1.7217 - accuracy: 0.2688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 07:57:11.138285: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 15s 98ms/step - loss: 1.7217 - accuracy: 0.2688 - val_loss: 1.4501 - val_accuracy: 0.5750\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.9982 - accuracy: 0.6148 - val_loss: 0.6236 - val_accuracy: 0.7688\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 11s 94ms/step - loss: 0.6834 - accuracy: 0.7677 - val_loss: 0.4170 - val_accuracy: 0.8417\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.4327 - accuracy: 0.8596 - val_loss: 0.3617 - val_accuracy: 0.8708\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 11s 93ms/step - loss: 0.3226 - accuracy: 0.8917 - val_loss: 0.3247 - val_accuracy: 0.9063\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 11s 90ms/step - loss: 0.2289 - accuracy: 0.9229 - val_loss: 0.2872 - val_accuracy: 0.9104\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 11s 91ms/step - loss: 0.1897 - accuracy: 0.9388 - val_loss: 0.3325 - val_accuracy: 0.9063\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 11s 95ms/step - loss: 0.1326 - accuracy: 0.9544 - val_loss: 0.2789 - val_accuracy: 0.9292\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 11s 93ms/step - loss: 0.1219 - accuracy: 0.9646 - val_loss: 0.4005 - val_accuracy: 0.9208\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 12s 96ms/step - loss: 0.1151 - accuracy: 0.9714 - val_loss: 0.3021 - val_accuracy: 0.9229\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.0888 - accuracy: 0.9760 - val_loss: 0.4253 - val_accuracy: 0.9104\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 0.1085 - accuracy: 0.9763 - val_loss: 0.2189 - val_accuracy: 0.9396\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.0537 - accuracy: 0.9852 - val_loss: 0.3343 - val_accuracy: 0.9396\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 12s 102ms/step - loss: 0.0856 - accuracy: 0.9810 - val_loss: 0.2708 - val_accuracy: 0.9271\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.0597 - accuracy: 0.9857 - val_loss: 0.3269 - val_accuracy: 0.9458\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.0630 - accuracy: 0.9859 - val_loss: 0.2374 - val_accuracy: 0.9479\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.0714 - accuracy: 0.9883 - val_loss: 0.3657 - val_accuracy: 0.9396\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.0545 - accuracy: 0.9883 - val_loss: 0.2587 - val_accuracy: 0.9646\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 0.0511 - accuracy: 0.9875 - val_loss: 0.5485 - val_accuracy: 0.9333\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.0549 - accuracy: 0.9880 - val_loss: 1.1744 - val_accuracy: 0.8396\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 12s 103ms/step - loss: 0.0734 - accuracy: 0.9862 - val_loss: 0.3208 - val_accuracy: 0.9625\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.0463 - accuracy: 0.9909 - val_loss: 0.3949 - val_accuracy: 0.9375\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.0610 - accuracy: 0.9883 - val_loss: 0.4376 - val_accuracy: 0.9500\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.0661 - accuracy: 0.9885 - val_loss: 0.6158 - val_accuracy: 0.9396\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.0503 - accuracy: 0.9901 - val_loss: 0.2570 - val_accuracy: 0.9417\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 12s 104ms/step - loss: 0.0628 - accuracy: 0.9891 - val_loss: 0.9578 - val_accuracy: 0.9250\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.0260 - accuracy: 0.9961 - val_loss: 0.4703 - val_accuracy: 0.9542\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.0665 - accuracy: 0.9927 - val_loss: 0.6450 - val_accuracy: 0.9542\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 13s 106ms/step - loss: 0.0679 - accuracy: 0.9911 - val_loss: 0.5877 - val_accuracy: 0.9542\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 13s 105ms/step - loss: 0.0573 - accuracy: 0.9919 - val_loss: 0.4454 - val_accuracy: 0.9542\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(128, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.Conv2D(256, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model_6_1 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_6_1.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_6_1.summary()\n",
    "\n",
    "history_6_1 = model_6_1.fit(\n",
    "  train_processed,\n",
    "  epochs=30,\n",
    "  validation_data=val_processed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying processed images on residuals model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_37 (InputLayer)          [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rescaling_33 (Rescaling)       (None, 100, 100, 3)  0           ['input_37[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_274 (Conv2D)            (None, 98, 98, 32)   864         ['rescaling_33[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 98, 98, 32)  128         ['conv2d_274[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 98, 98, 32)   0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)            (None, 98, 98, 32)   9216        ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 98, 98, 32)  128         ['conv2d_275[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 98, 98, 32)   0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_276 (Conv2D)            (None, 98, 98, 32)   9216        ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_118 (MaxPooling2  (None, 49, 49, 32)  0           ['conv2d_276[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_277 (Conv2D)            (None, 49, 49, 32)   1024        ['conv2d_274[0][0]']             \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 49, 49, 32)   0           ['max_pooling2d_118[0][0]',      \n",
      "                                                                  'conv2d_277[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 49, 49, 32)  128         ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 49, 49, 32)   0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_278 (Conv2D)            (None, 49, 49, 64)   18432       ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 49, 49, 64)  256         ['conv2d_278[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 49, 49, 64)   0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_279 (Conv2D)            (None, 49, 49, 64)   36864       ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_119 (MaxPooling2  (None, 25, 25, 64)  0           ['conv2d_279[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_280 (Conv2D)            (None, 25, 25, 64)   2048        ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 25, 25, 64)   0           ['max_pooling2d_119[0][0]',      \n",
      "                                                                  'conv2d_280[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 25, 25, 64)  256         ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 25, 25, 64)   0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_281 (Conv2D)            (None, 25, 25, 128)  73728       ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 25, 25, 128)  512        ['conv2d_281[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 25, 25, 128)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_282 (Conv2D)            (None, 25, 25, 128)  147456      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_120 (MaxPooling2  (None, 13, 13, 128)  0          ['conv2d_282[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_283 (Conv2D)            (None, 13, 13, 128)  8192        ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 13, 13, 128)  0           ['max_pooling2d_120[0][0]',      \n",
      "                                                                  'conv2d_283[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 13, 13, 128)  512        ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 13, 13, 128)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_284 (Conv2D)            (None, 13, 13, 256)  294912      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 13, 13, 256)  1024       ['conv2d_284[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 13, 13, 256)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_285 (Conv2D)            (None, 13, 13, 256)  589824      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_121 (MaxPooling2  (None, 7, 7, 256)   0           ['conv2d_285[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_286 (Conv2D)            (None, 7, 7, 256)    32768       ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 7, 7, 256)    0           ['max_pooling2d_121[0][0]',      \n",
      "                                                                  'conv2d_286[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 7, 7, 256)   1024        ['add_20[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 7, 7, 256)    0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_287 (Conv2D)            (None, 7, 7, 512)    1179648     ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 7, 7, 512)   2048        ['conv2d_287[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_288 (Conv2D)            (None, 7, 7, 512)    2359296     ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_122 (MaxPooling2  (None, 4, 4, 512)   0           ['conv2d_288[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_289 (Conv2D)            (None, 4, 4, 512)    131072      ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 4, 4, 512)    0           ['max_pooling2d_122[0][0]',      \n",
      "                                                                  'conv2d_289[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_33 (G  (None, 512)         0           ['add_21[0][0]']                 \n",
      " lobalAveragePooling2D)                                                                           \n",
      "                                                                                                  \n",
      " dropout_35 (Dropout)           (None, 512)          0           ['global_average_pooling2d_33[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 6)            3078        ['dropout_35[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,903,654\n",
      "Trainable params: 4,900,646\n",
      "Non-trainable params: 3,008\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 08:03:38.583418: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 6.4994 - accuracy: 0.3477"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 08:04:08.693380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 33s 225ms/step - loss: 6.4994 - accuracy: 0.3477 - val_loss: 3.9369 - val_accuracy: 0.1688\n",
      "Epoch 2/30\n",
      "120/120 [==============================] - 28s 231ms/step - loss: 2.0185 - accuracy: 0.5344 - val_loss: 1.9942 - val_accuracy: 0.4208\n",
      "Epoch 3/30\n",
      "120/120 [==============================] - 29s 239ms/step - loss: 1.2304 - accuracy: 0.6880 - val_loss: 2.8316 - val_accuracy: 0.4667\n",
      "Epoch 4/30\n",
      "120/120 [==============================] - 29s 243ms/step - loss: 0.7974 - accuracy: 0.7826 - val_loss: 2.4521 - val_accuracy: 0.4958\n",
      "Epoch 5/30\n",
      "120/120 [==============================] - 29s 242ms/step - loss: 0.7184 - accuracy: 0.8333 - val_loss: 1.2695 - val_accuracy: 0.6750\n",
      "Epoch 6/30\n",
      "120/120 [==============================] - 32s 267ms/step - loss: 0.4805 - accuracy: 0.8831 - val_loss: 2.2955 - val_accuracy: 0.5813\n",
      "Epoch 7/30\n",
      "120/120 [==============================] - 37s 308ms/step - loss: 0.3549 - accuracy: 0.9102 - val_loss: 5.5485 - val_accuracy: 0.5063\n",
      "Epoch 8/30\n",
      "120/120 [==============================] - 38s 313ms/step - loss: 0.2990 - accuracy: 0.9336 - val_loss: 0.5999 - val_accuracy: 0.8813\n",
      "Epoch 9/30\n",
      "120/120 [==============================] - 37s 305ms/step - loss: 0.2413 - accuracy: 0.9495 - val_loss: 0.4907 - val_accuracy: 0.9104\n",
      "Epoch 10/30\n",
      "120/120 [==============================] - 37s 312ms/step - loss: 0.2379 - accuracy: 0.9474 - val_loss: 2.1272 - val_accuracy: 0.6917\n",
      "Epoch 11/30\n",
      "120/120 [==============================] - 38s 315ms/step - loss: 0.1991 - accuracy: 0.9612 - val_loss: 0.6532 - val_accuracy: 0.9000\n",
      "Epoch 12/30\n",
      "120/120 [==============================] - 38s 314ms/step - loss: 0.1806 - accuracy: 0.9690 - val_loss: 0.5917 - val_accuracy: 0.9083\n",
      "Epoch 13/30\n",
      "120/120 [==============================] - 38s 316ms/step - loss: 0.1824 - accuracy: 0.9690 - val_loss: 1.5694 - val_accuracy: 0.8396\n",
      "Epoch 14/30\n",
      "120/120 [==============================] - 38s 317ms/step - loss: 0.1765 - accuracy: 0.9742 - val_loss: 0.7728 - val_accuracy: 0.9167\n",
      "Epoch 15/30\n",
      "120/120 [==============================] - 38s 313ms/step - loss: 0.1642 - accuracy: 0.9779 - val_loss: 1.4342 - val_accuracy: 0.8125\n",
      "Epoch 16/30\n",
      "120/120 [==============================] - 39s 324ms/step - loss: 0.1468 - accuracy: 0.9784 - val_loss: 0.7517 - val_accuracy: 0.9104\n",
      "Epoch 17/30\n",
      "120/120 [==============================] - 39s 326ms/step - loss: 0.1613 - accuracy: 0.9797 - val_loss: 0.5257 - val_accuracy: 0.9167\n",
      "Epoch 18/30\n",
      "120/120 [==============================] - 40s 334ms/step - loss: 0.1557 - accuracy: 0.9802 - val_loss: 0.4586 - val_accuracy: 0.9229\n",
      "Epoch 19/30\n",
      "120/120 [==============================] - 40s 337ms/step - loss: 0.1703 - accuracy: 0.9789 - val_loss: 0.4310 - val_accuracy: 0.9438\n",
      "Epoch 20/30\n",
      "120/120 [==============================] - 41s 345ms/step - loss: 0.1798 - accuracy: 0.9789 - val_loss: 0.7795 - val_accuracy: 0.9208\n",
      "Epoch 21/30\n",
      "120/120 [==============================] - 41s 340ms/step - loss: 0.1313 - accuracy: 0.9875 - val_loss: 0.6984 - val_accuracy: 0.9146\n",
      "Epoch 22/30\n",
      "120/120 [==============================] - 41s 340ms/step - loss: 0.1408 - accuracy: 0.9828 - val_loss: 1.0728 - val_accuracy: 0.8708\n",
      "Epoch 23/30\n",
      "120/120 [==============================] - 43s 356ms/step - loss: 0.1455 - accuracy: 0.9865 - val_loss: 0.5430 - val_accuracy: 0.9292\n",
      "Epoch 24/30\n",
      "120/120 [==============================] - 41s 344ms/step - loss: 0.1365 - accuracy: 0.9865 - val_loss: 0.4889 - val_accuracy: 0.9188\n",
      "Epoch 25/30\n",
      "120/120 [==============================] - 39s 327ms/step - loss: 0.1310 - accuracy: 0.9846 - val_loss: 0.7048 - val_accuracy: 0.9104\n",
      "Epoch 26/30\n",
      "120/120 [==============================] - 37s 306ms/step - loss: 0.1038 - accuracy: 0.9914 - val_loss: 1.0305 - val_accuracy: 0.8750\n",
      "Epoch 27/30\n",
      "120/120 [==============================] - 36s 299ms/step - loss: 0.1150 - accuracy: 0.9906 - val_loss: 3.1557 - val_accuracy: 0.7979\n",
      "Epoch 28/30\n",
      "120/120 [==============================] - 36s 297ms/step - loss: 0.1281 - accuracy: 0.9857 - val_loss: 1.1430 - val_accuracy: 0.9021\n",
      "Epoch 29/30\n",
      "120/120 [==============================] - 1029s 9s/step - loss: 0.1087 - accuracy: 0.9901 - val_loss: 0.6194 - val_accuracy: 0.9396\n",
      "Epoch 30/30\n",
      "120/120 [==============================] - 25s 209ms/step - loss: 0.1234 - accuracy: 0.9854 - val_loss: 1.8333 - val_accuracy: 0.8542\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "x = layers.Rescaling(1./255)(x)\n",
    "regularizer = keras.regularizers.L2(0.00004)\n",
    "\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, use_bias=False)(x)\n",
    "\n",
    "for size in [32, 64, 128, 256, 512]:\n",
    "  residual = x\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Activation(\"relu\")(x)\n",
    "  x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False, kernel_regularizer=regularizer)(x)\n",
    "  x = layers.BatchNormalization()(x)\n",
    "  x = layers.Activation(\"relu\")(x)\n",
    "  x = layers.Conv2D(size, 3, padding=\"same\", use_bias=False, kernel_regularizer=regularizer)(x)\n",
    "  x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "  residual = layers.Conv2D(size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
    "  x = layers.add([x, residual])\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model_6_2 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_6_2.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_6_2.summary()\n",
    "\n",
    "history_6_2 = model_6_2.fit(\n",
    "  train_processed,\n",
    "  epochs=30,\n",
    "  validation_data=val_processed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Efficient model - highest possible accuracy with lowest possible size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_31 (InputLayer)       [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d_222 (Conv2D)         (None, 98, 98, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_95 (MaxPoolin  (None, 49, 49, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_223 (Conv2D)         (None, 47, 47, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_96 (MaxPoolin  (None, 23, 23, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_224 (Conv2D)         (None, 21, 21, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_97 (MaxPoolin  (None, 10, 10, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_225 (Conv2D)         (None, 8, 8, 32)          9248      \n",
      "                                                                 \n",
      " global_average_pooling2d_27  (None, 32)               0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 6)                 198       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,782\n",
      "Trainable params: 23,782\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 04:11:59.983649: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 2.5547 - accuracy: 0.1701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 04:12:04.683507: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 5s 30ms/step - loss: 2.5547 - accuracy: 0.1701 - val_loss: 1.7908 - val_accuracy: 0.1583\n",
      "Epoch 2/40\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 1.8237 - accuracy: 0.1667 - val_loss: 1.7919 - val_accuracy: 0.1667\n",
      "Epoch 3/40\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 1.8234 - accuracy: 0.1635 - val_loss: 1.7918 - val_accuracy: 0.1688\n",
      "Epoch 4/40\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 1.8124 - accuracy: 0.1708 - val_loss: 1.7913 - val_accuracy: 0.1750\n",
      "Epoch 5/40\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 1.8559 - accuracy: 0.2096 - val_loss: 1.7436 - val_accuracy: 0.2833\n",
      "Epoch 6/40\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 1.7391 - accuracy: 0.2763 - val_loss: 1.5791 - val_accuracy: 0.3521\n",
      "Epoch 7/40\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 1.5024 - accuracy: 0.3865 - val_loss: 1.1283 - val_accuracy: 0.5479\n",
      "Epoch 8/40\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 1.2343 - accuracy: 0.5063 - val_loss: 0.9735 - val_accuracy: 0.6292\n",
      "Epoch 9/40\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 1.0508 - accuracy: 0.6021 - val_loss: 0.7639 - val_accuracy: 0.7375\n",
      "Epoch 10/40\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.9099 - accuracy: 0.6557 - val_loss: 0.6390 - val_accuracy: 0.7833\n",
      "Epoch 11/40\n",
      "120/120 [==============================] - 3s 24ms/step - loss: 0.8068 - accuracy: 0.6891 - val_loss: 0.5999 - val_accuracy: 0.7917\n",
      "Epoch 12/40\n",
      "120/120 [==============================] - 3s 25ms/step - loss: 0.7331 - accuracy: 0.7221 - val_loss: 0.5152 - val_accuracy: 0.8354\n",
      "Epoch 13/40\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.6536 - accuracy: 0.7536 - val_loss: 0.5048 - val_accuracy: 0.8333\n",
      "Epoch 14/40\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.5954 - accuracy: 0.7813 - val_loss: 0.8004 - val_accuracy: 0.7313\n",
      "Epoch 15/40\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.5517 - accuracy: 0.7953 - val_loss: 0.4279 - val_accuracy: 0.8521\n",
      "Epoch 16/40\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.5050 - accuracy: 0.8154 - val_loss: 0.4255 - val_accuracy: 0.8604\n",
      "Epoch 17/40\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.4658 - accuracy: 0.8294 - val_loss: 0.5031 - val_accuracy: 0.8083\n",
      "Epoch 18/40\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.4243 - accuracy: 0.8435 - val_loss: 0.4031 - val_accuracy: 0.8604\n",
      "Epoch 19/40\n",
      "120/120 [==============================] - 4s 30ms/step - loss: 0.3878 - accuracy: 0.8602 - val_loss: 0.3731 - val_accuracy: 0.8750\n",
      "Epoch 20/40\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.3752 - accuracy: 0.8656 - val_loss: 0.3027 - val_accuracy: 0.8854\n",
      "Epoch 21/40\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.3313 - accuracy: 0.8776 - val_loss: 0.2981 - val_accuracy: 0.8792\n",
      "Epoch 22/40\n",
      "120/120 [==============================] - 3s 26ms/step - loss: 0.3022 - accuracy: 0.8885 - val_loss: 0.3008 - val_accuracy: 0.8875\n",
      "Epoch 23/40\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.2730 - accuracy: 0.9018 - val_loss: 0.3056 - val_accuracy: 0.9000\n",
      "Epoch 24/40\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.2739 - accuracy: 0.9003 - val_loss: 0.2502 - val_accuracy: 0.9021\n",
      "Epoch 25/40\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.2339 - accuracy: 0.9180 - val_loss: 0.2491 - val_accuracy: 0.9167\n",
      "Epoch 26/40\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.2184 - accuracy: 0.9286 - val_loss: 0.2737 - val_accuracy: 0.9104\n",
      "Epoch 27/40\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.2225 - accuracy: 0.9294 - val_loss: 0.2618 - val_accuracy: 0.9042\n",
      "Epoch 28/40\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1866 - accuracy: 0.9339 - val_loss: 0.2562 - val_accuracy: 0.9125\n",
      "Epoch 29/40\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1622 - accuracy: 0.9451 - val_loss: 0.3061 - val_accuracy: 0.9104\n",
      "Epoch 30/40\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1565 - accuracy: 0.9440 - val_loss: 0.4292 - val_accuracy: 0.8813\n",
      "Epoch 31/40\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1371 - accuracy: 0.9534 - val_loss: 0.3011 - val_accuracy: 0.9188\n",
      "Epoch 32/40\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.1466 - accuracy: 0.9492 - val_loss: 0.2531 - val_accuracy: 0.9229\n",
      "Epoch 33/40\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1350 - accuracy: 0.9544 - val_loss: 0.2916 - val_accuracy: 0.9167\n",
      "Epoch 34/40\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1177 - accuracy: 0.9594 - val_loss: 0.2941 - val_accuracy: 0.9167\n",
      "Epoch 35/40\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1251 - accuracy: 0.9609 - val_loss: 0.2729 - val_accuracy: 0.9188\n",
      "Epoch 36/40\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.1287 - accuracy: 0.9607 - val_loss: 0.2914 - val_accuracy: 0.9146\n",
      "Epoch 37/40\n",
      "120/120 [==============================] - 3s 27ms/step - loss: 0.1413 - accuracy: 0.9635 - val_loss: 0.2669 - val_accuracy: 0.9208\n",
      "Epoch 38/40\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1063 - accuracy: 0.9664 - val_loss: 0.3251 - val_accuracy: 0.9021\n",
      "Epoch 39/40\n",
      "120/120 [==============================] - 3s 29ms/step - loss: 0.1009 - accuracy: 0.9706 - val_loss: 0.2699 - val_accuracy: 0.9146\n",
      "Epoch 40/40\n",
      "120/120 [==============================] - 3s 28ms/step - loss: 0.1086 - accuracy: 0.9716 - val_loss: 0.2897 - val_accuracy: 0.9188\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(100, 100, 3))\n",
    "x = inputs\n",
    "x = layers.Conv2D(16, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "model_7_1 = keras.Model(inputs, outputs)\n",
    "\n",
    "model_7_1.compile(optimizer=keras.optimizers.RMSprop(0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_7_1.summary()\n",
    "\n",
    "history_7_1 = model_7_1.fit(\n",
    "  train,\n",
    "  epochs=30,\n",
    "  validation_data=val\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
